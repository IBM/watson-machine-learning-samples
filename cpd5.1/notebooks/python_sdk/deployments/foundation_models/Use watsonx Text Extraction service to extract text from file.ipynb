{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx.ai Text Extraction service to extract text from file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook contains the steps and code demonstrating how to run a Text Extraction job using python SDK and then retrieve the results in the form of markdown file.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The purpose of this notebook is to demonstrate the usage a Text Extraction service and `ibm-watsonx-ai` Python SDK to retrieve a text from file that is located at IBM Cloud Object Storage.\n",
        "\n",
        "\n",
        "## Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [COS connection](#cos_connection)\n",
        "- [Text Extraction request](#text_extraction)\n",
        "- [Results examination](#results)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Contact with your Cloud Pak for Data administrator and ask them for your account credentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!pip install \"ibm-watsonx-ai>=1.1.5\" | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connection to WML\n",
        "\n",
        "Authenticate the Watson Machine Learning service on IBM Cloud Pak for Data. You need to provide platform `url`, your `username` and `api_key`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "username = 'PASTE YOUR USERNAME HERE'\n",
        "api_key = 'PASTE YOUR API_KEY HERE'\n",
        "url = 'PASTE THE PLATFORM URL HERE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    username=username,\n",
        "    api_key=api_key,\n",
        "    url=url,\n",
        "    instance_id=\"openshift\",\n",
        "    version=\"5.1\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively you can use `username` and `password` to authenticate WML services.\n",
        "\n",
        "```python\n",
        "credentials = Credentials(\n",
        "    username=***,\n",
        "    password=***,\n",
        "    url=***,\n",
        "    instance_id=\"openshift\",\n",
        "    version=\"5.1\"\n",
        ")\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with projects\n",
        "\n",
        "First of all, you need to create a project that will be used for your work. If you do not have project already created follow bellow steps.\n",
        "\n",
        "- Open IBM Cloud Pak main page\n",
        "- Click all projects\n",
        "- Create an empty project\n",
        "- Copy `project_id` from url and paste it below\n",
        "\n",
        "**Action**: Assign project ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_id = 'PASTE YOUR PROJECT ID HERE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an instance of APIClient with authentication details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To be able to interact with all resources available in Watson Machine Learning, you need to set **project_id** which you will be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.set.default_project(project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"cos_connection\"></a>\n",
        "## Create data connections with source document and results reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The document, from which we are going to extract text, is located at IBM Cloud Object Storage (COS). In the following example we are going to use [Granite Code Models paper](https://arxiv.org/pdf/2405.04324) as a source text document. Also, the final results file, which will contain extracted text and necessary metadata, will be placed in COS. Therefore, we use `ibm_watsonx_ai.helpers.DataConnection` and `ibm_watsonx_ai.helpers.S3Location` class to create a Python objects that will represent the references to the processed files. Please note that you have to create connection asset with your COS details (for detailed explanation how to do this see [IBM Cloud Object Storage connection](https://dataplatform.cloud.ibm.com/docs/content/wsj/manage-data/conn-cos.html?context=wx) or check below cells)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create connection to COS\n",
        "You can skip this section if you already have connection asset with **IBM Cloud Object Storage**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasource_name = 'bluemixcloudobjectstorage'\n",
        "bucketname = \"textextractionms\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cos_credentials = {\n",
        "                  \"endpoint_url\": \"<endpoint url>\",\n",
        "                  \"apikey\": \"<apikey>\",\n",
        "                  \"access_key_id\": \"<access_key_id>\",\n",
        "                  \"secret_access_key\": \"<secret_access_key>\"\n",
        "              }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating connections...\n",
            "SUCCESS\n"
          ]
        }
      ],
      "source": [
        "conn_meta_props= {\n",
        "    client.connections.ConfigurationMetaNames.NAME: f\"Connection to Database - {datasource_name} \",\n",
        "    client.connections.ConfigurationMetaNames.DATASOURCE_TYPE: client.connections.get_datasource_type_id_by_name(datasource_name),\n",
        "    client.connections.ConfigurationMetaNames.DESCRIPTION: \"Connection to external Database\",\n",
        "    client.connections.ConfigurationMetaNames.PROPERTIES: {\n",
        "        'bucket': bucketname,\n",
        "        'access_key': cos_credentials['access_key_id'],\n",
        "        'secret_key': cos_credentials['secret_access_key'],\n",
        "        'iam_url': 'https://iam.cloud.ibm.com/identity/token',\n",
        "        'url': cos_credentials['endpoint_url']\n",
        "    }\n",
        "}\n",
        "\n",
        "conn_details = client.connections.create(meta_props=conn_meta_props)\n",
        "connection_asset_id = client.connections.get_id(conn_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload file and create document and results reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "local_source_file_name = \"granite_code_models_paper.pdf\"\n",
        "source_file_name = \"./files/granite_code_models_paper.pdf\"\n",
        "results_file_name = \"./files/text_extraction_granite_code_models_paper.md\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.helpers import DataConnection, S3Location\n",
        "\n",
        "remote_document_reference = DataConnection(connection_asset_id=connection_asset_id,\n",
        "                                           location=S3Location(bucket = bucketname, path = \".\"))\n",
        "remote_document_reference.set_client(client)\n",
        "\n",
        "remote_document_reference.write(local_source_file_name, remote_name=source_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can create Data Connection that represents document and results reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "document_reference = DataConnection(connection_asset_id=connection_asset_id,\n",
        "                                    location=S3Location(bucket=bucketname,\n",
        "                                                        path=source_file_name))\n",
        "\n",
        "results_reference = DataConnection(connection_asset_id=connection_asset_id,\n",
        "                                   location=S3Location(bucket=bucketname,\n",
        "                                                       path=results_file_name))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"text_extraction\"></a>\n",
        "## Text Extraction request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since data connection for source and results files are ready, we can proceed to the text extraction run job step. To initialize Text Extraction manager we use `TextExtractions` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models.extractions import TextExtractions\n",
        "from ibm_watsonx_ai.metanames import TextExtractionsMetaNames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "extraction = TextExtractions(api_client=client,\n",
        "                             project_id=project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When running job the steps for the text extraction pipeline can be specified. For more details about available steps see [documentation](https://cloud.ibm.com/apidocs/watsonx-ai#text-extraction). The list of steps available in sdk can be found below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------  ----  --------\n",
            "META_PROP NAME    TYPE  REQUIRED\n",
            "OCR               dict  N\n",
            "TABLE_PROCESSING  dict  N\n",
            "----------------  ----  --------\n"
          ]
        }
      ],
      "source": [
        "TextExtractionsMetaNames().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To view sample parameter values for the text extraction steps run `get_example_values()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ocr': {'languages_list': ['en']}, 'tables_processing': {'enabled': True}}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TextExtractionsMetaNames().get_example_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our example we are going to use the following steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "steps = {TextExtractionsMetaNames.OCR: {'languages_list': ['en']},\n",
        "        TextExtractionsMetaNames.TABLE_PROCESSING: {'enabled': True}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can run Text Extraction job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'metadata': {'id': '5c3bf6fb-0a01-4e52-a16f-259068cbdacd',\n",
              "  'created_at': '2024-12-06T07:25:25.321Z',\n",
              "  'project_id': '99486413-555d-464c-9524-3114d6728eb2'},\n",
              " 'entity': {'document_reference': {'type': 'connection_asset',\n",
              "   'connection': {'id': 'b25d2b54-0658-4769-b5df-8edfc158096e'},\n",
              "   'location': {'bucket': 'text-extraction-ms',\n",
              "    'file_name': './files/granite_code_models_paper.pdf'}},\n",
              "  'document': None,\n",
              "  'results_reference': {'type': 'connection_asset',\n",
              "   'connection': {'id': 'b25d2b54-0658-4769-b5df-8edfc158096e'},\n",
              "   'location': {'bucket': 'text-extraction-ms',\n",
              "    'file_name': './files/text_extraction_granite_code_models_paper.md'}},\n",
              "  'steps': {'ocr': {'languages_list': ['en']},\n",
              "   'tables_processing': {'enabled': True}},\n",
              "  'assembly_md': {},\n",
              "  'results': {'status': 'submitted', 'number_pages_processed': 0}}}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "details = extraction.run_job(document_reference=document_reference, \n",
        "                             results_reference=results_reference, \n",
        "                             steps=steps,\n",
        "                             results_format='markdown')\n",
        "details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "extraction_job_id = extraction.get_id(extraction_details=details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can list text extraction jobs using a proper list method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EXTRACTION_ID</th>\n",
              "      <th>CREATED</th>\n",
              "      <th>STATUS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5c3bf6fb-0a01-4e52-a16f-259068cbdacd</td>\n",
              "      <td>2024-12-06T07:25:25.321Z</td>\n",
              "      <td>completed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71f159b1-397c-4578-b531-851c3731fb50</td>\n",
              "      <td>2024-12-05T08:20:44.318Z</td>\n",
              "      <td>completed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a83be8bc-48f9-422e-8d0e-e2d6fd63ae26</td>\n",
              "      <td>2024-12-05T08:31:46.672Z</td>\n",
              "      <td>completed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          EXTRACTION_ID                   CREATED     STATUS\n",
              "0  5c3bf6fb-0a01-4e52-a16f-259068cbdacd  2024-12-06T07:25:25.321Z  completed\n",
              "1  71f159b1-397c-4578-b531-851c3731fb50  2024-12-05T08:20:44.318Z  completed\n",
              "2  a83be8bc-48f9-422e-8d0e-e2d6fd63ae26  2024-12-05T08:31:46.672Z  completed"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extraction.list_jobs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Moreover, to get details of a particular text extraction request run following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'entity': {'document_reference': {'connection': {'id': 'b25d2b54-0658-4769-b5df-8edfc158096e'},\n",
              "   'location': {'bucket': 'text-extraction-ms',\n",
              "    'file_name': './files/granite_code_models_paper.pdf'},\n",
              "   'type': 'connection_asset'},\n",
              "  'results': {'completed_at': '2024-12-06T07:27:27.210Z',\n",
              "   'number_pages_processed': 28,\n",
              "   'running_at': '2024-12-06T07:25:27.528Z',\n",
              "   'status': 'completed'},\n",
              "  'results_reference': {'connection': {'id': 'b25d2b54-0658-4769-b5df-8edfc158096e'},\n",
              "   'location': {'bucket': 'text-extraction-ms',\n",
              "    'file_name': './files/text_extraction_granite_code_models_paper.md'},\n",
              "   'type': 'connection_asset'},\n",
              "  'steps': {'ocr': {'languages_list': ['en']},\n",
              "   'tables_processing': {'enabled': True}}},\n",
              " 'metadata': {'created_at': '2024-12-06T07:25:25.321Z',\n",
              "  'id': '5c3bf6fb-0a01-4e52-a16f-259068cbdacd',\n",
              "  'modified_at': '2024-12-06T07:27:27.223Z',\n",
              "  'project_id': '99486413-555d-464c-9524-3114d6728eb2'}}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extraction.get_job_details(extraction_id=extraction_job_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Furthermore, to delete text extraction jub run use `delete_job()` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"results\"></a>\n",
        "## Results examination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the job extraction is completed we can download the results file and process it further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_reference = extraction.get_results_reference(extraction_id=extraction_job_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"text_extraction_results_granite_code_models_paper.md\"\n",
        "\n",
        "results_reference.download(filename=filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "†Corresponding Authors \n",
            "\n",
            "Large Language Models (LLMs) trained on code are revolutionizing the software development process. Increasingly, code LLMs are being inte- grated into software development environments to improve the produc- tivity of human programmers, and LLM-based agents are beginning to show promise for handling complex tasks autonomously. Realizing the full potential of code LLMs requires a wide range of capabilities, including code generation, fixing bugs, explaining and documenting code, maintaining repositories, and more. In this work, we introduce the Granite series of decoder-only code models for code generative tasks, trained with code written in 116 programming languages. The Granite Code models family consists of models ranging in size from 3 to 34 billion parameters, suitable for applications ranging from complex application modernization tasks to on-device memory-constrained use cases. Evaluation on a comprehensive set of tasks demonstrates that Granite Code mode\n"
          ]
        }
      ],
      "source": [
        "with open(filename, 'r') as file:\n",
        "    extracted_text = file.read()\n",
        "\n",
        "print(extracted_text[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        " You successfully completed this notebook!\n",
        " \n",
        " You learned how to use `TextExtractions` manager to run text extraction requests, check status of the submitted job and download a results file.\n",
        " \n",
        "Check out our _<a href=\"https://ibm.github.io/watson-machine-learning-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Authors:\n",
        " **Mateusz Świtała**, Software Engineer at Watson Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Copyright © 2024-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "note_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}