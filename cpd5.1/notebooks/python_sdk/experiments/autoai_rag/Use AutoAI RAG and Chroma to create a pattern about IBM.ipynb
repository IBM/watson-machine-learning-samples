{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use AutoAI RAG and Chroma to create a pattern and get information from `ibm-watsonx-ai` SDK documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in the watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook contains the steps and code to demonstrate the usage of IBM AutoAI RAG. The AutoAI RAG experiment conducted in this notebook uses data scraped from the `ibm-watsonx-ai` SDK documentation.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The learning goals of this notebook are:\n",
        "\n",
        "- Create an AutoAI RAG job that will find the best RAG pattern based on provided data\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Define the RAG Optimizer](#definition)\n",
        "- [Run the RAG Experiment](#run)\n",
        "- [Compare and test RAG Patterns](#comparison)\n",
        "- [Historical runs](#runs)\n",
        "- [Clean up](#cleanup)\n",
        "- [Summary and next steps](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup task:\n",
        "\n",
        "-  Contact your Cloud Pak for Data administrator and ask them for your account credentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install and import the required modules and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U 'ibm-watsonx-ai[rag]>=1.2.4' | tail -n 1\n",
        "!pip install -U \"langchain_community>=0.3,<0.4\" | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connect to WML\n",
        "\n",
        "Authenticate the Watson Machine Learning service on IBM Cloud Pak for Data. You need to provide the platform `url`, your `username`, and your `api_key`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "username = 'PASTE YOUR USERNAME HERE'\n",
        "api_key = 'PASTE YOUR API_KEY HERE'\n",
        "url = 'PASTE THE PLATFORM URL HERE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    username=username,\n",
        "    api_key=api_key,\n",
        "    url=url,\n",
        "    instance_id=\"openshift\",\n",
        "    version=\"5.1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, you can use your `username` and `password` to authenticate WML services.\n",
        "\n",
        "```python\n",
        "credentials = Credentials(\n",
        "    username=***,\n",
        "    password=***,\n",
        "    url=***,\n",
        "    instance_id=\"openshift\",\n",
        "    version=\"5.1\"\n",
        ")\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with projects\n",
        "\n",
        "First, you need to create a project for your work. If you do not have a project already, create one by following these steps:\n",
        "\n",
        "- Open IBM Cloud Pak for Data\n",
        "- From the menu, click **View all projects**\n",
        "- Create a new project\n",
        "- Go to the **Manage** tab\n",
        "- Copy the `project_id`\n",
        "\n",
        "**Action**: Assign the project ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_id = 'PASTE YOUR PROJECT ID HERE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To be able to interact with all resources available in Watson Machine Learning, set the project that you are using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.set.default_project(project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"definition\"></a>\n",
        "\n",
        "## RAG Optimizer definition\n",
        "\n",
        "### Define a connection to the training data\n",
        "\n",
        "Upload the training data to the project as a data asset and then define a connection to the file. This example uses the `ModelInference` description from the [`ibm_watsonx_ai`](https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html) documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "url = \"https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html\"\n",
        "\n",
        "docs = WebBaseLoader(url).load()\n",
        "model_inference_content = docs[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Upload the training data to the project as a data asset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating data asset...\n",
            "SUCCESS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'7cf9bcac-b7af-49a1-bfba-a413c006777f'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "document_filename = \"ModelInference.txt\"\n",
        "\n",
        "if not os.path.isfile(document_filename):\n",
        "    with open(document_filename, \"w\") as file:\n",
        "        file.write(model_inference_content)\n",
        "\n",
        "document_asset_details = client.data_assets.create(name=document_filename, file_path=document_filename)\n",
        "\n",
        "document_asset_id = client.data_assets.get_id(document_asset_details)\n",
        "document_asset_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a connection to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.helpers import DataConnection\n",
        "\n",
        "input_data_references = [DataConnection(data_asset_id=document_asset_id)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define a connection to the test data\n",
        "\n",
        "Upload a `json` file that you want to use as a benchmark to the project as a data asset and then define a connection to the file. This example uses content from the [`ibm_watsonx_ai`](https://ibm.github.io/watsonx-ai-python-sdk/index.html) SDK documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "benchmarking_data_IBM_page_content = [\n",
        "    {\n",
        "        \"question\": \"What is path to ModelInference class?\",\n",
        "        \"correct_answer\": \"ibm_watsonx_ai.foundation_models.inference.ModelInference\",\n",
        "        \"correct_answer_document_ids\": [\n",
        "            \"ModelInference.txt\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is method for get model inferance details?\",\n",
        "        \"correct_answer\": \"get_details()\",\n",
        "        \"correct_answer_document_ids\": [\n",
        "            \"ModelInference.txt\"\n",
        "        ]\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Upload the benchmark testing data to the project as a data asset with `json` extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating data asset...\n",
            "SUCCESS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'cf8be77e-a4ff-4ca2-a2b6-0e729df93a18'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "test_filename = \"benchmarking_data_ModelInference.json\"\n",
        "\n",
        "if not os.path.isfile(test_filename):\n",
        "    with open(test_filename, \"w\") as json_file:\n",
        "        json.dump(benchmarking_data_IBM_page_content, json_file, indent=4)\n",
        "\n",
        "test_asset_details = client.data_assets.create(name=test_filename, file_path=test_filename)\n",
        "\n",
        "test_asset_id = client.data_assets.get_id(test_asset_details)\n",
        "test_asset_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a connection to the benchmark testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data_references = [DataConnection(data_asset_id=test_asset_id)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure the RAG Optimizer\n",
        "\n",
        "Provide the input information for the AutoAI RAG optimizer:\n",
        "- `name` - experiment name\n",
        "- `description` - experiment description\n",
        "- `max_number_of_rag_patterns` - maximum number of RAG patterns to create\n",
        "- `optimization_metrics` - target optimization metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.experiment import AutoAI\n",
        "\n",
        "experiment = AutoAI(credentials, project_id=project_id)\n",
        "\n",
        "rag_optimizer = experiment.rag_optimizer(\n",
        "    name='AutoAI RAG run - ModelInference documentation',\n",
        "    description=\"AutoAI RAG Optimizer on ibm_watsonx_ai ModelInference documentation\",\n",
        "    max_number_of_rag_patterns=4,\n",
        "    optimization_metrics=[AutoAI.RAGMetrics.ANSWER_CORRECTNESS]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To retrieve the configuration parameters, use `get_params()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'AutoAI RAG run - ModelInference documentation',\n",
              " 'description': 'AutoAI RAG Optimizer on ibm_watsonx_ai ModelInference documentation',\n",
              " 'max_number_of_rag_patterns': 4,\n",
              " 'optimization_metrics': ['answer_correctness']}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_optimizer.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"run\"></a>\n",
        "## Run the RAG Experiment\n",
        "\n",
        "Call the `run()` method to trigger the AutoAI RAG experiment. Choose one of two modes: \n",
        "\n",
        "- To use the **interactive mode** (synchronous job), specify `background_mode=False` \n",
        "- To use the **background mode** (asynchronous job), specify `background_mode=True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "##############################################\n",
            "\n",
            "Running '1ee9d070-c83d-4cb5-a435-43d94de1d87f'\n",
            "\n",
            "##############################################\n",
            "\n",
            "\n",
            "pending.....\n",
            "running.....................................\n",
            "completed\n",
            "Training of '1ee9d070-c83d-4cb5-a435-43d94de1d87f' finished successfully.\n"
          ]
        }
      ],
      "source": [
        "run_details = rag_optimizer.run(\n",
        "    input_data_references=input_data_references,\n",
        "    test_data_references=test_data_references,\n",
        "    background_mode=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To monitor the AutoAI RAG jobs in background mode, use the `get_run_status()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'completed'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_optimizer.get_run_status()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"comparison\"></a>\n",
        "## Compare and test RAG Patterns\n",
        "\n",
        "You can list the trained patterns and information on evaluation metrics in the form of a Pandas DataFrame by calling the `summary()` method. Use the DataFrame to compare all discovered patterns and select the one you want for further testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_answer_correctness</th>\n",
              "      <th>mean_faithfulness</th>\n",
              "      <th>mean_context_correctness</th>\n",
              "      <th>chunking.chunk_size</th>\n",
              "      <th>embeddings.model_id</th>\n",
              "      <th>vector_store.distance_metric</th>\n",
              "      <th>retrieval.method</th>\n",
              "      <th>retrieval.number_of_chunks</th>\n",
              "      <th>generation.model_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pattern_Name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pattern1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>512</td>\n",
              "      <td>ibm/slate-125m-english-rtrvr</td>\n",
              "      <td>cosine</td>\n",
              "      <td>window</td>\n",
              "      <td>5</td>\n",
              "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pattern2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8281</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1024</td>\n",
              "      <td>ibm/slate-125m-english-rtrvr</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>window</td>\n",
              "      <td>5</td>\n",
              "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pattern4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6720</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1024</td>\n",
              "      <td>ibm/slate-125m-english-rtrvr</td>\n",
              "      <td>cosine</td>\n",
              "      <td>window</td>\n",
              "      <td>5</td>\n",
              "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pattern3</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.3576</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1024</td>\n",
              "      <td>ibm/slate-125m-english-rtrvr</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>simple</td>\n",
              "      <td>5</td>\n",
              "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              mean_answer_correctness  mean_faithfulness  \\\n",
              "Pattern_Name                                               \n",
              "Pattern1                          1.0             0.6667   \n",
              "Pattern2                          1.0             0.8281   \n",
              "Pattern4                          1.0             0.6720   \n",
              "Pattern3                          0.5             0.3576   \n",
              "\n",
              "              mean_context_correctness  chunking.chunk_size  \\\n",
              "Pattern_Name                                                  \n",
              "Pattern1                           1.0                  512   \n",
              "Pattern2                           1.0                 1024   \n",
              "Pattern4                           1.0                 1024   \n",
              "Pattern3                           1.0                 1024   \n",
              "\n",
              "                       embeddings.model_id vector_store.distance_metric  \\\n",
              "Pattern_Name                                                              \n",
              "Pattern1      ibm/slate-125m-english-rtrvr                       cosine   \n",
              "Pattern2      ibm/slate-125m-english-rtrvr                    euclidean   \n",
              "Pattern4      ibm/slate-125m-english-rtrvr                       cosine   \n",
              "Pattern3      ibm/slate-125m-english-rtrvr                    euclidean   \n",
              "\n",
              "             retrieval.method  retrieval.number_of_chunks  \\\n",
              "Pattern_Name                                                \n",
              "Pattern1               window                           5   \n",
              "Pattern2               window                           5   \n",
              "Pattern4               window                           5   \n",
              "Pattern3               simple                           5   \n",
              "\n",
              "                           generation.model_id  \n",
              "Pattern_Name                                    \n",
              "Pattern1      meta-llama/llama-3-1-8b-instruct  \n",
              "Pattern2      meta-llama/llama-3-1-8b-instruct  \n",
              "Pattern4      meta-llama/llama-3-1-8b-instruct  \n",
              "Pattern3      meta-llama/llama-3-1-8b-instruct  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary = rag_optimizer.summary()\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Additionally, you can pass the `scoring` parameter to the summary method to filter RAG patterns, starting with the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary = rag_optimizer.summary(scoring=\"faithfulness\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the selected pattern\n",
        "\n",
        "Get the RAGPattern object from the RAG Optimizer experiment. By default, the RAGPattern of the best pattern is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best pattern is: Pattern1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ibm_watsonx_ai.foundation_models.extensions.rag.pattern.pattern.RAGPattern at 0x155736c50>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_pattern_name = summary.index.values[0]\n",
        "print('Best pattern is:', best_pattern_name)\n",
        "\n",
        "best_pattern = rag_optimizer.get_pattern(pattern_name=\"Pattern1\")\n",
        "best_pattern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To retrieve the pattern details, use the `get_pattern_details` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rag_optimizer.get_pattern_details(pattern_name='Pattern2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the index/collection\n",
        "\n",
        "Build a solution using the best pattern with additional document indexing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To check the `index_name` that you are working on, use the `best_pattern` method. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_pattern.vector_store._index_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://ibm.github.io/watsonx-ai-python-sdk/fm_embeddings.html\",\n",
        "    \"https://ibm.github.io/watsonx-ai-python-sdk/fm_custom_models.html\",\n",
        "    \"https://ibm.github.io/watsonx-ai-python-sdk/fm_text_extraction.html\"\n",
        "]\n",
        "docs_list = WebBaseLoader(urls).load()\n",
        "doc_splits = best_pattern.chunker.split_documents(docs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['6725adcaf281965af27100854c86e7cca86b2e101ea2aaa03bb535bc73122c66',\n",
              " '097a23e86e44625d53a3017a98d5a4480437eec7f07f1190e54d0af638653807',\n",
              " '5ca05bba9bdb16a696e16b10763a309fc607141063550ae617a9432f4dd8be45',\n",
              " '403478a3ca41145145daf0e6d15cb8a482bc79b0486bcb79f7dc5f4d487a5c62',\n",
              " '9d3b51d2aeaa0bad48672e42135825b34548742a4d20cfb13617f7004055edb9',\n",
              " '24628f30b0c805ed6f3423d7d8cae878df6cda0601785a02df72a7dbe29672da',\n",
              " '02cab2320f3ab03bf2f27f94bcd143202e2cc88c0a7275b2b4f1bef0ab645df8',\n",
              " 'dfb96bc7f12b52572739ee31a86ed93f97bea43b8ec0b09608943345456ca6f1',\n",
              " '9452bf02ff2e978bafa4c9021e4e4774bce393103bd0d3e130bc392b79e9c97d',\n",
              " '06c81a352d551a38d5d43f71c4346e26aadd461c8f130371edb97bff2fa63fec',\n",
              " '234fdc00083820332c723a4f6bd1a9ab5181726df785899729953aeb2b82e1a6',\n",
              " '753eed2b1575615322ee5482dd899b33d5d6f9886034954aec05934ca7a8ee3c',\n",
              " 'c9965f644c828f1cc3de727b5c83c212c921d40b4aaa7037ab4ce6932ad86a69',\n",
              " '2dc9caad80d046bdfa883fac89d8d21d656ea101da1a9d5cb107a3ba3caae117',\n",
              " '8102aadc0c8647633aaca64d3bec56c32eb8ce6b2bb6e3d7c1b99d0b4f84eef6',\n",
              " '094103149e5d19a3865f38f9f799647a52a5929e406d215aefbf73ac13e37e3c',\n",
              " '9204a0c354580344e94fef86fb8fdb7bbdb2131e079f2587394d53a0a17cbbee',\n",
              " '2e407d24aab8d4fa512473429e2bbd0663dc271eaa20d0efb1f94978b40603a2',\n",
              " '0406814910c95094d9097bc9cf190453061c3b09921f1517cd39147c5f3896f6',\n",
              " '408f20cac274dec41d72f2b9403babd13538ea4a18a12a114c90bf9fcc2a800c',\n",
              " '92d6003d6df9eecb25e26260d257529fde68cdefbf591b52734a0a97bd1667b1',\n",
              " '5ca328f81a6752b39d71fa2087329a87fb99eea2e0ae7aaf6aa8c6d939be2b24',\n",
              " 'c98054c14078b76c2fd36bf5a4fc8205cec9203de9da34aeccf8de8e3bdf07b6',\n",
              " 'cd48e770d9fa86dad839af163b3eb36469c7ccf610434b6ab00b6c21b09e45ec',\n",
              " '9458d426866a2044a2a4533933d2c421c30954f320665724b8f1c96657b37025',\n",
              " '383b1ac555d89a6495a2097aead91389a344a331f4bccc2fc60a5ee0b1dc65ea',\n",
              " '1fa19010226040c7f9dab36923297f11eaec414a4c6fbb3cc77502b8ed892b4b',\n",
              " '80c963969e5dd6e2ab69a172f2145453b719c01fef48c42a016c779044449128',\n",
              " '64023c9571622adf8220e051e7d23fbce37978188da49ae4b36ab2ae83741a56',\n",
              " '19bd4bf99987ecead116c46c57ceffde43381b8ce1c862d00f92d936ba264842',\n",
              " 'd27238c5f37754a6f0f29cdbae10d0788dd023d923592d9342981a9d49553fd0',\n",
              " 'a6af3cd509d81438ed8a5642efdbd67b38f43e83508682ed1dd74f21e1ce50ae',\n",
              " '49b65eaa8c8ffaca83b77d8aa508e847e2b5c18043c335a2dc99f7da83d25cca',\n",
              " '9b266ed02c610925e6c0ee4feb94200db6aacd277e0312844d9c10a2cf786d68',\n",
              " 'b32ab71133907d9dca8870ef2de0940a4c38622354d91a8b6df0f163a8546578',\n",
              " '01bc188e10de91e7feb7fb32b9dbd884933b1551ec21c2bd584cc2da597b1329',\n",
              " '44cb419aced051cf7a8220140d51308c2c00b8058269b7e4d5e236d063aed495',\n",
              " '5dc01961a82554df53301898f5056c5cfddc5e28fa32d932ea70619706c5f420',\n",
              " 'b0507b576292210da508384c28d103e15616eefabd6947a0185e6c06038f0fe4',\n",
              " '4af18c0f7fb4936d01bc83beb2fcc8cda207fa63fdf43a5d33772622a8706be0',\n",
              " '41245790df6042ddff114afc2aad2435f2825314b4d041dc24c3909f4582e61c',\n",
              " '2bfcedc2ba63a12285d2556655e43f005362aae3df2108618d0e892069feb407',\n",
              " '87c22b856be708d0b50c850ecd4c1a8e097be0978decf67bc5232db8475882e9',\n",
              " 'df2360eaf03dd3d99be7d1561765728ff70171b2ba14b97065a8fbcff580efe4',\n",
              " '2f4aa6934ca00b2e05602e67148a217270148c76fa1ab643c0342713ec617f97',\n",
              " '7fc32975f210f966b005c48ed84870096741d6c09cfd9739e1799b84c6a5fe89',\n",
              " '8ababd6b9392645e14871240ebf9a4c72162a618c1bc73bd8703f08539bd09bb',\n",
              " '2c4c9101f2460825f8fc5015cf26ab84fbd5af796e0fa54d2b86cbdb69ce6907',\n",
              " 'f8d7dbc1b3d7be71eb30cc26d5fb61d86900a60bfec26cc781888fa03ab641ef',\n",
              " '1d136dfa0596448b605d735908bb529c30da6f4929d7a80444e4a2f5757a53d9',\n",
              " '06a988406406705185648a5ac0b7000d520f015345e6c2fe8861b7467102f536',\n",
              " '751bd33be140a0255c6ce440f22f1ed9bac2f9e15592355d53a1a6a0a376e04c',\n",
              " 'c4d511433cc3f45d0320ebf68d4a73ab9d2c1aec163a3b25547485952ef323b8',\n",
              " 'c372ba0297ae2560e043f8cab39d3d4f33cdf93b39baffa1f054587d3a892171',\n",
              " 'dd9777d4cf7aa6aefb31c379f0591db888c9a905804a7e871674da28840fe799',\n",
              " '73a4f66d52c5bbbb3dffedb81c9f622eec884a44ed6e459d1d456a2e3140417b',\n",
              " '3afd8aedab00891c37759085c73950493706722322fdc34e8efe990b9f9b7c34',\n",
              " '707c090e0979e0843b53a491319eecfcc93b4fc1710f883ce8e20d00bd6998bf',\n",
              " 'b054c1853501555ca7558a60e661e7c73522638701d3b96cb46453aff22084f4',\n",
              " '63bb5a069a11f67c1d1bfa17088a88a6e0ba1a51ec007523ca7af9e7c36e8154',\n",
              " '7bca16127ae875f7ee97f339c1142c45a70b99ddfc65716e2e5faeebda410949',\n",
              " '21b9317d8cb52c99778d34758e8331cd44cafbc1b883582a50dd0c6674c861d1',\n",
              " 'b1ef1a465e31ec04669516b0e307c39a6fd718e139894e2325dccf318e97ce16',\n",
              " '60ddc46f9a7ea560058eb4b97266d208334b4bc8601b5bb1d3c87c1f3dd58aa8',\n",
              " 'af1391975c63e7989916e284704e360fb5740957617dc2cf9262ba5b2c642dde',\n",
              " '9513275c3df82356807889a5d5f554994562e9d1fd94b988baded7690a4743c6',\n",
              " 'f1ef20a4c8e27eee0e9cde8f0d54a679e014502dcd6894243337a714acd63376',\n",
              " '27bdf8d0c5a5b0c115bed28344aba089ce0ca54a89e08ffe3e8b2c22630dd34d',\n",
              " 'a9c85ce47b52d3b6ba44531ba20f1ab4c4b4c0f3bb216feb16a65b792395adf9',\n",
              " '47de4f86ba643f001431eeb68a0df6e2509afbb96d623d5ee0937e1295881184',\n",
              " 'bfeccbbb45ca83f2d0f6bd5dd2126c5db94a351866f00f7cc1a24a25508b07ce',\n",
              " '588c1a1b7841f06d9e50114e19cba57413f9c4350a8cefd4efe505fa5a6be35d',\n",
              " 'e30a7eb0eb2e1438d03ebffb88057e9eb1b7054a1f2442b0de3ed6e4272c7e75',\n",
              " '4c556da7422de5a4818197bfc937cd607f40f2e3e2c6b71ff3db316d09e5dbe3',\n",
              " 'e28a7b7cb804f4021602a2f9146a2626418d1e80dff23b89ad3e1ba2e1e563e9']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_pattern.indexing_function(doc_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Query the RAGPattern locally to test it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'predictions': [{'fields': ['answer', 'reference_documents'],\n",
              "   'values': [['\\n\\nAccording to the document, to add Task Credentials, you can use the following methods:\\n\\n1. List available task credentials: `client.task_credentials.list()`\\n2. Create new task credentials: `client.task_credentials.store()`\\n3. Get the status of available task credentials: `client.task_credentials.get_details()`\\n\\nIf the list is empty, you can create new task credentials using the `store` method. Task Credentials are required on IBM watsonx.ai for IBM Cloud to make a deployment, and they can help deploy a custom foundation model and avoid token expiration issues.',\n",
              "     [{'page_content': 'IBM watsonx.ai for IBM Cloud\\nIBM watsonx.ai software with IBM Cloud Pak for Data\\n\\n\\nIBM watsonx.ai for IBM Cloud¶\\nThis section shows how to create task credentials, store and deploy a model, and use the ModelInference module with the created deployment on IBM watsonx.ai for IBM Cloud.\\n\\nInitialize an APIClient object¶\\nInitialize an APIClient object if needed. For more details about supported APIClient initialization, see Setup.\\nfrom ibm_watsonx_ai import APIClient client = APIClient(credentials)\\nclient.set.default_project(project_id=project_id)\\n# or client.set.default_space(space_id=space_id)\\n\\n\\n\\n\\nAdd Task Credentials¶\\n\\nWarning\\nIf not already added, Task Credentials are required on IBM watsonx.ai for IBM Cloud to make a deployment.\\n\\nWith task credentials, you can deploy a custom foundation model and avoid token expiration issues.\\nFor more details, see Adding task credentials.\\nTo list available task credentials, use the list method:\\nclient.task_credentials.list() If the list is empty, you can create new task credentials with the store method:\\nclient.task_credentials.store()\\n\\n\\nTo get the status of available task credentials, use the get_details method:\\nclient.task_credentials.get_details() Store the model in the service repository¶\\nTo store a model as an asset in the repo, you must first create proper metadata.\\nFor Cloud, you need to have an active connection to Cloud Object Storage.\\nTo see how to create a COS connection, refer to Connection Asset.\\nGet the parameters for the MODEL_LOCATION field below from the COS connection.\\nmetadata = {\\n    client.repository.ModelMetaNames.NAME: \"custom FM asset,\\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_ID: sw_spec_id,\\n    client.repository.ModelMetaNames.TYPE: client.repository.ModelAssetTypes.CUSTOM_FOUNDATION_MODEL_1_0,\\n    client.repository.ModelMetaNames.MODEL_LOCATION: {\\n        \"file_path\": \"path/to/pvc\",\\n        \"bucket\": \"watsonx-llm-models\",\\n        \"connection_id\": \"5e891c6b-3aa9-4f01-8e2d-785d81797466\",\\n    },\\n}',\n",
              "       'metadata': {'sequence_number': [6, 7, 8, 9, 10],\n",
              "        'document_id': '-2689579869660702020'}},\n",
              "      {'page_content': 'Back to top\\n\\n\\n\\n\\n\\nView this page\\n\\n\\n\\n\\nToggle Light / Dark / Auto color theme\\n\\n\\n\\n\\n\\n\\n\\nToggle table of contents sidebar\\n\\n\\n\\n\\n\\nCustom models¶\\nThe custom models of watsonx.ai client might differ depending on the product offering. Go to your product section\\nto see the steps for model deployment.\\n\\nIBM watsonx.ai for IBM Cloud\\nIBM watsonx.ai software with IBM Cloud Pak for Data\\n\\n\\nIBM watsonx.ai for IBM Cloud¶\\nThis section shows how to create task credentials, store and deploy a model, and use the ModelInference module with the created deployment on IBM watsonx.ai for IBM Cloud.\\n\\nInitialize an APIClient object¶\\nInitialize an APIClient object if needed. For more details about supported APIClient initialization, see Setup.\\nfrom ibm_watsonx_ai import APIClient client = APIClient(credentials)\\nclient.set.default_project(project_id=project_id)\\n# or client.set.default_space(space_id=space_id)\\n\\n\\n\\n\\nAdd Task Credentials¶\\n\\nWarning\\nIf not already added, Task Credentials are required on IBM watsonx.ai for IBM Cloud to make a deployment.\\n\\nWith task credentials, you can deploy a custom foundation model and avoid token expiration issues.\\nFor more details, see Adding task credentials.\\nTo list available task credentials, use the list method:\\nclient.task_credentials.list() If the list is empty, you can create new task credentials with the store method:\\nclient.task_credentials.store()\\n\\n\\nTo get the status of available task credentials, use the get_details method:\\nclient.task_credentials.get_details() Store the model in the service repository¶\\nTo store a model as an asset in the repo, you must first create proper metadata.\\nFor Cloud, you need to have an active connection to Cloud Object Storage.\\nTo see how to create a COS connection, refer to Connection Asset.\\nGet the parameters for the MODEL_LOCATION field below from the COS connection.\\nmetadata = {\\n    client.repository.ModelMetaNames.NAME: \"custom FM asset,\\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_ID: sw_spec_id,',\n",
              "       'metadata': {'sequence_number': [5, 6, 7, 8, 9],\n",
              "        'document_id': '-2689579869660702020'}},\n",
              "      {'page_content': 'the path to a CA_BUNDLE file\\nthe path of a directory with certificates of trusted CAs\\nTrue - default path to truststore will be taken\\nFalse - no verification will be made persistent_connection (bool, optional) – defines whether to keep a persistent connection when evaluating the generate, ‘embed_query’, and ‘embed_documents` methods with one prompt\\nor batch of prompts that meet the length limit. For more details, see Generate embeddings.\\nTo close the connection, run embeddings.close_persistent_connection(), defaults to True. Added in 1.1.2.\\nbatch_size (int, optional) – Number of elements to be embedded sending in one call, defaults to 1000 Note\\nWhen the credentials parameter is passed, one of these parameters is required: [project_id, space_id].\\n\\n\\nHint\\nYou can copy the project_id from the Project’s Manage tab (Project -> Manage -> General -> Details).\\n\\nExample:\\n from ibm_watsonx_ai import Credentials\\n from ibm_watsonx_ai.foundation_models import Embeddings\\n from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames as EmbedParams\\n from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes embed_params = {\\n     EmbedParams.TRUNCATE_INPUT_TOKENS: 3,\\n     EmbedParams.RETURN_OPTIONS: {\\n     \\'input_text\\': True\\n     }\\n }\\n\\n embedding = Embeddings(\\n     model_id=EmbeddingTypes.IBM_SLATE_30M_ENG,\\n     params=embed_params,\\n     credentials=Credentials(\\n         api_key = \"***\",\\n         url = \"https://us-south.ml.cloud.ibm.com\"),\\n     project_id=\"*****\"\\n     )\\n\\n\\n\\n\\nclose_persistent_connection()[source]¶\\nOnly applicable if persistent_connection was set to True in Embeddings initialization. embed_documents(texts, params=None, concurrency_limit=5)[source]¶\\nReturns list of embedding vectors for provided texts.\\n\\nParameters:\\n\\ntexts (list[str]) – list of texts for which embedding vectors will be generated\\nparams (ParamsType | None, optional) – MetaProps for the embedding generation, use ibm_watsonx_ai.metanames.EmbedTextParamsMetaNames().show() to view the list of MetaNames, defaults to None\\nconcurrency_limit (int, optional) – number of requests to be sent in parallel, max is 10, defaults to 5',\n",
              "       'metadata': {'sequence_number': [8, 9, 10, 11, 12],\n",
              "        'document_id': '4995309765013428143'}},\n",
              "      {'page_content': 'Prompt Template Manager\\nExtensionsToggle navigation of Extensions\\nLangChain\\nLlamaIndex\\nRAG\\n\\n\\nHelpers\\nCustom models\\nText Extractions\\nParameter Scheme\\nRerank\\n\\n\\nSaving external models\\n\\n\\nSamples\\nMigration from ibm_watson_machine_learning\\nV1 Migration Guide\\nChangelog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBack to top\\n\\n\\n\\n\\n\\nView this page\\n\\n\\n\\n\\nToggle Light / Dark / Auto color theme\\n\\n\\n\\n\\n\\n\\n\\nToggle table of contents sidebar\\n\\n\\n\\n\\n\\nCustom models¶\\nThe custom models of watsonx.ai client might differ depending on the product offering. Go to your product section\\nto see the steps for model deployment.\\n\\nIBM watsonx.ai for IBM Cloud\\nIBM watsonx.ai software with IBM Cloud Pak for Data\\n\\n\\nIBM watsonx.ai for IBM Cloud¶\\nThis section shows how to create task credentials, store and deploy a model, and use the ModelInference module with the created deployment on IBM watsonx.ai for IBM Cloud.\\n\\nInitialize an APIClient object¶\\nInitialize an APIClient object if needed. For more details about supported APIClient initialization, see Setup.\\nfrom ibm_watsonx_ai import APIClient client = APIClient(credentials)\\nclient.set.default_project(project_id=project_id)\\n# or client.set.default_space(space_id=space_id)\\n\\n\\n\\n\\nAdd Task Credentials¶\\n\\nWarning\\nIf not already added, Task Credentials are required on IBM watsonx.ai for IBM Cloud to make a deployment.\\n\\nWith task credentials, you can deploy a custom foundation model and avoid token expiration issues.\\nFor more details, see Adding task credentials.\\nTo list available task credentials, use the list method:\\nclient.task_credentials.list() If the list is empty, you can create new task credentials with the store method:\\nclient.task_credentials.store()\\n\\n\\nTo get the status of available task credentials, use the get_details method:\\nclient.task_credentials.get_details()',\n",
              "       'metadata': {'sequence_number': [4, 5, 6, 7, 8],\n",
              "        'document_id': '-2689579869660702020'}},\n",
              "      {'page_content': 'Prompt Template Manager\\nExtensionsToggle navigation of Extensions\\nLangChain\\nLlamaIndex\\nRAG\\n\\n\\nHelpers\\nCustom models\\nText Extractions\\nParameter Scheme\\nRerank\\n\\n\\nSaving external models\\n\\n\\nSamples\\nMigration from ibm_watson_machine_learning\\nV1 Migration Guide\\nChangelog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBack to top\\n\\n\\n\\n\\n\\nView this page\\n\\n\\n\\n\\nToggle Light / Dark / Auto color theme\\n\\n\\n\\n\\n\\n\\n\\nToggle table of contents sidebar\\n\\n\\n\\n\\n\\nText Extractions¶\\n\\n\\nclass ibm_watsonx_ai.foundation_models.extractions.TextExtractions(credentials=None, project_id=None, space_id=None, api_client=None)[source]¶\\nBases: WMLResource\\nInstantiate the Text Extraction service.\\n\\nParameters:\\n\\ncredentials (Credentials, optional) – credentials to the Watson Machine Learning instance\\nproject_id (str, optional) – ID of the Watson Studio project, defaults to None\\nspace_id (str, optional) – ID of the Watson Studio space, defaults to None\\napi_client (APIClient, optional) – initialized APIClient object with a set project ID or space ID. If passed, credentials and project_id/space_id are not required, defaults to None\\n\\n\\nRaises:\\n\\nInvalidMultipleArguments – raised if space_id and project_id or credentials and api_client are provided simultaneously\\nWMLClientError – raised if the CPD version is less than 5.0\\n\\n\\n\\n from ibm_watsonx_ai import Credentials\\n from ibm_watsonx_ai.foundation_models.extractions import TextExtractions\\n\\nextraction = TextExtractions(\\n     credentials=Credentials(\\n                         api_key = \"***\",\\n                         url = \"https://us-south.ml.cloud.ibm.com\"),\\n     project_id=\"*****\"\\n     ) delete_job(extraction_id)[source]¶\\nDelete a text extraction job.\\n\\nReturns:\\nreturn “SUCCESS” if the deletion succeeds\\n\\nReturn type:\\nstr\\n\\n\\nExample:\\nextraction.delete_job(extraction_id=\"<extraction_id>\")\\n\\n\\n\\n\\n\\nstatic get_id(extraction_details)[source]¶\\nGet the unique ID of a stored extraction request.\\n\\nParameters:\\nextraction_details (dict) – metadata of the stored extraction\\n\\nReturns:\\nunique ID of the stored extraction request\\n\\nReturn type:\\nstr',\n",
              "       'metadata': {'sequence_number': [4, 5, 6, 7, 8],\n",
              "        'document_id': '213324646291236183'}}]]]}]}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions = [\"How to add Task Credentials?\"]\n",
        "\n",
        "payload = {\n",
        "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
        "        {\n",
        "            \"values\": questions,\n",
        "            \"access_token\": client.token\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "best_pattern.inference_function()(payload)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"runs\"></a>\n",
        "## Historical runs\n",
        "\n",
        "In this section, you will learn how to work with historical RAG Optimizer jobs (runs).\n",
        "\n",
        "To list historical runs, use the `list()` method and provide the `'rag_optimizer'` filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>run_id</th>\n",
              "      <th>state</th>\n",
              "      <th>auto_pipeline_optimizer name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-11-27T10:53:06.823Z</td>\n",
              "      <td>1ee9d070-c83d-4cb5-a435-43d94de1d87f</td>\n",
              "      <td>completed</td>\n",
              "      <td>AutoAI RAG run - ModelInference documentation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  timestamp                                run_id      state  \\\n",
              "0  2024-11-27T10:53:06.823Z  1ee9d070-c83d-4cb5-a435-43d94de1d87f  completed   \n",
              "\n",
              "                    auto_pipeline_optimizer name  \n",
              "0  AutoAI RAG run - ModelInference documentation  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment.runs(filter='rag_optimizer').list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1ee9d070-c83d-4cb5-a435-43d94de1d87f'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_id = run_details['metadata']['id']\n",
        "run_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the executed optimizer's configuration parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'AutoAI RAG run - ModelInference documentation',\n",
              " 'description': 'AutoAI RAG Optimizer on ibm_watsonx_ai ModelInference documentation',\n",
              " 'max_number_of_rag_patterns': 4,\n",
              " 'optimization_metrics': ['answer_correctness']}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment.runs.get_rag_params(run_id=run_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the historical rag_optimizer instance and training details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "historical_opt = experiment.runs.get_rag_optimizer(run_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List trained patterns for the selected optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_answer_correctness</th>\n",
              "      <th>mean_faithfulness</th>\n",
              "      <th>mean_context_correctness</th>\n",
              "      <th>chunking.chunk_size</th>\n",
              "      <th>embeddings.model_id</th>\n",
              "      <th>vector_store.distance_metric</th>\n",
              "      <th>retrieval.method</th>\n",
              "      <th>retrieval.number_of_chunks</th>\n",
              "      <th>generation.model_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pattern_Name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pattern1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>512</td>\n",
              "      <td>ibm/slate-125m-english-rtrvr</td>\n",
              "      <td>cosine</td>\n",
              "      <td>window</td>\n",
              "      <td>5</td>\n",
              "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pattern2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8281</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1024</td>\n",
              "      <td>ibm/slate-125m-english-rtrvr</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>window</td>\n",
              "      <td>5</td>\n",
              "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pattern4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6720</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1024</td>\n",
              "      <td>ibm/slate-125m-english-rtrvr</td>\n",
              "      <td>cosine</td>\n",
              "      <td>window</td>\n",
              "      <td>5</td>\n",
              "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pattern3</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.3576</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1024</td>\n",
              "      <td>ibm/slate-125m-english-rtrvr</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>simple</td>\n",
              "      <td>5</td>\n",
              "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              mean_answer_correctness  mean_faithfulness  \\\n",
              "Pattern_Name                                               \n",
              "Pattern1                          1.0             0.6667   \n",
              "Pattern2                          1.0             0.8281   \n",
              "Pattern4                          1.0             0.6720   \n",
              "Pattern3                          0.5             0.3576   \n",
              "\n",
              "              mean_context_correctness  chunking.chunk_size  \\\n",
              "Pattern_Name                                                  \n",
              "Pattern1                           1.0                  512   \n",
              "Pattern2                           1.0                 1024   \n",
              "Pattern4                           1.0                 1024   \n",
              "Pattern3                           1.0                 1024   \n",
              "\n",
              "                       embeddings.model_id vector_store.distance_metric  \\\n",
              "Pattern_Name                                                              \n",
              "Pattern1      ibm/slate-125m-english-rtrvr                       cosine   \n",
              "Pattern2      ibm/slate-125m-english-rtrvr                    euclidean   \n",
              "Pattern4      ibm/slate-125m-english-rtrvr                       cosine   \n",
              "Pattern3      ibm/slate-125m-english-rtrvr                    euclidean   \n",
              "\n",
              "             retrieval.method  retrieval.number_of_chunks  \\\n",
              "Pattern_Name                                                \n",
              "Pattern1               window                           5   \n",
              "Pattern2               window                           5   \n",
              "Pattern4               window                           5   \n",
              "Pattern3               simple                           5   \n",
              "\n",
              "                           generation.model_id  \n",
              "Pattern_Name                                    \n",
              "Pattern1      meta-llama/llama-3-1-8b-instruct  \n",
              "Pattern2      meta-llama/llama-3-1-8b-instruct  \n",
              "Pattern4      meta-llama/llama-3-1-8b-instruct  \n",
              "Pattern3      meta-llama/llama-3-1-8b-instruct  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "historical_opt.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"cleanup\"></a>\n",
        "## Clean up\n",
        "\n",
        "To delete the current experiment, use the `cancel_run(hard_delete=True)` method.\n",
        "\n",
        "**Warning:** Be careful: once you delete an experiment, you will no longer be able to refer to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_optimizer.cancel_run(hard_delete=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To clean up all of the created assets:\n",
        "- experiments\n",
        "- trainings\n",
        "- pipelines\n",
        "- model definitions\n",
        "- models\n",
        "- functions\n",
        "- deployments\n",
        "\n",
        "follow the steps in this sample [notebook](https://github.com/IBM/watson-machine-learning-samples/blob/master/cpd5.1/notebooks/python_sdk/instance-management/Machine%20Learning%20artifacts%20management.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to use `ibm-watsonx-ai` to run AutoAI RAG experiments. \n",
        "\n",
        " Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Authors\n",
        "\n",
        "**Mateusz Szewczyk**, Software Engineer at Watson Machine Learning\n",
        "\n",
        "Copyright © 2024-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "note_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
