{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically Building a RAG Pipeline with AutoAI RAG on Watsonx.ai Using Db2 Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the following Python notebook, I have built a **Retrieval-Augmented Generation (RAG) pipeline** to answer questions based on a collection of articles Iâ€™ve written about **IBM Db2â€™s machine learning features**.\n",
    "\n",
    "To construct this pipeline, I used **AutoAI RAG**, an automated tool available as a service on **Watsonx.ai Cloud**. AutoAI RAG simplifies the process of building an **end-to-end RAG pipeline** by running experiments with multiple configurations to identify the best-performing RAG pattern.\n",
    "\n",
    "## How AutoAI RAG Works\n",
    "\n",
    "1. **Generates candidate patterns**  \n",
    "   - Explores different **LLMs, embedding models, and retrieval strategies**.  \n",
    "2. **Evaluates candidate patterns**  \n",
    "   - Uses **sample question-answer pairs** to rank the candidates based on a predefined evaluation metric.  \n",
    "3. **Automates complexity**  \n",
    "   - Removes the need for manual design and optimization.  \n",
    "4. **Deploys the best pattern**  \n",
    "   - Once the optimal pattern is found, it is automatically deployed on **Watsonx.ai**, enabling seamless **question-answering** over a **private knowledge base**.\n",
    "\n",
    "This automation makes it significantly easier to build and deploy **effective RAG pipelines** without dealing with the underlying complexities.\n",
    "\n",
    "Check it out!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prerequisites**  \n",
    "\n",
    "Before running this notebook, ensure that you have:  \n",
    "\n",
    "### **1. Set Up a Python Environment**  \n",
    "- Create a Python environment with the required dependencies.  \n",
    "- This notebook was developed using **Python 3.12.3** within a **virtual environment (venv)**.  \n",
    "- The complete list of installed Python packages and their versions is available in the **[`requirements.txt`](requirements.txt\n",
    ")** file located in the same directory of this notebook.  \n",
    "\n",
    "### **2. Provision Watsonx.ai Runtime and Create a Watsonx.ai Project**  \n",
    "- You need an active **Watsonx.ai runtime** and a **Watsonx.ai project**.  \n",
    "- Follow the instructions in the official documentation:  \n",
    "  ðŸ‘‰ [Coding an AutoAI RAG experiment with a Chroma vector store](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-rag-code-chroma.html?context=wx&audience=wdp)  \n",
    "\n",
    "### **3. Configure API Credentials**  \n",
    "- In the same directory as this notebook, create a file named **`.env`** (the filename must be exactly `.env`).  \n",
    "- Add the following keys and replace the placeholders with your actual credentials:  \n",
    "\n",
    "```ini\n",
    "WATSONX_PROJECT=REPLACE_WITH_YOUR_WATSONX_AI_PROJECT_ID\n",
    "WATSONX_APIKEY=REPLACE_WITH_YOUR_WATSONX_AI_RUNTIME_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai import APIClient, Credentials\n",
    "from ibm_watsonx_ai.experiment import AutoAI\n",
    "from ibm_watsonx_ai.helpers import DataConnection\n",
    "import os\n",
    "import json\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from ibm_watsonx_ai.experiment import AutoAI\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `watsonx.ai` APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `watsonx.ai` API key and project id from `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(os.getcwd()+\"/.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `watsonx.ai` credentials and create an instance of `watsonx.ai` APIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials(\n",
    "                url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "                api_key = os.getenv(\"WATSONX_APIKEY\", \"\")\n",
    "                )\n",
    "\n",
    "client = APIClient(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the watsonx.ai `project id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_id = os.getenv(\"WATSONX_PROJECT\", \"\")\n",
    "client.set.default_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Upload Training Data to IBM Cloud COS bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the list of files that I previously uploaded to COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>ASSET_TYPE</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>ASSET_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ModelInference.txt</td>\n",
       "      <td>data_asset</td>\n",
       "      <td>20198</td>\n",
       "      <td>56345f72-6f01-41b3-8e8c-bbd31011c164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benchmarking_data_ModelInference.json</td>\n",
       "      <td>data_asset</td>\n",
       "      <td>458</td>\n",
       "      <td>cfe2836e-cebf-4c59-8c99-d042c7418021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    NAME  ASSET_TYPE   SIZE  \\\n",
       "0                     ModelInference.txt  data_asset  20198   \n",
       "1  benchmarking_data_ModelInference.json  data_asset    458   \n",
       "\n",
       "                               ASSET_ID  \n",
       "0  56345f72-6f01-41b3-8e8c-bbd31011c164  \n",
       "1  cfe2836e-cebf-4c59-8c99-d042c7418021  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.data_assets.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training content from the above URL and save it locally as `ModelInference.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html\"\n",
    "\n",
    "docs = WebBaseLoader(url).load()\n",
    "\n",
    "# Access the content of the loaded document\n",
    "train_doc_content = docs[0].page_content\n",
    "train_filename = \"ModelInference.txt\"\n",
    "\n",
    "with open(train_filename, \"w\") as file:\n",
    "        # Write the content of the web page to the file\n",
    "        file.write(train_doc_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ModelInference.txt` wasnt's previously uploaded to COS, Upload it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file: ModelInference.txt was previously uploaded with asset ID: 56345f72-6f01-41b3-8e8c-bbd31011c164\n"
     ]
    }
   ],
   "source": [
    "wx_assets = client.data_assets.list()\n",
    "\n",
    "# If an asset with the name document_file doesn't exist already, upload it to wx.ai\n",
    "if train_filename not in wx_assets['NAME'].values:\n",
    "    # Upload the training file\n",
    "    document_asset_details = client.data_assets.create(name=train_filename, file_path=train_filename)\n",
    "    print(f'Uploaded training file: {train_filename}')\n",
    "    \n",
    "    # Get the ID of the uploaded training file\n",
    "    document_asset_id = client.data_assets.get_id(document_asset_details)\n",
    "    \n",
    "    # Define a connection to the training data\n",
    "    train_data_references = [DataConnection(data_asset_id=document_asset_id)]\n",
    "else:\n",
    "    # Get the asset_id for the matching row\n",
    "    document_asset_id = wx_assets.loc[wx_assets['NAME'] == train_filename, 'ASSET_ID'].iloc[0]\n",
    "    print(f\"Training file: {train_filename} was previously uploaded with asset ID: {document_asset_id}\")\n",
    "    \n",
    "    # Define a connection to the previously uploaded training data\n",
    "    train_data_references = [DataConnection(data_asset_id=document_asset_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Upload Evaluation data to COS \n",
    "`AutoAI RAG` experiment will use this evaluation data to compute the accuracy of candidate `RAG Pipelines` during the exeriment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'benchmarking_data_ModelInference.json' has been overwritten successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "benchmarking_data_IBM_page_content = [\n",
    "    {\n",
    "        \"question\": \"What is path to ModelInference class?\",\n",
    "        \"correct_answer\": \"ibm_watsonx_ai.foundation_models.inference.ModelInference\",\n",
    "        \"correct_answer_document_ids\": [\n",
    "            \"ModelInference.txt\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is method for get model inferance details?\",\n",
    "        \"correct_answer\": \"get_details()\",\n",
    "        \"correct_answer_document_ids\": [\n",
    "            \"ModelInference.txt\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "test_filename = \"benchmarking_data_ModelInference.json\"\n",
    "\n",
    "# Overwrite the file regardless of its existence\n",
    "with open(test_filename, \"w\") as json_file:\n",
    "    json.dump(benchmarking_data_IBM_page_content, json_file, indent=4)\n",
    "    print(f\"File '{test_filename}' has been overwritten successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an asset with the name test_filename doesn't exist already, upload it to wx.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file: benchmarking_data_ModelInference.json was previously uploaded with asset ID: cfe2836e-cebf-4c59-8c99-d042c7418021\n"
     ]
    }
   ],
   "source": [
    "if test_filename not in wx_assets['NAME'].values:\n",
    "    # Upload the test file\n",
    "    document_asset_details = client.data_assets.create(name=test_filename, file_path=test_filename)\n",
    "    print(f'Uploaded test file: {test_filename}')\n",
    "    \n",
    "    # Get the ID of the uploaded test file\n",
    "    document_asset_id = client.data_assets.get_id(document_asset_details)\n",
    "    \n",
    "    # Define a connection to the test data\n",
    "    test_data_references = [DataConnection(data_asset_id=document_asset_id)]\n",
    "else:\n",
    "    # Get the asset_id for the matching row\n",
    "    document_asset_id = wx_assets.loc[wx_assets['NAME'] == test_filename, 'ASSET_ID'].iloc[0]\n",
    "    print(f\"Test file: {test_filename} was previously uploaded with asset ID: {document_asset_id}\")\n",
    "    \n",
    "    # Define a connection to the previously uploaded test data\n",
    "    test_data_references = [DataConnection(data_asset_id=document_asset_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Run `AutoAI RAG` Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = AutoAI(credentials, project_id=project_id)\n",
    "rag_optimizer_name = 'DEMO - AutoAI RAG ibm-watsonx-ai SDK documentation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the list of Past `AutoAI RAG` experiment runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>run_id</th>\n",
       "      <th>state</th>\n",
       "      <th>auto_pipeline_optimizer name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-16T16:17:16.389Z</td>\n",
       "      <td>596ddb0f-1bbc-492b-bec5-0a0b4f7bc599</td>\n",
       "      <td>completed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-14T19:46:53.187Z</td>\n",
       "      <td>98804827-00b4-4a08-af0a-38912903bab1</td>\n",
       "      <td>completed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-14T17:27:17.666Z</td>\n",
       "      <td>a23c7ab2-903b-4cf8-92f6-a20986d74099</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-14T16:18:52.696Z</td>\n",
       "      <td>ab3277bb-fe33-417d-b8ea-3b70c0744f2c</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-14T15:59:55.175Z</td>\n",
       "      <td>4145dd5f-94da-425c-85b6-b00e24971cd5</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-14T15:50:56.139Z</td>\n",
       "      <td>85a2cab9-e863-412b-895b-daaebd2fd29d</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-14T14:45:58.774Z</td>\n",
       "      <td>2ec7c054-970d-48e8-bdce-d5ecb91dbbae</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-10T21:26:42.846Z</td>\n",
       "      <td>46f9ac00-3896-419f-97db-6c06b6fd1965</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp                                run_id      state  \\\n",
       "0  2025-01-16T16:17:16.389Z  596ddb0f-1bbc-492b-bec5-0a0b4f7bc599  completed   \n",
       "1  2025-01-14T19:46:53.187Z  98804827-00b4-4a08-af0a-38912903bab1  completed   \n",
       "2  2025-01-14T17:27:17.666Z  a23c7ab2-903b-4cf8-92f6-a20986d74099     failed   \n",
       "3  2025-01-14T16:18:52.696Z  ab3277bb-fe33-417d-b8ea-3b70c0744f2c     failed   \n",
       "4  2025-01-14T15:59:55.175Z  4145dd5f-94da-425c-85b6-b00e24971cd5     failed   \n",
       "5  2025-01-14T15:50:56.139Z  85a2cab9-e863-412b-895b-daaebd2fd29d     failed   \n",
       "6  2025-01-14T14:45:58.774Z  2ec7c054-970d-48e8-bdce-d5ecb91dbbae     failed   \n",
       "7  2025-01-10T21:26:42.846Z  46f9ac00-3896-419f-97db-6c06b6fd1965     failed   \n",
       "\n",
       "                        auto_pipeline_optimizer name  \n",
       "0  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "1  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "2  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "3  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "4  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "5  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "6  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "7  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_experiments = experiment.runs(filter='rag_optimizer').list()\n",
    "past_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the list of past `AutoAI RAG` experiment runs includes a successful run of the `DEMO - AutoAI RAG ibm-watsonx-ai SDK documentation` rag optimizer. \n",
    "- If a successful run is found, load this run from history. \n",
    "- If no successful run of the given rag optimizer is found, then start a new run of this rag optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving previously created RAG Optimizer: DEMO - AutoAI RAG ibm-watsonx-ai SDK documentation, runid: 596ddb0f-1bbc-492b-bec5-0a0b4f7bc599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure the timestamp column is in datetime format\n",
    "past_experiments['timestamp'] = pd.to_datetime(past_experiments['timestamp'])\n",
    "\n",
    "# Filter for rows matching the given optimizer name and not in failed state\n",
    "filtered_experiments = past_experiments[\n",
    "    (past_experiments['auto_pipeline_optimizer name'] == rag_optimizer_name) &\n",
    "    (past_experiments['state'] != 'failed')\n",
    "]\n",
    "\n",
    "if filtered_experiments.empty:\n",
    "    print(f\"No runs found for optimizer '{rag_optimizer_name}' in a non-failed state.\")\n",
    "    \n",
    "    print(f'create and run a new RAG Optimizer: {rag_optimizer_name}')\n",
    "    # create a new experiment\n",
    "    rag_optimizer = experiment.rag_optimizer(\n",
    "        name=rag_optimizer_name,\n",
    "        description=\"AutoAI RAG Optimizer for Db2 AI Blogs\",\n",
    "        max_number_of_rag_patterns=4,\n",
    "        optimization_metrics=[AutoAI.RAGMetrics.ANSWER_CORRECTNESS]\n",
    "    )\n",
    "    \n",
    "    rag_optimizer.run(\n",
    "        input_data_references=train_data_references,\n",
    "        test_data_references=test_data_references,\n",
    "        background_mode=False\n",
    "    )\n",
    "    \n",
    "    print(f'status of RAG Optimizer: {rag_optimizer_name} is {rag_optimizer.get_run_status()}')\n",
    "else:\n",
    "    # Sort the filtered dataframe by timestamp in descending order\n",
    "    sorted_experiments = filtered_experiments.sort_values(by='timestamp', ascending=False)\n",
    "\n",
    "    # Get the run_id of the most recent run\n",
    "    most_recent_run_id = sorted_experiments.iloc[0]['run_id']\n",
    "        \n",
    "     # get the previously completed experiment with the same name as experiment_name\n",
    "    print(f'Retrieving previously created RAG Optimizer: {rag_optimizer_name}, runid: {most_recent_run_id}')\n",
    "    \n",
    "     # Get the historical rag_optimizer instance and training details\n",
    "    rag_optimizer = experiment.runs.get_rag_optimizer(most_recent_run_id)\n",
    "\n",
    "summary = rag_optimizer.summary(scoring=\"faithfulness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the list of `RAG patterns` from the successful run of rag optimizer: `DEMO - AutoAI RAG ibm-watsonx-ai SDK documentation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_faithfulness</th>\n",
       "      <th>mean_answer_correctness</th>\n",
       "      <th>mean_context_correctness</th>\n",
       "      <th>chunking.method</th>\n",
       "      <th>chunking.chunk_size</th>\n",
       "      <th>chunking.chunk_overlap</th>\n",
       "      <th>embeddings.model_id</th>\n",
       "      <th>vector_store.distance_metric</th>\n",
       "      <th>retrieval.method</th>\n",
       "      <th>retrieval.number_of_chunks</th>\n",
       "      <th>generation.model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pattern2</th>\n",
       "      <td>0.8654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>window</td>\n",
       "      <td>5</td>\n",
       "      <td>meta-llama/llama-3-1-70b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern5</th>\n",
       "      <td>0.8281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>cosine</td>\n",
       "      <td>window</td>\n",
       "      <td>3</td>\n",
       "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern4</th>\n",
       "      <td>0.8182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>cosine</td>\n",
       "      <td>window</td>\n",
       "      <td>5</td>\n",
       "      <td>meta-llama/llama-3-70b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern1</th>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>window</td>\n",
       "      <td>5</td>\n",
       "      <td>meta-llama/llama-3-70b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern3</th>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>simple</td>\n",
       "      <td>5</td>\n",
       "      <td>meta-llama/llama-3-1-70b-instruct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean_faithfulness  mean_answer_correctness  \\\n",
       "Pattern_Name                                               \n",
       "Pattern2                 0.8654                      1.0   \n",
       "Pattern5                 0.8281                      1.0   \n",
       "Pattern4                 0.8182                      1.0   \n",
       "Pattern1                 0.5216                      0.5   \n",
       "Pattern3                 0.1837                      0.5   \n",
       "\n",
       "              mean_context_correctness chunking.method  chunking.chunk_size  \\\n",
       "Pattern_Name                                                                  \n",
       "Pattern2                           1.0       recursive                 1024   \n",
       "Pattern5                           1.0       recursive                 1024   \n",
       "Pattern4                           1.0       recursive                 1024   \n",
       "Pattern1                           1.0       recursive                  512   \n",
       "Pattern3                           1.0       recursive                 1024   \n",
       "\n",
       "              chunking.chunk_overlap             embeddings.model_id  \\\n",
       "Pattern_Name                                                           \n",
       "Pattern2                         256  intfloat/multilingual-e5-large   \n",
       "Pattern5                         512  intfloat/multilingual-e5-large   \n",
       "Pattern4                         256  intfloat/multilingual-e5-large   \n",
       "Pattern1                         256    ibm/slate-125m-english-rtrvr   \n",
       "Pattern3                         256  intfloat/multilingual-e5-large   \n",
       "\n",
       "             vector_store.distance_metric retrieval.method  \\\n",
       "Pattern_Name                                                 \n",
       "Pattern2                        euclidean           window   \n",
       "Pattern5                           cosine           window   \n",
       "Pattern4                           cosine           window   \n",
       "Pattern1                        euclidean           window   \n",
       "Pattern3                        euclidean           simple   \n",
       "\n",
       "              retrieval.number_of_chunks                generation.model_id  \n",
       "Pattern_Name                                                                 \n",
       "Pattern2                               5  meta-llama/llama-3-1-70b-instruct  \n",
       "Pattern5                               3   meta-llama/llama-3-1-8b-instruct  \n",
       "Pattern4                               5    meta-llama/llama-3-70b-instruct  \n",
       "Pattern1                               5    meta-llama/llama-3-70b-instruct  \n",
       "Pattern3                               5  meta-llama/llama-3-1-70b-instruct  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the details of the best `RAG` pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pattern is: Pattern2\n",
      "mean_faithfulness                                          0.8654\n",
      "mean_answer_correctness                                       1.0\n",
      "mean_context_correctness                                      1.0\n",
      "chunking.method                                         recursive\n",
      "chunking.chunk_size                                          1024\n",
      "chunking.chunk_overlap                                        256\n",
      "embeddings.model_id                intfloat/multilingual-e5-large\n",
      "vector_store.distance_metric                            euclidean\n",
      "retrieval.method                                           window\n",
      "retrieval.number_of_chunks                                      5\n",
      "generation.model_id             meta-llama/llama-3-1-70b-instruct\n",
      "Name: Pattern2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "best_pattern_name = summary.index.values[0]\n",
    "print('Best pattern is:', best_pattern_name)\n",
    "\n",
    "print(summary.loc[best_pattern_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the best pattern from the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/db2inst1/watson-machine-learning-samples/.venv/lib/python3.12/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:415: LifecycleWarning: Model 'meta-llama/llama-3-1-70b-instruct' is in deprecated state from 2025-01-22 until 2025-05-30. IDs of alternative models: llama-3-3-70b-instruct, llama-3-2-90b-vision-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warnings.warn(\n",
      "/home/db2inst1/watson-machine-learning-samples/.venv/lib/python3.12/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:415: LifecycleWarning: Model 'meta-llama/llama-3-1-70b-instruct' is in deprecated state from 2025-01-22 until 2025-05-30. IDs of alternative models: llama-3-3-70b-instruct, llama-3-2-90b-vision-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_pattern = rag_optimizer.get_pattern(pattern_name=best_pattern_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Vector Index Using the best pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download My 3 articles, chunk and vectorize them using the best `RAG` pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://community.ibm.com/community/user/datamanagement/blogs/shaikh-quader/2024/05/07/building-an-in-db-linear-regression-model-with-ibm\",\n",
    "    \"https://www.ibm.com/blog/how-to-build-a-decision-tree-model-in-ibm-db2/\",\n",
    "    \"https://community.ibm.com/community/user/datamanagement/blogs/shaikh-quader/2024/05/27/db2ai-pyudf\"\n",
    "]\n",
    "docs_list = WebBaseLoader(urls).load()\n",
    "doc_splits = best_pattern.chunker.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of chunks created from the above 3 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an in-memory vector index, using the above chunks, with `Chromadb` and the best rag pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4516f52d08be4c1c7db464e853ffe18df646aebf47ef5b749f93c928b6ea4d91',\n",
       " '4861beecc81b2a91bb60cc5cc0225cd7965d770052e73805f292fb2b0d8bca94',\n",
       " '9ebbf2a649e7c4596e56f94378f6f917b11095abc515da5322865f64b53c640f',\n",
       " '0654d621300703203c90bbd756a5744d9e30e590e26ceaf9a37c544488557ee7',\n",
       " 'ba30dab400e9b61a67805d3a220b4b551e3618fa92100282cd0a030aef8a178f',\n",
       " '9ec4d827f923d09d121fb90c00659f6eb2793ceaffa60be9d2d32d8907479622',\n",
       " 'e9ca0a491a4c7faea7eebccc2d9192fbb4e70609a1f8aa233a421ee8a58022ef',\n",
       " 'fc94701031cfe7f8491b5681434b2e480bb0ea7684661dd438dcd7a961d47004',\n",
       " '2a25ba26d558b1bb27701436f8fbd4a9518a4b7e582ef07422c9eb6c109a8208',\n",
       " 'bc7acc8e020ab42a9789c3dcc0ab6161dd9889f92c2c5ca709d6b8ff83c1e065',\n",
       " '8d9fafd4f0e65d45b00ec79723add359a01037db2332238784838eab2a89e4df',\n",
       " 'b68b937cbb0418cbadd1e266f4d2eba56856c7f213ad5ea7e0e54b8e70c87792',\n",
       " 'df9c25b21293bcc0b3fc4133c0548cf9891a208b23d1237157a9a206ad6c34c2',\n",
       " '91b7eb9a85ccecdd2793aa5282917723b1744b88d0c3b4cce305d5e934847adf',\n",
       " 'ada38812c2b68dd1a9f2be8360dc418699f1fc40b1fe81b995c2097c772a9b61',\n",
       " 'fd332a7b17a1676e0660b17463c5a24b625d7fdc72ae71511357fc44815450d2',\n",
       " 'da4246ace053ce043a98663a3d720fe56aa731098c61f4e7ead4fc0445158c9e',\n",
       " '2a38a05b4b644ac6d987bd32a49c1c39c6ee4e3963af0241b7c68af364a99a38',\n",
       " '862f2358c350e2ba9c3c9a71c8ea94fac3b79f6e065ac0156bd23555b8723c8b',\n",
       " 'f393f5d7b482c8ed4c09e5d51365cd6a183ee68b894e6c09b27fb906c610fc81',\n",
       " '4358c3710cc9dfefbb28ef76214bfd3cbc1f70b329fb99aab072d19b9c613865',\n",
       " 'c7f93afe209757ed3ac346ff475dd8c88385a271515eab3ef6f23247dc996982',\n",
       " '6ea27a6aca07fd8f59816ed7b8c2f33031754a35e08db053235b67729fa4c91e',\n",
       " '2d8b7cdda0829f160f02f41aa40a679a81aa9af0230667ef09ce62490d9a341c',\n",
       " 'f75b7dcad612fb5a822c17def26ad6337383b2f0943aace63d9a6a068de1cb55',\n",
       " '6727044ba2127bbf3d83d569ffd80c97055dbe900bc7e1ea1f3ad229f105e05d',\n",
       " '8ba821b81c9d12972b8c65378acf72c3a0fde55b97529f6c219996dd5a3f1fa6',\n",
       " 'd69291ef44710da72a1ed5b843ccfca81a9be01a13a076c2cc721cf0ff0a115c',\n",
       " '2976222f9478866c7c9cc6cd94882756ce97b0645596fb0bcc6469df34bad7cf',\n",
       " '8d756e8d5f4d9703f1ec59d6cd6ec7db951904ec7188a49477bc53bc68fc5c70',\n",
       " 'f6f6447be67a5aede492fe3c99c258818f9493d90997a56fe4953888cc31fbd9',\n",
       " 'cd64a6300f51b3bc97a8c075a22d49d1434ec277cd5b31910f6eac979e2bbc79',\n",
       " '77f483f5dc0ceed92cbd948a7747ab43dff7e7bb55c65d8abc1720ad652ade4a',\n",
       " '48a59dec7dd547c6e96cc9d1891559946c3eaf4e027d92d6bc942af805e5051b',\n",
       " 'de660e76f3b3af0e6b0f4e4055b6588f9737c7d244be39f00afe3ba6d77075a6',\n",
       " '2479e4ffc26cae6e5b6c834173efb726ad9f6b7b0cc7fcb4ff4c2d114ce1cc0d',\n",
       " '6883b46df5e8abf97ccf147e7b8876ee154bee5fb8de4130cb9db76804a386a7',\n",
       " 'df21b52c7098473de2f470aa7e25ca94cb217f89bd6f92b7c4cb95367940b4a7',\n",
       " 'f8b6b29585086bfab8bd3cd87f7a67ca02b6d2ff5875bea23b992daf3a2c21c2',\n",
       " '62145a10f459a97acd78915255c57eef521f98723134c49a5746425c10c3fbcc',\n",
       " 'cd237600f361c0999a7bd8792f938e4dc6feb6f765f54844cd84e771fdc1a735',\n",
       " 'eb58bd4fb91224c773f67783aa174bf85994f7bf357fe65f7d566636624df49b',\n",
       " '19e8c4189035f730059e0601773f9c3519fc921efe89adc42fcb0967dbf49fae',\n",
       " 'a5a261d54378c8085b4c22752089d5c5933980e3ec50318418fa8083be277bc6',\n",
       " '8346196d7fc2033b73ad441f267f4a1344d66da076883e8655fa91299814dffe',\n",
       " 'de00c5d1c2336fea7e5a5329f0068c242a109480a576905ae31a49c83048e899',\n",
       " 'e4e3d29faba78d701ed0e953093d4502329c3c9b4265f4f0961ee338047f8ba4',\n",
       " 'b6bcc2e57074c4d14b845ffccfa01514fc039097a0676fb473477d69757e3333',\n",
       " '756575e9992d173adec98d51a9044d2e5da82ead10d7ee11e2cc8bfaa975ba97',\n",
       " 'c2fc2ae4df64344f8ca4417f9828a974e96d6495246633b41248e7e4c48a774f',\n",
       " 'ca03b9104bc9ccb8414b5145c908722f03b3e92579a59734fdb7f77f86ad4437',\n",
       " 'adc29c95da4971c1a2e167d992310f6b30f0c1db706916fd412a9c1906ff962f',\n",
       " '750f8cf6bbfa236e0e5b36dc79c9f1afc816f5712d9b07587e45dbf3a0a055ed',\n",
       " '69435449a232b139c8406e2831ab0b7ddf620bb4aecfe9eebe69634a0c24c450',\n",
       " '46a2d198da0d5d868a3794c9324ec66dfeff3a3ec72e68a1726b84089918cd09',\n",
       " 'e1c150642018ce13eff9831165cc47a67ddcb8329c65062e694247829262eef5',\n",
       " '69ff013dddb71a1fd6fb1074de5b0ab1399631fb9897494dc9b0a81549f0e559',\n",
       " '67180186278582640289dcc0d07decf3c6543f96ea75cf4890d1c5864b7f8a0a',\n",
       " '17858156ca0098d139e9d2659de98c381e88ea425556b24462918e0c5ab69337',\n",
       " '130fda486af39645e50df095466818f79339bbafee13d28f250c67a21bc6b787',\n",
       " 'b9e001bba1d8ee6dae27d630539d59513a3b9f9a9f54b046e6ef1e6dbc7a85e3',\n",
       " '518edcbc8ada60079196c5e130ef85c3c2a77c1159503a52d806f95e7762101f',\n",
       " 'b3d390bf87cacd9f1c8ae6ae3694376edb82832bc64151ab00242545f1faf117',\n",
       " '4fde9a218f9686d78f43063f8c20dd6bd4428637baf6087b61cf140b0f617ab9',\n",
       " '5a0e6580713c5578c20826d7bc767ea56476bbb9d8fd8fe91865dd04f75b72e4',\n",
       " 'd16243064053f7a3a3205ff29ba30d29dbcdbc8a892fde9b4ca5e5c0aaa468b8',\n",
       " '0fe87d9bbd3e01d9028baf95c4cbeb5fd3f092f0e10b9f5f5290e4da226e832f',\n",
       " '71277ba4f4069d69aaf3da3d4d9de71efd90d8af5444601fd26fee7c2cc8dc0e',\n",
       " '5fc443b8f4631501489454f770233dc811fd1a002f8caaa82a24d5cef1b4e1a8',\n",
       " 'c6dec2b043d09158fb09e9b14da187a493c14237d2bed683c8247c90f9286e7a',\n",
       " 'c9e93d2328cbd4fbe49f2d0a89068ce8ee404280c0a03a44e14b41213c758de4',\n",
       " '7531f91d4cf2c688b900c7c0f87d492b7a3679506ac5781d93428e71dba6a02b',\n",
       " '933ef0bcc9dfa5870dc8b4f605f1d7e6e5dfb0fe45ce7152b4aaccf1f306a78d',\n",
       " '7f373eac1f3ccc6aca4c75cea941d518f2a16569437b0c45af882575b4991fee',\n",
       " 'c280c928a916f4bdd871c00729a06450bed5674401a28b4ceb9051b410341c78',\n",
       " '4e67a4407363683b693b630acc5ad581bd43413f41d7d508a286188ea10667b1',\n",
       " '2922eb93883e68edd0dc2c75b1ca0e3359c34d05d6ab8de6a53ab98a9cdc1997',\n",
       " 'e258888516ec34895b1020aaed95a387685fe02de311574c5f3f858554301eb7',\n",
       " 'ac350c95b16cfc96c178c1cbaddffc7af00ebf337e414b8596e0f73a5051e60c',\n",
       " 'a843044b7870e16b5fb9c1d7c88e639c6d0509eabbc73df09f2ca49420474b1c',\n",
       " '6656c0e2514f1e9d09777b7bcca20568666acd898c369a63c00b051c72a6452d',\n",
       " '2579513edc81c35c3536fec26034270794230a0fc692540887dd6b8a6ba5757d',\n",
       " '1a6ac993ba55a9857caf871fadc3c9432d464a003106e51a2530ec4ffeb21481',\n",
       " 'ac8c655d864415018ddda639c82ca31ac7fe6d7390db5e96a4de8e047c3ecf9e',\n",
       " '46d618225cf6611d4adc053026bbdc1ea053292609a4e096128b9116b129bc8c',\n",
       " '85234a7498e2998709015d90541b40353d7141bda9980305ab88180d133de204',\n",
       " 'ca55dc238456c0e9fee095b01d1a11ed46edce6d71e34ebf57d4b2f2fe8005d1',\n",
       " '9f3108d5d7273e24cc24c9cb853c2e6d06b944e7cf5b27ebdfdbef8c0f6467bb',\n",
       " '970b9980d4a411f8d4ecb6019678def53d3a2ccd45f69996a8d2e94d2d6b42c2',\n",
       " 'ad15e0dc804bbb99d29e2a09a4e64ca8c0ea3f40d907b9087c9e29ac4d26e178']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pattern.indexing_function(doc_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask Questions from Indexed Articles Using the Best RAG Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`First Question`: How to generate summary statistics for a Db2 table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "To generate summary statistics for a Db2 table, you can use the `SUMMARY1000` stored procedure (SP). The syntax is as follows:\n",
       "\n",
       "`CALL IDAX.SUMMARY1000('intable=table_name, outtable=output_table_name')`\n",
       "\n",
       "Replace `table_name` with the name of the input table from which you want to collect statistics, and `output_table_name` with the name of the table where you want to store the gathered statistics.\n",
       "\n",
       "The `SUMMARY1000` SP will create additional output tables for each column type (e.g., `output_table_name_NUM` for numeric columns and `output_table_name_CHAR` for nominal columns). These tables will contain summary statistics such as count, average, variance, standard deviation, skewness, and excess kurtosis for numeric columns, and count, distinct values, and frequency for nominal columns."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [\"How to generate summary statistics for a Db2 table?\"]\n",
    "\n",
    "payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"values\": questions,\n",
    "            \"access_token\": client.service_instance._get_token()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_response = best_pattern.inference_function()(payload)\n",
    "Markdown(score_response[\"predictions\"][0][\"values\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Second Question`: `How can one inference a Python model with Db2?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "To inference a Python model with Db2, you can deploy the trained model on a secure Db2 server using a Python user-defined function. This allows you to generate predictions effortlessly with SQL queries. You can make predictions directly inside Db2 using simple SQL queries. The Python model can be deployed on Db2 using a Python User-Defined Function, and then you can use SQL queries to generate predictions from the deployed model. The SQL query can input rows from a test table into the model, and the model will output a table with the predictions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [\"How can one inference a Python model with Db2?\"]\n",
    "\n",
    "payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"values\": questions,\n",
    "            \"access_token\": client.service_instance._get_token()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_response = best_pattern.inference_function()(payload)\n",
    "Markdown(score_response[\"predictions\"][0][\"values\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Third Question`: `How to integrate a Python model with Db2?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "According to the document, you can integrate a Python model with Db2 by deploying the trained Python model on a secure Db2 server using a Python user-defined function. This allows you to generate predictions effortlessly with SQL queries. The steps to do this include:\n",
       "\n",
       "1. Loading the training dataset from a Db2 database table into a Python Jupyter notebook.\n",
       "2. Preprocessing the data to transform raw input features into a final feature set.\n",
       "3. Creating a machine learning pipeline using scikit-learn with a logistic regression algorithm.\n",
       "4. Training the pipeline using the training dataset and evaluating the model's quality.\n",
       "5. Deploying the trained model on Db2 using a Python User-Defined Function.\n",
       "6. Generating predictions from the deployed model via SQL.\n",
       "\n",
       "These steps are contained within a single notebook, showing the end-to-end workflow of data loading, data transformation, model training, model evaluation, and model inferencing and deployment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [\"How to integrate a Python model with Db2?\"]\n",
    "\n",
    "payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"values\": questions,\n",
    "            \"access_token\": client.service_instance._get_token()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_response = best_pattern.inference_function()(payload)\n",
    "Markdown(score_response[\"predictions\"][0][\"values\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Fourth Question`: `What is Python UDF?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "A Python User-Defined Function (UDF) is a function written in Python that can be used in SQL queries to perform specific tasks or calculations. In the context of the provided document, a Python UDF is used to deploy a trained machine learning model on a Db2 database, allowing users to generate predictions from the model using SQL queries. The UDF loads the trained model, collects input rows, makes predictions, and returns the results as a table."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [\"What is Python UDF?\"]\n",
    "\n",
    "payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"values\": questions,\n",
    "            \"access_token\": client.service_instance._get_token()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_response = best_pattern.inference_function()(payload)\n",
    "Markdown(score_response[\"predictions\"][0][\"values\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn More"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Automating a RAG pattern with AutoAI (watxonx doc)](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-programming-rag.html?context=wx)\n",
    "2. [AutoAI RAG Sample Notebooks (Github)](https://github.com/IBM/watson-machine-learning-samples/tree/master/cloud/notebooks/python_sdk/experiments/autoai_rag)\n",
    "3. [AutoAI Python SDK](https://ibm.github.io/watsonx-ai-python-sdk/autoai.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
