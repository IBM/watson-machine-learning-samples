{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Use watsonx.ai python SDK to manage Prompt Template assets and create deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Disclaimers\n",
    "\n",
    "- Use only Projects and Spaces that are available in watsonx context.\n",
    "\n",
    "\n",
    "## Notebook content\n",
    "\n",
    "This notebook contains the steps and code to demonstrate support for Prompt Template inference and their deployments.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "\n",
    "## Learning goal\n",
    "\n",
    "The goal of this notebook is to demonstrate how to create a Prompt Template asset and deployment pointing on it. In general, a Prompt Template is a pattern for generating prompts for language models. A template may contain instruction, input/output prefixes, few-shot examples and appropriate context that may vary depending on different tasks.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Prompt Template Inference](#prompt)\n",
    "- [Prompt Template Deployment](#deployment)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Contact with your Cloud Pack for Data administrator and ask him for your account credentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install and import the `ibm-watsonx-ai` and dependecies\n",
    "**Note:** `ibm-watsonx-ai` documentation can be found <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/index.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U ibm-watsonx-ai | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to WML\n",
    "\n",
    "Authenticate the Watson Machine Learning service on IBM Cloud Pack for Data. You need to provide platform `url`, your `username` and `api_key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'PASTE YOUR USERNAME HERE'\n",
    "api_key = 'PASTE YOUR API_KEY HERE'\n",
    "url = 'PASTE THE PLATFORM URL HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    username=username,\n",
    "    api_key=api_key,\n",
    "    url=url,\n",
    "    instance_id=\"openshift\",\n",
    "    version=\"5.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can use `username` and `password` to authenticate WML services.\n",
    "\n",
    "```python\n",
    "credentials = Credentials(\n",
    "    username=***,\n",
    "    password=***,\n",
    "    url=***,\n",
    "    instance_id=\"openshift\",\n",
    "    version=\"5.0\"\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the project id\n",
    "The Prompt Template requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"prompt\"></a>\n",
    "## Prompt Template on `watsonx.ai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models.prompts import PromptTemplateManager, PromptTemplate\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes, DecodingMethods, PromptTemplateFormats\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Instantiate PromptTemplateManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prompt_mgr = PromptTemplateManager(\n",
    "    credentials=credentials,\n",
    "    project_id=project_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create a Prompt Template object and store it in the project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use a `PromptTemplate` object to store the properties of a newly created prompt template. Prompt text is composed of the instruction, input/output prefixes, few-shot examples and input text. All of the mentioned fields may contain placeholders (`{...}`) with input variables and for the template to be valid, these input variables must be also specified in `input_variables` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(name=\"New prompt\",\n",
    "                                 model_id=ModelTypes.FLAN_T5_XXL,\n",
    "                                 model_params = {GenParams.DECODING_METHOD: \"sample\"},\n",
    "                                 description=\"My example\",\n",
    "                                 task_ids=[\"generation\"],\n",
    "                                 input_variables=[\"object\"],\n",
    "                                 instruction=\"Answer on the following question\",\n",
    "                                 input_prefix=\"Human\",\n",
    "                                 output_prefix=\"Assistant\",\n",
    "                                 input_text=\"What is {object} and how does it work?\",\n",
    "                                 examples=[[\"What is a loan and how does it work?\", \n",
    "                                            \"A loan is a debt that is repaid with interest over time.\"]]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using `store_prompt(prompt_template_id)` method, one can store newly created prompt template in your ptoject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stored_prompt_template = prompt_mgr.store_prompt(prompt_template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset id: 4ad15484-5551-487c-8c19-89ff8e2765cd\n",
      "Is it a template?: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Asset id: {stored_prompt_template.prompt_id}\")\n",
    "print(f\"Is it a template?: {stored_prompt_template.is_template}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also store a template which is a `langchain` Prompt Template object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset id: d95b55e3-7946-43f1-a0c0-556c15d8c3a2\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate as LcPromptTemplate\n",
    "\n",
    "langchain_prompt_template = LcPromptTemplate(template=\"What is {object} and how does it work?\",\n",
    "                                             input_variables=[\"object\"])\n",
    "stored_prompt_template_lc = prompt_mgr.store_prompt(prompt_template=langchain_prompt_template)\n",
    "print(f\"Asset id: {stored_prompt_template_lc.prompt_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Manage Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>CREATED</th>\n",
       "      <th>LAST MODIFIED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d95b55e3-7946-43f1-a0c0-556c15d8c3a2</td>\n",
       "      <td>My prompt</td>\n",
       "      <td>2024-04-23T14:36:25Z</td>\n",
       "      <td>2024-04-23T14:36:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4ad15484-5551-487c-8c19-89ff8e2765cd</td>\n",
       "      <td>New prompt</td>\n",
       "      <td>2024-04-23T14:36:07Z</td>\n",
       "      <td>2024-04-23T14:36:07Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID        NAME               CREATED  \\\n",
       "0  d95b55e3-7946-43f1-a0c0-556c15d8c3a2   My prompt  2024-04-23T14:36:25Z   \n",
       "1  4ad15484-5551-487c-8c19-89ff8e2765cd  New prompt  2024-04-23T14:36:07Z   \n",
       "\n",
       "          LAST MODIFIED  \n",
       "0  2024-04-23T14:36:25Z  \n",
       "1  2024-04-23T14:36:07Z  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_mgr.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To retrive Prompt Template asset from project and return string that contains Prompt Template input we use `load_prompt(prompt_template_id, astype=...)`. Returned input string is composed of the fields: `instruction`, `input_prefix`, `output_prefix`, `examples` and `input_text`. After substituting prompt variables, one can evaluate a language model on the obtained string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer on the following question\n",
      "\n",
      "Human What is a loan and how does it work?\n",
      "Assistant A loan is a debt that is repaid with interest over time.\n",
      "\n",
      "Human What is {object} and how does it work?\n",
      "Assistant\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt_mgr.load_prompt(prompt_id=stored_prompt_template.prompt_id, astype=PromptTemplateFormats.STRING)\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To update Prompt Template data use `prompt_mgr.update_prompt` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer on the following question in a concise way.\n",
      "\n",
      "Human What is a loan and how does it work?\n",
      "Assistant A loan is a debt that is repaid with interest over time.\n",
      "\n",
      "Human What is {object} and how does it work?\n",
      "Assistant\n"
     ]
    }
   ],
   "source": [
    "prompt_with_new_instruction = PromptTemplate(instruction=\"Answer on the following question in a concise way.\")\n",
    "prompt_mgr.update_prompt(prompt_id=stored_prompt_template.prompt_id, \n",
    "                         prompt_template=prompt_with_new_instruction)\n",
    "prompt_text = prompt_mgr.load_prompt(prompt_id=stored_prompt_template.prompt_id, astype=PromptTemplateFormats.STRING)\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Furthermore, to get information about locked state of Prompt Template run following method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'locked': True, 'locked_by': '1000330999', 'lock_type': 'edit'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_mgr.get_lock(prompt_id=stored_prompt_template.prompt_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using `lock` or `unlock` method, one can change locked state of Prompt Template asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'locked': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_mgr.unlock(prompt_id=stored_prompt_template_lc.prompt_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once the prompt template is unlocked it can be deleted. You can also use the `list` method to check the available prompt templates (passing `limit=2` parameter will return only 2 recently created templates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id of the Prompt Template asset that will be deleted: d95b55e3-7946-43f1-a0c0-556c15d8c3a2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>CREATED</th>\n",
       "      <th>LAST MODIFIED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ad15484-5551-487c-8c19-89ff8e2765cd</td>\n",
       "      <td>New prompt</td>\n",
       "      <td>2024-04-23T14:36:07Z</td>\n",
       "      <td>2024-04-23T14:36:36Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID        NAME               CREATED  \\\n",
       "0  4ad15484-5551-487c-8c19-89ff8e2765cd  New prompt  2024-04-23T14:36:07Z   \n",
       "\n",
       "          LAST MODIFIED  \n",
       "0  2024-04-23T14:36:36Z  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Id of the Prompt Template asset that will be deleted: {stored_prompt_template_lc.prompt_id}\")\n",
    "prompt_mgr.delete_prompt(prompt_id=stored_prompt_template_lc.prompt_id)\n",
    "prompt_mgr.list(limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"deployment\"></a>\n",
    "## Deployment pointing to Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To create deployment pointing to a Prompt template asset we have to initialized `APIClient` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "client = APIClient(wml_credentials=credentials)\n",
    "client.set.default_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the deployment exmaple we will use the prompt with the following input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer on the following question in a concise way.\n",
      "\n",
      "Human What is a loan and how does it work?\n",
      "Assistant A loan is a debt that is repaid with interest over time.\n",
      "\n",
      "Human What is {object} and how does it work?\n",
      "Assistant\n"
     ]
    }
   ],
   "source": [
    "prompt_input_text = prompt_mgr.load_prompt(prompt_id=stored_prompt_template.prompt_id, \n",
    "                                           astype=PromptTemplateFormats.STRING)\n",
    "print(prompt_input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we create deployment providing the id of Prompt Template asset and meta props. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '4ad15484-5551-487c-8c19-89ff8e2765cd' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "initializing\n",
      "Note: online_url is deprecated and will be removed in a future release. Use serving_urls instead.\n",
      "\n",
      "ready\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='12a0675a-5c53-4bef-a308-0250390e4805'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"SAMPLE DEPLOYMENT PROMPT TEMPLATE\",\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
    "    client.deployments.ConfigurationMetaNames.BASE_MODEL_ID: \"ibm/granite-13b-chat-v2\"}\n",
    "\n",
    "deployment_details = client.deployments.create(artifact_uid=stored_prompt_template.prompt_id, meta_props=meta_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ---------------------------------  -----  ------------------------  ----------------  ----------  ----------------\n",
      "GUID                                  NAME                               STATE  CREATED                   ARTIFACT_TYPE     SPEC_STATE  SPEC_REPLACEMENT\n",
      "12a0675a-5c53-4bef-a308-0250390e4805  SAMPLE DEPLOYMENT PROMPT TEMPLATE  ready  2024-04-23T14:37:59.762Z  foundation_model\n",
      "------------------------------------  ---------------------------------  -----  ------------------------  ----------------  ----------  ----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GUID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CREATED</th>\n",
       "      <th>ARTIFACT_TYPE</th>\n",
       "      <th>SPEC_STATE</th>\n",
       "      <th>SPEC_REPLACEMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12a0675a-5c53-4bef-a308-0250390e4805</td>\n",
       "      <td>SAMPLE DEPLOYMENT PROMPT TEMPLATE</td>\n",
       "      <td>ready</td>\n",
       "      <td>2024-04-23T14:37:59.762Z</td>\n",
       "      <td>foundation_model</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   GUID                               NAME  \\\n",
       "0  12a0675a-5c53-4bef-a308-0250390e4805  SAMPLE DEPLOYMENT PROMPT TEMPLATE   \n",
       "\n",
       "   STATE                   CREATED     ARTIFACT_TYPE SPEC_STATE  \\\n",
       "0  ready  2024-04-23T14:37:59.762Z  foundation_model              \n",
       "\n",
       "  SPEC_REPLACEMENT  \n",
       "0                   "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Substitute prompt variables and generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "deployment_id = deployment_details.get(\"metadata\", {}).get(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: online_url is deprecated and will be removed in a future release. Use serving_urls instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A mortgage is a loan that is used to buy a house.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deployments.generate_text(deployment_id, params={\"prompt_variables\": {\"object\": \"a mortgage\"},\n",
    "                                                        GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "                                                        GenParams.STOP_SEQUENCES: ['\\n\\n'],\n",
    "                                                        GenParams.MAX_NEW_TOKENS: 50})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate text using ModelInference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can also generate text based on your Prompt Template deployment using `ModelInference` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_inference = ModelInference(deployment_id=deployment_id, \n",
    "                                 credentials=credentials, \n",
    "                                 project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A mortgage is a loan that is used to buy a house.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference.generate_text(params={\"prompt_variables\": {\"object\": \"a mortgage\"},\n",
    "                                      GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "                                      GenParams.STOP_SEQUENCES: ['\\n\\n'],\n",
    "                                      GenParams.MAX_NEW_TOKENS: 50})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary and next steps\n",
    "\n",
    " You successfully completed this notebook!.\n",
    " \n",
    " You learned how to create valid Prompt Template and store it in watsonx.ai project. Furthermore, you also learned how to create deployment pointing to a Prompt Template asset and generate text using base model.\n",
    " \n",
    " Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Authors\n",
    "\n",
    "**Mateusz Świtała**, Software Engineer at Watson Machine Learning.\n",
    "\n",
    "**Mateusz Szewczyk**, Software Engineer at Watson Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright © 2023, 2024 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
