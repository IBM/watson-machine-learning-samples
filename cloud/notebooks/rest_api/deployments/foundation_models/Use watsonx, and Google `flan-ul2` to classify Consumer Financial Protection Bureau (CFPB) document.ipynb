{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and Google `google/flan-ul2` to classify consumer financial protection bureau document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook contains the steps and code to demonstrate support of complaint classification in watsonx. It introduces commands for data retrieval and model testing.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The goal of this notebook is to demonstrate how to use `google/flan-ul2` model to Consumer Financial Protection Bureau (CFPB) document.\n",
        "\n",
        "## Use case & dataset\n",
        "The Consumer Financial Protection Bureau (CFPB) is a federal U.S. agency that acts as a mediator when disputes arise between financial institutions and consumers. Via a web form, consumers can send the agency a narrative of their dispute. A foundation model would make the classification of complaints and their routing to the appropriate teams more efficient than manually tagged complaints.\n",
        "Dataset has narrative and 5 product categories as follow:\n",
        "\n",
        "* credit reporting\n",
        "* debt collection\n",
        "* mortgages and loans \n",
        "* credit cards\n",
        "* retail banking\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Data loading](#data)\n",
        "- [Foundation Models on watsonx](#models)\n",
        "- [Model testing](#predict)\n",
        "- [Score](#score)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "##  Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install and import the `datasets` and dependecies\n",
        "you need to install below required dependencies to be able to continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install datasets | tail -n 1\n",
        "!pip install requests | tail -n 1\n",
        "!pip install wget | tail -n 1\n",
        "!pip install pandas | tail -n 1\n",
        "!pip install ibm-cloud-sdk-core | tail -n 1\n",
        "!pip install \"scikit-learn==1.3.2\" | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, getpass, wget\n",
        "import requests\n",
        "from ibm_cloud_sdk_core import IAMTokenManager\n",
        "from pandas import value_counts, read_csv, DataFrame\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inferencing class\n",
        "This cell defines a class that makes a REST API call to the watsonx Foundation Model\n",
        "inferencing API that we will use to generate output from the provided input.\n",
        "The class takes the access token created in the previous step, and uses it to\n",
        "make a REST API call with input, model id and model parameters. The response\n",
        "from the API call is returned as the cell output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Action:** Provide watsonx.ai Runtime url to work with watsonx.ai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint_url = input(\"Please enter your watsonx.ai Runtime endpoint url (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a `Prompt` class for prompts generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Prompt:\n",
        "    def __init__(self, access_token, project_id):\n",
        "        self.access_token = access_token\n",
        "        self.project_id = project_id\n",
        "\n",
        "    def generate(self, input, model_id, parameters):\n",
        "        wml_url = f\"{endpoint_url}/ml/v1/text/generation?version=2024-03-19\"\n",
        "        Headers = {\n",
        "            \"Authorization\": \"Bearer \" + self.access_token,\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Accept\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model_id\": model_id,\n",
        "            \"input\": input,\n",
        "            \"parameters\": parameters,\n",
        "            \"project_id\": self.project_id\n",
        "        }\n",
        "        response = requests.post(wml_url, json=data, headers=Headers)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()[\"results\"][0]\n",
        "        else:\n",
        "            return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### watsonx API connection\n",
        "This cell defines the credentials required to work with watsonx API for Foundation\n",
        "Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"IBM Cloud user API key\">documentation</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "access_token = IAMTokenManager(\n",
        "    apikey = getpass.getpass(\"Please enter your watsonx.ai api key (hit enter): \"),\n",
        "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
        ").get_token()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the project id\n",
        "The API requires project id that provides the context for the call. We will obtain\n",
        "the id from the project in which this notebook runs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"data\"></a>\n",
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the `financial documents` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = 'Data_Finance.csv'\n",
        "url = 'https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/data/cfpb_complaints/cfpb_compliants.csv'\n",
        "if not os.path.isfile(filename): wget.download(url, out=filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>narrative</th>\n",
              "      <th>product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>currently hold one credit best buy visa paying...</td>\n",
              "      <td>credit_card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>asked verification debt appeared credit report...</td>\n",
              "      <td>debt_collection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>loan chase auto car accident car totaled insur...</td>\n",
              "      <td>mortgages_and_loans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pas due amount came denied income driven plan ...</td>\n",
              "      <td>mortgages_and_loans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>attn collection dept submitting complaint refe...</td>\n",
              "      <td>credit_reporting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           narrative              product\n",
              "0  currently hold one credit best buy visa paying...          credit_card\n",
              "1  asked verification debt appeared credit report...      debt_collection\n",
              "2  loan chase auto car accident car totaled insur...  mortgages_and_loans\n",
              "3  pas due amount came denied income driven plan ...  mortgages_and_loans\n",
              "4  attn collection dept submitting complaint refe...     credit_reporting"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data= read_csv(\"Data_Finance.csv\")\n",
        "data=data[['narrative','product']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect the product class distribution. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "retail_banking         3863\n",
              "credit_card            5031\n",
              "mortgages_and_loans    5822\n",
              "credit_reporting       6000\n",
              "debt_collection        6642\n",
              "Name: product, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['product'].value_counts().sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split data to train and test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train, data_test, y_train, y_test = train_test_split(data['narrative'], \n",
        "                                                    data['product'],\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=33, \n",
        "                                                    stratify=data['product'])\n",
        "data_train = DataFrame(data_train)\n",
        "data_test = DataFrame(data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"models\"></a>\n",
        "## Foundation Models on watsonx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bigcode/starcoder',\n",
              " 'bigscience/mt0-xxl',\n",
              " 'codellama/codellama-34b-instruct-hf',\n",
              " 'eleutherai/gpt-neox-20b',\n",
              " 'google/flan-t5-xl',\n",
              " 'google/flan-t5-xxl',\n",
              " 'google/flan-ul2',\n",
              " 'ibm-mistralai/mixtral-8x7b-instruct-v01-q',\n",
              " 'ibm/granite-13b-chat-v1',\n",
              " 'ibm/granite-13b-chat-v2',\n",
              " 'ibm/granite-13b-instruct-v1',\n",
              " 'ibm/granite-13b-instruct-v2',\n",
              " 'ibm/granite-20b-multilingual',\n",
              " 'ibm/mpt-7b-instruct2',\n",
              " 'meta-llama/llama-2-13b-chat',\n",
              " 'meta-llama/llama-2-70b-chat']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models_json = requests.get(endpoint_url + '/ml/v1/foundation_model_specs?version=2024-03-19&limit=50',\n",
        "                           headers={\n",
        "                                    'Authorization': f'Bearer {access_token}',\n",
        "                                    'Content-Type': 'application/json',\n",
        "                                    'Accept': 'application/json'\n",
        "                            }).json()\n",
        "models_ids = [m['model_id'] for m in models_json['resources']]\n",
        "models_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You need to specify `model_id` that will be used for inferencing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_id = \"google/flan-ul2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"predict\"></a>\n",
        "##  Classify customer complaints "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define instructions for the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "instruction=\"\"\"Determine the class of product expressed in the sentense.\n",
        "Use either 'credit_card', 'debt_collection','mortgages_and_loans',retail_banking, or 'credit_reporting'.\n",
        "Use the provided examples as a template. \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare model inputs for zero-shot example - use below zero_shot_inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentence example 1 is:\n",
            " receiving current copy credit report discovered entry identified inquiry qualified deletion report\n",
            "\n",
            "The sentence example 2 is:\n",
            " got scam told send via cash apps able sent via cash apps adamant need send complete total via paid total amount reading since going remove called need put downpayment material need church helping remove need put downpayment return money within sent money since limit consumer protection program able send noticed scammed filed report return money back denied dispute something need get done scammer cash apps need better proctection protect innocent customer like\n",
            "\n",
            "The sentence example 3 is:\n",
            " service member elected servicemembers civil relief act usaa prior departure reduced auto insurance due vehicle use gone austere environment limited communication mail forwarded location member deactivate cell phone gone turn back upon return mail sent arriving late month later due remote location logistical challenge usaa visa credit card well year issue credit limit card balance reward point due equating cashed apparently charge appeared card departed unaware receive communication lender could reach assuming tried usaa closed credit card reported day non payment credit bureau upon return immediately paid amount attempted numerous time unsuccessfully resolve issue usaa mentioned account voluntarily closed point would available day would allow credit instance negative reporting credit report brought score scra respectfully request removal negative credit reporting allow cash payment reward point balance credit reporting loss available credit would good credit limit restored well negative reporting credit cost year come inability obtain lower mortgage loan rate credit card etc due relocate week plan purchase home many thanks relief assistance could provide sincerely military member\n",
            "\n",
            "The sentence example 4 is:\n",
            " contacted u bank fraud department said couldnt find account worry need make sure case fraud happening suspect might part\n",
            "\n",
            "The sentence example 5 is:\n",
            " pandemic hoping youre safe sound listen shocked reviewed credit report today found late payment\n",
            "\n"
          ]
        }
      ],
      "source": [
        "zero_shot_inputs = [{\"input\": text} for text in data_test['narrative']]\n",
        "for i in range(5):\n",
        "    print(f\"The sentence example {i+1} is:\\n {zero_shot_inputs[i]['input']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare model inputs for few-shot examples - use below few_shot_inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "data_train_and_labels=data_train.copy()\n",
        "data_train_and_labels['product']=y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "few_shot_example=[]\n",
        "few_shot_examples=[]\n",
        "for phrase,product in data_train_and_labels.groupby('product').apply(lambda x: x.sample(2)).values:\n",
        "    few_shot_example.append(f\"\\tsentence:\\t{phrase}\\n\\tproduct: {product}\\n\")\n",
        "few_shot_examples=[''.join(few_shot_example)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentence example 1 is:\n",
            " receiving current copy credit report discovered entry identified inquiry qualified deletion report\n",
            "\n",
            "The sentence example 2 is:\n",
            " got scam told send via cash apps able sent via cash apps adamant need send complete total via paid total amount reading since going remove called need put downpayment material need church helping remove need put downpayment return money within sent money since limit consumer protection program able send noticed scammed filed report return money back denied dispute something need get done scammer cash apps need better proctection protect innocent customer like\n",
            "\n",
            "The sentence example 3 is:\n",
            " service member elected servicemembers civil relief act usaa prior departure reduced auto insurance due vehicle use gone austere environment limited communication mail forwarded location member deactivate cell phone gone turn back upon return mail sent arriving late month later due remote location logistical challenge usaa visa credit card well year issue credit limit card balance reward point due equating cashed apparently charge appeared card departed unaware receive communication lender could reach assuming tried usaa closed credit card reported day non payment credit bureau upon return immediately paid amount attempted numerous time unsuccessfully resolve issue usaa mentioned account voluntarily closed point would available day would allow credit instance negative reporting credit report brought score scra respectfully request removal negative credit reporting allow cash payment reward point balance credit reporting loss available credit would good credit limit restored well negative reporting credit cost year come inability obtain lower mortgage loan rate credit card etc due relocate week plan purchase home many thanks relief assistance could provide sincerely military member\n",
            "\n",
            "The sentence example 4 is:\n",
            " contacted u bank fraud department said couldnt find account worry need make sure case fraud happening suspect might part\n",
            "\n",
            "The sentence example 5 is:\n",
            " pandemic hoping youre safe sound listen shocked reviewed credit report today found late payment\n",
            "\n"
          ]
        }
      ],
      "source": [
        "few_shot_inputs_ = [{\"input\": text} for text in data_test['narrative'].values]\n",
        "for i in range(5):\n",
        "    print(f\"The sentence example {i+1} is:\\n {few_shot_inputs_[i]['input']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the model parameters\n",
        "We need to provide a set of model parameters that will influence the\n",
        "result:Based on decoding strategy that ww have for the models, the parameters can change.\n",
        "\n",
        "There are two decoding strategies: `greedy`, `sampling`.\n",
        "\n",
        "We usually use `greedy` for classification, Summarization, Extraction and Q&A.\n",
        "\n",
        "We usually use `sampling` for content generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters = {\n",
        "         \"decoding_method\": \"greedy\",\n",
        "         \"random_seed\": 33,\n",
        "         \"repetition_penalty\":1,\n",
        "         \"min_new_tokens\": 1,\n",
        "         \"max_new_tokens\": 5\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate the classification of Consumer Financial Protection Bureau (CFPB) document using `google/flan-ul2` model.\n",
        "\n",
        "\n",
        "**Note:** You might need to adjust model `parameters` for different models or tasks, to do so please refer to <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/fm_model.html#metanames.GenTextParamsMetaNames\" target=\"_blank\" rel=\"GenTextParamsMetaNames params\">documentation</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the `Prompt` class.\n",
        "\n",
        "**Hint:** Your authentication token might expire, if so please regenerate the `access_token` reinitialize the `Prompt` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = Prompt(access_token, project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the product classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "for inp in few_shot_inputs_[:5]:\n",
        "    results.append(prompt.generate(\" \".join([instruction+few_shot_examples[0], inp['input']]), model_id, parameters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'credit_reporting',\n",
              "  'generated_token_count': 5,\n",
              "  'input_token_count': 1575,\n",
              "  'stop_reason': 'max_tokens'},\n",
              " {'generated_text': 'product: credit_card',\n",
              "  'generated_token_count': 5,\n",
              "  'input_token_count': 1648,\n",
              "  'stop_reason': 'max_tokens'},\n",
              " {'generated_text': 'credit_card',\n",
              "  'generated_token_count': 4,\n",
              "  'input_token_count': 1758,\n",
              "  'stop_reason': 'eos_token'},\n",
              " {'generated_text': 'retail_banking',\n",
              "  'generated_token_count': 5,\n",
              "  'input_token_count': 1585,\n",
              "  'stop_reason': 'eos_token'},\n",
              " {'generated_text': 'credit_reporting',\n",
              "  'generated_token_count': 5,\n",
              "  'input_token_count': 1580,\n",
              "  'stop_reason': 'max_tokens'}]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"score\"></a>\n",
        "## Score the model\n",
        "\n",
        "**Note:** To run the Score section for model scoring on the whole financial phrasebank dataset, please transform following `markdown` cells to `code` cells.\n",
        "Have in mind that scoring model on the whole test set can take significant amount of time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the true labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "y_true = y_test.values[:5]\n",
        "print(y_true)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the prediction labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "y_pred = [result['generated_text'] for result in results]\n",
        "y_pred\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate the accuracy score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "print(accuracy_score(y_pred, y_true))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        " You successfully completed this notebook!.\n",
        " \n",
        " You learned how to classify Consumer Financial Protection Bureau documents with Google's `google-flan-ul2` on watsonx. \n",
        " \n",
        " Check out our <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"Online Documentation\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ### Author: \n",
        " \n",
        " **Kahila Mokhtari**\n",
        "\n",
        " **Mateusz Szewczyk**, Software Engineer at watsonx.ai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Copyright © 2023-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
