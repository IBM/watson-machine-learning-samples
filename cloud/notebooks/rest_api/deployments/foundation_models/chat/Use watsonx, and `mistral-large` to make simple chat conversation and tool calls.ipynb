{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and `mistralai/mistral-large` to make simple chat conversation and tool calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook provides a detailed demonstration of the steps and code required to showcase support for Chat models, including the integration of tools and watsonx.ai models.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The purpose of this notebook is to demonstrate how to use Chat models, e.g. `mistralai/mistral-large` by using tools.\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Foundation Models on watsonx](#models)\n",
        "- [Work with chat messages](#chat)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install and import the `datasets` and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!pip install requests | tail -n 1\n",
        "!pip install ibm-cloud-sdk-core | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass, os, requests\n",
        "from ibm_cloud_sdk_core import IAMTokenManager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inferencing class\n",
        "This cell defines a class that makes a REST API call to the watsonx Foundation Model\n",
        "inferencing API that we will use to generate output from the provided input.\n",
        "The class takes the access token created in the previous step, and uses it to\n",
        "make a REST API call with input, model id and model parameters. The response\n",
        "from the API call is returned as the cell output.\n",
        "\n",
        "\n",
        "**Action:** Provide watsonx.ai Runtime url to work with watsonx.ai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "endpoint_url = input(\"Please enter your watsonx.ai Runtime endpoint url (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a `ModelInferanceChat` class for chat generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelInferanceChat:\n",
        "    def __init__(self, access_token, project_id):\n",
        "        self.access_token = access_token\n",
        "        self.project_id = project_id\n",
        "\n",
        "    def chat(\n",
        "        self, \n",
        "        model_id, \n",
        "        messages, \n",
        "        tools = None, \n",
        "        tool_choice = None, \n",
        "        tool_choice_option = None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        wml_url = f\"{endpoint_url}/ml/v1/text/chat?version=2024-10-07\"\n",
        "        Headers = {\n",
        "            \"Authorization\": \"Bearer \" + self.access_token,\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Accept\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model_id\": model_id,\n",
        "            \"messages\": messages,\n",
        "            \"tools\": tools,\n",
        "            \"tool_choice\": tool_choice,\n",
        "            \"tool_choice_option\": tool_choice_option,\n",
        "            \"project_id\": self.project_id,\n",
        "        }\n",
        "        data = data | kwargs\n",
        "        response = requests.post(wml_url, json=data, headers=Headers)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### watsonx API connection\n",
        "Use the code cell below to define the watsonx.ai credentials that are required to work with watsonx Foundation Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">Managing user API keys</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "access_token = IAMTokenManager(\n",
        "    apikey = getpass.getpass(\"Enter your watsonx.ai api key and hit enter: \"),\n",
        "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
        ").get_token()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the project id\n",
        "You need to provide the project ID to give the Foundation Model the context for the call. If you have a default project ID set in Watson Studio, the notebook obtains that project ID. Otherwise, you need to provide the project ID in the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"models\"></a>\n",
        "## Set up the Foundation Model on `watsonx.ai`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify the `model_id` of the model you will use for the chat with tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_id = \"mistralai/mistral-large\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the `ModelInferanceChat` class.\n",
        "\n",
        "**Hint:** Your authentication token might expire, if so please regenerate the `access_token` reinitialize the `ModelInferanceChat` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ModelInferanceChat(access_token, project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"chat\"></a>\n",
        "## Work with chat messages "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Working with simple chat message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\", \n",
        "        \"content\": \"What is 1 + 1\"\n",
        "    }\n",
        "]\n",
        "\n",
        "simple_chat_response = model.chat(\n",
        "    model_id=model_id,\n",
        "    messages=messages\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The sum of 1 + 1 is 2. Here it is:\n",
            "\n",
            " 1\n",
            "+1\n",
            "____\n",
            " 2\n"
          ]
        }
      ],
      "source": [
        "print(simple_chat_response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Working with simple chat message with params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\", \n",
        "        \"content\": \"What is 1 + 1\"\n",
        "    }\n",
        "]\n",
        "\n",
        "simple_chat_response_2 = model.chat(\n",
        "    model_id=model_id,\n",
        "    messages=messages,\n",
        "    temperature=1.5,\n",
        "    max_tokens=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The sum of 1 and 1 is 2. So,\n",
            "\n",
            "1 + 1 = 2\n"
          ]
        }
      ],
      "source": [
        "print(simple_chat_response_2[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with an advanced chat message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"Who won the world series in 2020?\"\n",
        "            }\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"Where was it played?\"\n",
        "            }\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "advanced_chat_response = model.chat(\n",
        "    model_id=model_id,\n",
        "    messages=messages\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The 2020 World Series was played at Globe Life Field in Arlington, Texas. Due to the COVID-19 pandemic, the entire series was played at a neutral site for the first time in Major League Baseball history. The Dodgers defeated the Tampa Bay Rays in six games to win their seventh World Series championship.\n"
          ]
        }
      ],
      "source": [
        "print(advanced_chat_response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with chat messages using `tools` and `tool_choice`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"},\n",
        "]\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "tool_choice = {\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\"}}\n",
        "\n",
        "tool_response = model.chat(\n",
        "    model_id=model_id,\n",
        "    messages=messages, \n",
        "    tools=tools, \n",
        "    tool_choice=tool_choice\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"\",\n",
            "    \"tool_calls\": [\n",
            "        {\n",
            "            \"id\": \"chatcmpl-tool-6846b1bfab404019ae72b9da50c5e1be\",\n",
            "            \"type\": \"function\",\n",
            "            \"function\": {\n",
            "                \"name\": \"get_current_weather\",\n",
            "                \"arguments\": \"{\\\"location\\\":\\\"\\\"}\"\n",
            "            }\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "print(json.dumps(tool_response[\"choices\"][0][\"message\"], indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with chat messages using `tools` and `tool_choice_option`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        'function': {\n",
        "            'description': 'Adds a and b.',\n",
        "            'name': 'add',\n",
        "            'parameters': {\n",
        "                'properties': {\n",
        "                    'a': {'type': 'float'},\n",
        "                    'b': {'type': 'float'}},\n",
        "                'required': ['a', 'b'],\n",
        "                'type': 'object'}\n",
        "        },\n",
        "        'type': 'function'\n",
        "    },\n",
        "    {\n",
        "        'function': {\n",
        "            'description': 'Multiplies a and b.',\n",
        "            'name': 'multiply',\n",
        "            'parameters': {\n",
        "                'properties': {\n",
        "                    'a': {'type': 'float'},\n",
        "                    'b': {'type': 'float'}},\n",
        "                'required': ['a', 'b'],\n",
        "                'type': 'object'}\n",
        "        },\n",
        "        'type': 'function'\n",
        "    }\n",
        "]\n",
        "\n",
        "tool_choice_option = \"auto\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"role\": \"assistant\",\n",
            "    \"tool_calls\": [\n",
            "        {\n",
            "            \"id\": \"chatcmpl-tool-268dd36350cd4729b41fc7048b208eec\",\n",
            "            \"type\": \"function\",\n",
            "            \"function\": {\n",
            "                \"name\": \"add\",\n",
            "                \"arguments\": \"{\\\"a\\\": 5, \\\"b\\\": 6}\"\n",
            "            }\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is 5 + 6?\"},\n",
        "]\n",
        "\n",
        "tools_response = model.chat(\n",
        "    model_id=model_id,\n",
        "    messages=messages, \n",
        "    tools=tools, \n",
        "    tool_choice_option=tool_choice_option\n",
        ")\n",
        "\n",
        "print(json.dumps(tools_response[\"choices\"][0][\"message\"], indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"role\": \"assistant\",\n",
            "    \"tool_calls\": [\n",
            "        {\n",
            "            \"id\": \"chatcmpl-tool-b178a5f6d8f7402b922393dda87e3d27\",\n",
            "            \"type\": \"function\",\n",
            "            \"function\": {\n",
            "                \"name\": \"multiply\",\n",
            "                \"arguments\": \"{\\\"a\\\": 5, \\\"b\\\": 6}\"\n",
            "            }\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is 5 * 6?\"},\n",
        "]\n",
        "\n",
        "tools_response_2 = model.chat(\n",
        "    model_id=model_id,\n",
        "    messages=messages, \n",
        "    tools=tools, \n",
        "    tool_choice_option=tool_choice_option\n",
        ")\n",
        "\n",
        "print(json.dumps(tools_response_2[\"choices\"][0][\"message\"], indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to work with chat models using tools and watsonx.ai.\n",
        "\n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Author\n",
        "\n",
        "**Mateusz Szewczyk**, Software Engineer at watsonx.ai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright © 2024-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
