{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and `google/flan-ul2` to extract the named entities of  climate fever document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "This notebook contains the steps and code to demonstrate support of named entity extraction in watsonx. It introduces commands for data retrieval and model testing.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The objective is to explore and utilize the Google Flan-UL2 model for entity extraction.Google Flan-UL2 is a pre-trained language model which can be used for token-level entity extraction tasks. Entity extraction, also known as Named Entity Recognition (NER), involves identifying and classifying named entities (such as persons, organizations, locations, dates, etc.) from unstructured text.\n",
        "\n",
        "Here are the steps we took in this notebook for Named Entity Extractions:\n",
        "- Data Collection and Preprocessing:\n",
        "Collect or obtain a dataset containing text documents \n",
        "- Instructions:\n",
        "Define the task and the prompt: Determine the specific entity extraction task we want the model to perform. Design an appropriate prompt that includes relevant instructions for the model, such as input format and expected output format.\n",
        "- Training Examples:\n",
        "provide training examples in the form of input-output pairs. Each input example consists of a prompt and corresponding tokenized text, while the output is the target entity labels associated with the tokens in the text.\n",
        "- Evaluation:\n",
        "Compare the predicted entity labels with the  pseudo ground truth labels in the test set. Calculate evaluation metrics, such as precision, recall, and F1-score, to assess the performance of the model for entity extraction.(**we do not have ground truth entity extraction data for this dataset, we use an open source package to create a pseudo-ground truth that can be used for demonstration purposes.**)\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The goal of this notebook is to demonstrate how to use `google/flan-ul2` model to extract named entities for climate change claims.\n",
        "\n",
        "## Use case & dataset\n",
        "A dataset adopting the FEVER methodology that consists of 1535 real-world claims regarding climate-change collected on the internet. Each claim is accompanied by five manually annotated evidence sentences retrieved from the English Wikipedia that support, refute or do not give enough information to validate the claim totalling in 7675 claim-evidence pairs. The dataset features challenging claims that relate multiple facets and disputed cases of claims where both supporting and refuting evidence are present.Named entities are  extracted form the claims using the google/flan-ul2 model. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Data loading](#data)\n",
        "- [Foundation Models on watsonx](#models)\n",
        "- [Model testing](#predict)\n",
        "- [Score](#score)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "##  Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install and import the `datasets` and dependecies\n",
        "you need to install below required dependencies to be able to continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install datasets | tail -n 1\n",
        "!pip install requests | tail -n 1\n",
        "!pip install wget | tail -n 1\n",
        "!pip install ibm-cloud-sdk-core | tail -n 1\n",
        "!pip install \"scikit-learn==1.3.2\" | tail -n 1\n",
        "!pip install spacy | tail -n 1\n",
        "!python -m spacy download en_core_web_sm | tail -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, getpass, wget\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import requests\n",
        "import spacy\n",
        "import copy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import classification_report\n",
        "from ibm_cloud_sdk_core import IAMTokenManager\n",
        "from sklearn.model_selection import train_test_split\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inferencing class\n",
        "This cell defines a class that makes a REST API call to the watsonx Foundation Model\n",
        "inferencing API that we will use to generate output from the provided input.\n",
        "The class takes the access token created in the previous step, and uses it to\n",
        "make a REST API call with input, model id and model parameters. The response\n",
        "from the API call is returned as the cell output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Action:** Provide watsonx.ai Runtime url to work with wastonx.ai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint_url = getpass.getpass(\"Please enter your watsonx.ai Runtime endpoint url (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a `Prompt` class for prompts generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Prompt:\n",
        "    def __init__(self, access_token, project_id):\n",
        "        self.access_token = access_token\n",
        "        self.project_id = project_id\n",
        "\n",
        "    def generate(self, input, model_id, parameters):\n",
        "        wml_url = f\"{endpoint_url}/ml/v1/text/generation?version=2024-03-19\"\n",
        "        Headers = {\n",
        "            \"Authorization\": \"Bearer \" + self.access_token,\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Accept\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model_id\": model_id,\n",
        "            \"input\": input,\n",
        "            \"parameters\": parameters,\n",
        "            \"project_id\": self.project_id\n",
        "        }\n",
        "        response = requests.post(wml_url, json=data, headers=Headers)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()[\"results\"][0]\n",
        "        else:\n",
        "            return response.text\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### watsonx API connection\n",
        "This cell defines the credentials required to work with watsonx API for Foundation\n",
        "Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud personal API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"IBM Cloud user API key\">documentation</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "access_token = IAMTokenManager(\n",
        "    apikey = getpass.getpass(\"Please enter your watsonx.ai api key (hit enter): \"),\n",
        "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
        ").get_token()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the project id\n",
        "The API requires project id that provides the context for the call. We will obtain\n",
        "the id from the project in which this notebook runs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = getpass.getpass(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"data\"></a>\n",
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the `climate` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = 'data_clm_fever.csv'\n",
        "url = 'https://raw.githubusercontent.com/kmokht1/Datasets/main/data_clm_fever.csv'\n",
        "if not os.path.isfile(filename): wget.download(url, out=filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Global warming is driving polar bears toward e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The sun has gone into ‘lockdown’ which could c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The polar bear population has been growing.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ironic' study finds more CO2 has slightly cool...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Human additions of CO2 are in the margin of er...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               claim\n",
              "0  Global warming is driving polar bears toward e...\n",
              "1  The sun has gone into ‘lockdown’ which could c...\n",
              "2        The polar bear population has been growing.\n",
              "3  Ironic' study finds more CO2 has slightly cool...\n",
              "4  Human additions of CO2 are in the margin of er..."
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data= read_csv(\"data_clm_fever.csv\", index_col=[0])\n",
        "#data=data[['narrative','product']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split data to train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train, data_test, _,_ = train_test_split(data['claim'], \n",
        "                                                    data['claim'],\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=33,\n",
        "                                             )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect data sample "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "662                   Polar bear numbers are increasing.\n",
            "207    \"In 1999 New Scientist reported a comment by t...\n",
            "675    \"We found [U.S. weather] stations located next...\n",
            "175    Skeptics who oppose scientific findings that t...\n",
            "728    Pollard and DeConto are the first to admit tha...\n",
            "99     Global average temperatures over land have plu...\n",
            "747    the world is barely half a degree Celsius (0.9...\n",
            "670    Theory, models and direct measurement confirm ...\n",
            "849    Never mind that the emissions of carbon dioxid...\n",
            "948    Sea-level rise does not seem to depend on ocea...\n",
            "Name: claim, dtype: object\n"
          ]
        }
      ],
      "source": [
        "data_sample=data_train.reset_index(inplace=False, drop=True)[random.sample(range(0, len(data_train)), 10)]\n",
        "print(data_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"models\"></a>\n",
        "## Foundation Models on watsonx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bigcode/starcoder',\n",
              " 'bigscience/mt0-xxl',\n",
              " 'codellama/codellama-34b-instruct-hf',\n",
              " 'eleutherai/gpt-neox-20b',\n",
              " 'google/flan-t5-xl',\n",
              " 'google/flan-t5-xxl',\n",
              " 'google/flan-ul2',\n",
              " 'ibm-mistralai/mixtral-8x7b-instruct-v01-q',\n",
              " 'ibm/granite-13b-chat-v1',\n",
              " 'ibm/granite-13b-chat-v2',\n",
              " 'ibm/granite-13b-instruct-v1',\n",
              " 'ibm/granite-13b-instruct-v2',\n",
              " 'ibm/granite-20b-multilingual',\n",
              " 'ibm/mpt-7b-instruct2',\n",
              " 'meta-llama/llama-2-13b-chat',\n",
              " 'meta-llama/llama-2-70b-chat']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models_json = requests.get(endpoint_url + '/ml/v1/foundation_model_specs?version=2024-03-19&limit=50',\n",
        "                           headers={\n",
        "                                    'Authorization': f'Bearer {access_token}',\n",
        "                                    'Content-Type': 'application/json',\n",
        "                                    'Accept': 'application/json'\n",
        "                            }).json()\n",
        "models_ids = [m['model_id'] for m in models_json['resources']]\n",
        "models_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You need to specify `model_id` that will be used for inferencing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_id = \"google/flan-ul2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"predict\"></a>\n",
        "##  Analyze named entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define instructions for the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare model inputs\n",
        "\n",
        "for zero-shot example, use below zero_shot_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentence example 1 is:\n",
            " Most likely the primary control knob [on climate change] is the ocean waters and this environment that we live in.\n",
            "\n",
            "The sentence example 2 is:\n",
            " The Rio Grande is a classic “feast or famine” river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\n",
            "\n",
            "The sentence example 3 is:\n",
            " Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.”\n",
            "\n",
            "The sentence example 4 is:\n",
            " In our lifetime, there has been no correlation between carbon dioxide emissions and temperature\n",
            "\n",
            "The sentence example 5 is:\n",
            " There is no way for us to prevent the world’s CO2 emissions    from doubling by 2100\"\n",
            "\n",
            "The sentence example 6 is:\n",
            " Wu et al (2010) use a new method to calculate ice sheet mass balance.\n",
            "\n",
            "The sentence example 7 is:\n",
            " In the last 35 years of global warming, sun and climate have been going in opposite directions.\n",
            "\n",
            "The sentence example 8 is:\n",
            " Australia has more solar coverage than any other continent.\n",
            "\n",
            "The sentence example 9 is:\n",
            " Polar bears are in danger of extinction as well as many other species.\n",
            "\n",
            "The sentence example 10 is:\n",
            " The United States has been restricting soot emissions  in Draconian fashion since the Clean Air Act of 1963.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "zero_shot_inputs = [{\"input\": text} for text in data_test]\n",
        "for i in range(10):\n",
        "    print(f\"The sentence example {i+1} is:\\n {zero_shot_inputs[i]['input']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare model inputs\n",
        "\n",
        "for few-shot examples, use below few_shot_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentence example 1 is:\n",
            " Most likely the primary control knob [on climate change] is the ocean waters and this environment that we live in.\n",
            "\n",
            "The sentence example 2 is:\n",
            " The Rio Grande is a classic “feast or famine” river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\n",
            "\n",
            "The sentence example 3 is:\n",
            " Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.”\n",
            "\n",
            "The sentence example 4 is:\n",
            " In our lifetime, there has been no correlation between carbon dioxide emissions and temperature\n",
            "\n",
            "The sentence example 5 is:\n",
            " There is no way for us to prevent the world’s CO2 emissions    from doubling by 2100\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "few_shot_inputs_ = [{\"input\": text} for text in data_test.values]\n",
        "for i in range(5):\n",
        "    print(f\"The sentence example {i+1} is:\\n {few_shot_inputs_[i]['input']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing the dictionaries of the inputs: for demonstration purposes, we provide the examples using an open source entity extraction model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process each document in the dataset\n",
        "example_dic ={}\n",
        "example_dic_list=[]\n",
        "\n",
        "for document in data_sample:\n",
        "    \n",
        "    doc = nlp(document.strip())  # Process the document with spacy NLP pipeline\n",
        "    if (len(doc.ents) != 0):\n",
        "        example_dic ={}\n",
        "        example_dic['document']=document\n",
        "        for i, ent in enumerate(doc.ents):\n",
        "            example_dic[f'phrase_{i}']=ent.text\n",
        "            example_dic[f'label_{i}']=ent.label_\n",
        "            \n",
        "        example_dic_list.append(example_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"document\": \"\\\"In 1999\\u00a0New Scientist\\u00a0reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas\\u00a0could disappear by 2035.\",\n",
            "        \"phrase_0\": \"1999\",\n",
            "        \"label_0\": \"DATE\",\n",
            "        \"phrase_1\": \"Indian\",\n",
            "        \"label_1\": \"NORP\",\n",
            "        \"phrase_2\": \"Syed Hasnain\",\n",
            "        \"label_2\": \"PERSON\",\n",
            "        \"phrase_3\": \"Himalayas\",\n",
            "        \"label_3\": \"GPE\",\n",
            "        \"phrase_4\": \"2035\",\n",
            "        \"label_4\": \"DATE\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"\\\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads,\\u00a0on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\",\n",
            "        \"phrase_0\": \"U.S.\",\n",
            "        \"label_0\": \"GPE\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"Skeptics who oppose scientific findings that threaten their world view are far closer to Galileo's belief-based critics in the Catholic Church.\",\n",
            "        \"phrase_0\": \"Galileo\",\n",
            "        \"label_0\": \"PRODUCT\",\n",
            "        \"phrase_1\": \"the Catholic Church\",\n",
            "        \"label_1\": \"ORG\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"Pollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\",\n",
            "        \"phrase_0\": \"DeConto\",\n",
            "        \"label_0\": \"GPE\",\n",
            "        \"phrase_1\": \"first\",\n",
            "        \"label_1\": \"ORDINAL\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "json_formatted_str = json.dumps(example_dic_list[:4], indent=4)\n",
        "print(json_formatted_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating text format from the above dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "examples=[]\n",
        "for i in range(len(example_dic_list)):\n",
        "    examples.append('document: \\n'+example_dic_list[i]['document']+'\\n')\n",
        "    di=copy.deepcopy(example_dic_list[i])\n",
        "    del di['document']\n",
        "    examples.append('\\n')\n",
        "    examples.append(str(di))\n",
        "    examples.append('\\n\\n\\n')\n",
        "examples_input=''.join(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "document: \n",
            "\"In 1999 New Scientist reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas could disappear by 2035.\n",
            "\n",
            "{'phrase_0': '1999', 'label_0': 'DATE', 'phrase_1': 'Indian', 'label_1': 'NORP', 'phrase_2': 'Syed Hasnain', 'label_2': 'PERSON', 'phrase_3': 'Himalayas', 'label_3': 'GPE', 'phrase_4': '2035', 'label_4': 'DATE'}\n",
            "\n",
            "\n",
            "document: \n",
            "\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads, on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\n",
            "\n",
            "{'phrase_0': 'U.S.', 'label_0': 'GPE'}\n",
            "\n",
            "\n",
            "document: \n",
            "Skeptics who oppose scientific findings that threaten their world view are far closer to Galileo's belief-based critics in the Catholic Church.\n",
            "\n",
            "{'phrase_0': 'Galileo', 'label_0': 'PRODUCT', 'phrase_1': 'the Catholic Church', 'label_1': 'ORG'}\n",
            "\n",
            "\n",
            "document: \n",
            "Pollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\n",
            "\n",
            "{'phrase_0': 'DeConto', 'label_0': 'GPE', 'phrase_1': 'first', 'label_1': 'ORDINAL'}\n",
            "\n",
            "\n",
            "document: \n",
            "Global average temperatures over land have plummeted by more than 1C since the middle of this year – their biggest and steepest fall on record.\n",
            "\n",
            "{'phrase_0': 'the middle of this year', 'label_0': 'DATE'}\n",
            "\n",
            "\n",
            "document: \n",
            "the world is barely half a degree Celsius (0.9 degrees Fahrenheit) warmer than it was about 35 years ago\n",
            "\n",
            "{'phrase_0': 'barely half', 'label_0': 'CARDINAL', 'phrase_1': '0.9 degrees', 'label_1': 'QUANTITY', 'phrase_2': 'Fahrenheit', 'label_2': 'GPE', 'phrase_3': 'about 35 years ago', 'label_3': 'DATE'}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(examples_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the model parameters\n",
        "We need to provide a set of model parameters that will influence the\n",
        "result:Based on decoding strategy that we have for the models, the parameters can change.\n",
        "\n",
        "There are two decoding strategies: 1-Greedy 2-Sampling.\n",
        "\n",
        "We usually use Greedy for complaint classification, Summarization,Extraction and Q&A\n",
        "\n",
        "We usually use Sampling for content generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GREEDY PAREMETER CONFIGURATION\n",
        "\n",
        "parameters = {\n",
        "         \"decoding_method\": \"greedy\",\n",
        "         \"random_seed\": 33,\n",
        "         \"repetition_penalty\":1,\n",
        "         \"min_new_tokens\": 1,\n",
        "         \"max_new_tokens\": 150\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract the named entities of climate claim document using `google/flan-ul2` model.\n",
        "\n",
        "\n",
        "**Note:** You might need to adjust model `parameters` for different models or tasks, to do so please refer to <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/fm_model.html#metanames.GenTextParamsMetaNames\" target=\"_blank\" rel=\"GenTextParamsMetaNames params\">documentation</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the `Promtp` class.\n",
        "\n",
        "**Hint:** Your authentication token might expire, if so please regenerate the `access_token` reinitialize the `Promtp` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = Prompt(access_token, project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List of all possible NERs: As we do not have ground truth entity extraction data for this dataset, we use an open source package to get the list of named entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
          ]
        }
      ],
      "source": [
        "list_of_NERS=nlp.get_pipe('ner').labels\n",
        "print(list_of_NERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the instruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "instruction=\"\"\"\n",
        "Accurately identify and classify named entities in text. The list of possible labels are:['CARDINAL','DATE','EVENT','FAC','GPE','LANGUAGE','LAW',\n",
        "'LOC','MONEY','NORP','ORDINAL','ORG','PERCENT','PERSON','PRODUCT','QUANTITY','TIME','WORK_OF_ART'].\n",
        "\n",
        "Return your responses in dictionary format. for the each found item, provide the \"phrase\" and\n",
        "the corresponding \"label\" along with their number as dictionary keys separated by numbers. \n",
        "Encapsulate the phrases and labels in single quotation mark. \n",
        "For instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\n",
        "Use the following training examples as follows:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accurately identify and classify named entities in text. The list of possible labels are:['CARDINAL','DATE','EVENT','FAC','GPE','LANGUAGE','LAW',\n",
            "'LOC','MONEY','NORP','ORDINAL','ORG','PERCENT','PERSON','PRODUCT','QUANTITY','TIME','WORK_OF_ART'].\n",
            "\n",
            "Return your responses in dictionary format. for the each found item, provide the \"phrase\" and\n",
            "the corresponding \"label\" along with their number as dictionary keys separated by numbers. \n",
            "Encapsulate the phrases and labels in single quotation mark. \n",
            "For instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\n",
            "Use the following training examples as follows:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(instruction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "for inp in few_shot_inputs_[:40]:\n",
        "    results.append(prompt.generate(\" \".join([instruction+examples_input+ \"document:\" +inp['input']]), model_id, parameters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"generated_text\": \"['control knob', 'ORG', 'LOC', 'PERSON', 'EVENT', 'LANGUAGE', 'PERCENT', 'ORG', 'PERSON', 'PERCENT', 'PERSON', 'PERCENT', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON'\",\n",
            "        \"generated_token_count\": 150,\n",
            "        \"input_token_count\": 935,\n",
            "        \"stop_reason\": \"max_tokens\"\n",
            "    },\n",
            "    {\n",
            "        \"generated_text\": \"phrase_0: \\\"The Rio Grande\\\", 'label_0': 'LOC', 'phrase_1': 'feast or famine', 'label_1': 'LOC', 'phrase_2': 'a dry year or two typically followed by a couple of wet years that allow for recovery', 'label_2': 'LOC', 'phrase_3': 'a couple of wet years', 'label_3': 'LOC', 'phrase_4': 'recovery', 'label_4'\",\n",
            "        \"generated_token_count\": 150,\n",
            "        \"input_token_count\": 950,\n",
            "        \"stop_reason\": \"max_tokens\"\n",
            "    },\n",
            "    {\n",
            "        \"generated_text\": \"phrase_0': Mountain West', 'label_0': 'LOC', 'phrase_1': Pacific Northwest', 'label_1': 'LOC', 'phrase_2': 'Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.', 'label_2': 'LOC', 'label_3': 'DATE', 'label_4': 'EVENT', 'label_5': '\",\n",
            "        \"generated_token_count\": 150,\n",
            "        \"input_token_count\": 950,\n",
            "        \"stop_reason\": \"max_tokens\"\n",
            "    },\n",
            "    {\n",
            "        \"generated_text\": \"'phrase_0': 'carbon dioxide emissions', 'label_0': 'QUANTITY', 'phrase_1': 'temperature', 'label_1': 'TIME', 'phrase_2': 'our lifetime', 'label_2': 'PERSON'\",\n",
            "        \"generated_token_count\": 85,\n",
            "        \"input_token_count\": 926,\n",
            "        \"stop_reason\": \"eos_token\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "json_formatted_str = json.dumps(results[:4], indent=4)\n",
        "print(json_formatted_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Document #0:\n",
            "Most likely the primary control knob [on climate change] is the ocean waters and this environment that we live in.\n",
            "Raw results from LLM model:\n",
            "  ['control knob', 'ORG', 'LOC', 'PERSON', 'EVENT', 'LANGUAGE', 'PERCENT', 'ORG', 'PERSON', 'PERCENT', 'PERSON', 'PERCENT', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #1:\n",
            "The Rio Grande is a classic “feast or famine” river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\n",
            "Raw results from LLM model:\n",
            "  phrase_0: \"The Rio Grande\", 'label_0': 'LOC', 'phrase_1': 'feast or famine', 'label_1': 'LOC', 'phrase_2': 'a dry year or two typically followed by a couple of wet years that allow for recovery', 'label_2': 'LOC', 'phrase_3': 'a couple of wet years', 'label_3': 'LOC', 'phrase_4': 'recovery', 'label_4'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #2:\n",
            "Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.”\n",
            "Raw results from LLM model:\n",
            "  phrase_0': Mountain West', 'label_0': 'LOC', 'phrase_1': Pacific Northwest', 'label_1': 'LOC', 'phrase_2': 'Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.', 'label_2': 'LOC', 'label_3': 'DATE', 'label_4': 'EVENT', 'label_5': '\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #3:\n",
            "In our lifetime, there has been no correlation between carbon dioxide emissions and temperature\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'carbon dioxide emissions', 'label_0': 'QUANTITY', 'phrase_1': 'temperature', 'label_1': 'TIME', 'phrase_2': 'our lifetime', 'label_2': 'PERSON'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #4:\n",
            "There is no way for us to prevent the world’s CO2 emissions    from doubling by 2100\"\n",
            "Raw results from LLM model:\n",
            "  phrase_0': 'CO2 emissions', 'label_0': 'QUANTITY', 'phrase_1': 'from doubling by 2100', 'label_1': 'DATE', 'phrase_2': 'world’s', 'label_2': 'CO2', 'phrase_3': 'from doubling by 2100', 'label_3': 'DATE', 'phrase_4': 'There is no way for us to prevent the world’s CO2 emissions from doubling by 2100', \n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #5:\n",
            "Wu et al (2010) use a new method to calculate ice sheet mass balance.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'Wu et al', 'label_0': 'PERSON', 'phrase_1': '(2010)', 'label_1': 'DATE'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #6:\n",
            "In the last 35 years of global warming, sun and climate have been going in opposite directions.\n",
            "Raw results from LLM model:\n",
            "  ['35 years', 'ORDER', 'CARDINAL', 'LAW', 'PERSON', 'PERCENT', 'QUANTITY', 'PERCENT', 'PERSON', 'PERCENT', 'PERSON', 'PERCENT', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PER\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #7:\n",
            "Australia has more solar coverage than any other continent.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'Australia', 'label_0': 'LOC'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #8:\n",
            "Polar bears are in danger of extinction as well as many other species.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'Polar bears', 'label_0': 'FAC', 'phrase_1': 'many other species', 'label_1': 'FAC'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #9:\n",
            "The United States has been restricting soot emissions  in Draconian fashion since the Clean Air Act of 1963.\n",
            "Raw results from LLM model:\n",
            "  phrase_0': \"The United States\" , 'label_0': 'LOC', 'phrase_1': \"Draconian fashion\" , 'label_1': 'LAW', 'phrase_2': \"Clean Air Act\" , 'label_2': 'LAW', 'phrase_3': '1963', 'label_3': 'DATE'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #10:\n",
            "The costs of inaction far outweigh the costs of mitigation.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'costs of inaction', 'label_0': 'QUANTITY', 'phrase_1': 'costs of mitigation', 'label_1': 'QUANTITY'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #11:\n",
            "“In their award winning book, ‘Taken By Storm’ (2007), Canadian researchers Christopher Essex and Ross McKitrick explain: ‘Temperature is not an amount of something [like height or weight].\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'Taken By Storm’ ', 'label_0': 'BOOK', 'phrase_1': 'Canadian', 'label_1': 'LOC', 'phrase_2': 'Christopher Essex', 'label_2': 'PERSON', 'phrase_3': 'Ross McKitrick', 'label_3': 'PERSON', 'phrase_4': 'Temperature', 'label_4': 'PRODUCT'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #12:\n",
            "Greg Hunt CSIRO research shows carbon emissions can be reduced by 20 per cent over 40 years using nature, soils and trees.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'Greg Hunt CSIRO', 'label_0': 'ORG', 'phrase_1': 'research shows carbon emissions can be reduced by 20 per cent over 40 years using nature, soils and trees', 'label_1': 'PERCENT'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #13:\n",
            "With that in mind, they propose a plausible and terrifying “2050 scenario” whereby humanity could face irreversible collapse in just three decades.\n",
            "Raw results from LLM model:\n",
            "  ['2050 scenario', 'label_0': 'PERSON', 'label_1': '2050', 'label_2': 'scenario', 'label_3': 'irreversible collapse', 'label_4': 'three decades']\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #14:\n",
            "No known natural forcing fits the fingerprints of observed warming except anthropogenic greenhouse gases.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'known natural forcing', 'label_0': 'FAC', 'phrase_1': 'anthropogenic greenhouse gases', 'label_1': 'FAC'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #15:\n",
            "We know the Northwest Passage had been open before.\"\n",
            "Raw results from LLM model:\n",
            "  phrase_0': \"the Northwest Passage had been open before.\", 'label_0': 'NORP', 'phrase_1': 'We know', 'label_1': 'PERSON'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #16:\n",
            "Mass coral bleaching is a new phenomenon and was never observed before the 1980s as global warming ramped up.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'Mass coral bleaching', 'label_0': 'FAC', 'phrase_1': 'new phenomenon', 'label_1': 'GPE', 'phrase_2': 'was never observed before the 1980s', 'label_2': 'EVENT', 'phrase_3': 'global warming ramped up', 'label_3': 'GPE', 'phrase_4': 'before the 1980s', 'label_4': 'DATE'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #17:\n",
            "[S]unspot activity on the surface of our star has dropped to a new low.\n",
            "Raw results from LLM model:\n",
            "  ['phrase_0': 's]unspot activity', 'label_0': 'FAC']\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #18:\n",
            "Carbon dioxide is a trace gas.”\n",
            "Raw results from LLM model:\n",
            "  phrase_0: \"Carbon dioxide is a trace gas.\", 'label_0': 'QUANTITY', 'phrase_1': 'Carbon dioxide', 'label_1': 'TRACE_GAS'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #19:\n",
            "Arctic sea ice has been steadily thinning, even in the last few years while the surface ice (eg - sea ice extent) increased slightly.\n",
            "Raw results from LLM model:\n",
            "  ['Arctic sea ice', 'label_0': 'LOC', 'label_1': 'FAC', 'label_2': 'ORG', 'label_3': 'PERSON', 'label_4': 'PERCENT', 'label_5': 'QUANTITY', 'label_6': 'PERCENT', 'label_7': 'PERSON', 'label_8': 'PERCENT', 'label_9': 'PERSON\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #20:\n",
            "The consensus among scientists and policy-makers is that we’ll pass this point of no return if the global mean temperature rises by more than two degrees Celsius.\n",
            "Raw results from LLM model:\n",
            "  ['point of no return', 'label_0': 'QUANTITY', 'point', 'label_1': 'QUANTITY', 'two degrees Celsius', 'label_2': 'QUANTITY', 'global mean temperature', 'label_3': 'QUANTITY', 'scientists', 'label_4': 'PERSON', 'policy-makers', 'label_5': 'PERSON']\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #21:\n",
            "Over the last 30-40 years 80% of coral in the Caribbean have been destroyed and 50% in Indonesia and the Pacific.\n",
            "Raw results from LLM model:\n",
            "  ['Carribean', 'LOC'], ['Indonesia', 'LOC'], ['Pacific', 'LOC']]\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #22:\n",
            "There are about 120,000 solar energy jobs in the United States, but only 1,700 of them are in Georgia.\n",
            "Raw results from LLM model:\n",
            "  ['United States', 'LOC', 'Georgia', 'LOC']\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #23:\n",
            "All the indicators show that global warming is still happening.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'global warming', 'label_0': 'GPE'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #24:\n",
            "While there are isolated cases of growing glaciers, the overwhelming trend in glaciers worldwide is retreat.\n",
            "Raw results from LLM model:\n",
            "  ['grow glaciers', 'label_0': 'LOC', 'grow glaciers', 'label_1': 'LOC', 'grow glaciers', 'label_2': 'LOC', 'grow glaciers', 'label_3': 'LOC', 'grow glaciers', 'label_4': 'LOC', 'grow glaciers', 'label_5': 'LOC', 'grow glaciers', 'label_6': '\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #25:\n",
            "\"The 30 major droughts of the 20th century were likely natural in all respects; and, hence, they are \"indicative of what could also happen in the future,\" as Narisma\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': \"The 30 major droughts of the 20th century were likely natural in all respects; and, hence, they are \"indicative of what could also happen in the future,\" as narisma', 'label_0': 'PERSON', 'label_1': 'ORG', 'label_2': 'PERCENT', 'label_3': 'ORG', 'label_4': 'PERCENT', 'label_5': 'PERSON', 'label_6': 'PERSON\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #26:\n",
            "Previous IPCC reports tended to assume that clouds would have a neutral impact because the warming and cooling feedbacks would cancel each other out.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'IPCC', 'label_0': 'ORG', 'phrase_1': 'reports', 'label_1': 'EVENT', 'phrase_2': 'would cancel each other out', 'label_2': 'warming and cooling feedbacks'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #27:\n",
            "Measurements indicating that 2017 had relatively more sea ice in the Arctic and less melting of glacial ice in Greenland casts scientific doubt on the reality of global warming.\n",
            "Raw results from LLM model:\n",
            "  ['Arctic', 'label_0': 'LOC', 'Greenland', 'label_1': 'LOC', 'label_2': 'LOC', 'label_3': 'LOC', 'label_4': 'LOC', 'label_5': 'LOC', 'label_6': 'LOC', 'label_7': 'LOC', 'label_8': 'LOC', 'label_9': \n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #28:\n",
            "It has never been shown that human emissions of carbon dioxide drive global warming.\n",
            "Raw results from LLM model:\n",
            "  ['human emissions', 'label_0': 'PERCENT', 'human emissions', 'label_1': 'CO2', 'label_2': 'global warming']\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #29:\n",
            "cutting speed limits could slow climate change\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'cutting speed limits', 'label_0': 'QUANTITY', 'phrase_1': 'could slow climate change', 'label_1': 'QUANTITY'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #30:\n",
            "Research has found a human influence on the climate of the past several decades ...\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'human influence', 'label_0': 'ORG', 'phrase_1': 'on the climate of the past several decades', 'label_1': 'ORG', 'phrase_2': 'Research has found', 'label_2': 'ORG', 'phrase_3': 'on the climate of the past several decades', 'label_3': 'ORG', 'phrase_4': 'Research has found', 'label_4': 'ORG\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #31:\n",
            "By 2100 the seas will rise another 6 inches or so—a far cry from Al Gore’s alarming numbers\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'Al Gore’s', 'label_0': 'PERSON', 'phrase_1': 'alarming numbers', 'label_1': 'PERSON', 'phrase_2': '6 inches', 'label_2': 'QUANTITY', 'phrase_3': '2100', 'label_3': 'DATE'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #32:\n",
            "Multiple lines of independent evidence indicate humidity is rising and provides positive feedback.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'multiple lines of independent evidence', 'label_0': 'PERCENT'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #33:\n",
            "a study that totally debunks the whole concept of man-made Global Warming\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'Global Warming', 'label_0': 'GPE', 'phrase_1': 'man-made', 'label_1': 'GPE', 'phrase_2': 'concept', 'label_2': 'GPE', 'phrase_3': 'whole', 'label_3': 'GPE', 'phrase_4': 'concept', 'label_4': 'GPE', 'phrase_5': 'whole concept\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #34:\n",
            "Claims have recently surfaced in the blogosphere that an increasing number of scientists are warning of an imminent global cooling, some even going so far as to call it a \"growing consensus\".\n",
            "Raw results from LLM model:\n",
            "  ['phrase_0': 'blogosphere', 'label_0': 'LOC', 'phrase_1': 'increasing number of scientists', 'label_1': 'PERSON', 'phrase_2': 'global cooling', 'label_2': 'EVENT', 'phrase_3': 'growing consensus', 'label_3': 'PERSON']\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #35:\n",
            "The extent of climate change’s influence on the jet stream is an intense subject of research.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'climate change’s influence', 'label_0': 'ORG', 'phrase_1': 'jet stream', 'label_1': 'REGION', 'phrase_2': 'research', 'label_2': 'ORG', 'phrase_3': 'intense', 'label_3': 'ORG', 'phrase_4': 'subject', 'label_4': 'ORG', 'phrase_5':\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #36:\n",
            "CO2 limits won't cool the planet.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'CO2 limits', 'label_0': 'QUANTITY', 'phrase_1': 'cool the planet', 'label_1': 'ORDER', 'phrase_2': 'limits', 'label_2': 'CO2', 'phrase_3': 'CO2', 'label_3': 'ORDER', 'phrase_4': 'CO2', 'label_4': 'ORDER', 'phrase_5': 'CO2\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #37:\n",
            "“Global warming alarmists’ preferred electricity source – wind power – kills nearly 1 million bats every year (to say nothing of the more than 500,000 birds killed every year) in the United States alone.\n",
            "Raw results from LLM model:\n",
            "  phrase_0': \"Global warming alarmists’ preferred electricity source – wind power – kills nearly 1 million bats every year (to say nothing of the more than 500,000 birds killed every year) in the United States alone.\", 'label_0': 'LOC', 'phrase_1': 'United States', 'label_1': 'LOC'\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #38:\n",
            "They concluded that trends toward rising climate damages were mainly due to increased population and economic activity in the path of storms, that it was not currently possible to determine the portion of damages attributable to greenhouse gases, and that they didn’t expect that situation to change in the near future.\n",
            "Raw results from LLM model:\n",
            "  ['They', 'label_0': 'PERSON', 'label_1': 'ORG', 'label_2': 'PERCENT', 'label_3': 'LAW', 'label_4': 'PERCENT', 'label_5': 'PERSON', 'label_6': 'PERCENT', 'label_7': 'PERSON', 'label_8': 'PERCENT', 'label_9': 'PERSON', 'label_\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Document #39:\n",
            "Humans are too insignificant to affect global climate.\n",
            "Raw results from LLM model:\n",
            "  'phrase_0': 'Humans', 'label_0': 'PERSON', 'phrase_1': 'global climate', 'label_1': 'PERCENT'\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(results)):\n",
        "    print('--------------------------------------------------')\n",
        "    print(f\"Document #{i}:\\n{few_shot_inputs_[i]['input']}\")\n",
        "    print(f'Raw results from LLM model:\\n ',results[i]['generated_text'])\n",
        "    print('--------------------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Score the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we need to extract `y_true` by performing NER using **Spacy** package as the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process each document in the few_shot_inputs_\n",
        "fsi ={}\n",
        "fsi_list_for_ground_truth=[]\n",
        "\n",
        "for document in few_shot_inputs_[:40]:\n",
        "    doc = nlp(document['input'].strip())  # Process the document with spacy NLP pipeline\n",
        "    if (len(doc.ents) != 0):\n",
        "        fsi ={}\n",
        "        fsi['document']=document['input']\n",
        "        for i, ent in enumerate(doc.ents):\n",
        "            fsi[f'phrase_{i}']=ent.text\n",
        "            fsi[f'label_{i}']=ent.label_\n",
        "        \n",
        "            \n",
        "        fsi_list_for_ground_truth.append(fsi)\n",
        "    else:\n",
        "        fsi_list_for_ground_truth.append({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {},\n",
            "    {\n",
            "        \"document\": \"The Rio Grande is a classic \\u201cfeast or famine\\u201d river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\",\n",
            "        \"phrase_0\": \"The Rio Grande\",\n",
            "        \"label_0\": \"ORG\",\n",
            "        \"phrase_1\": \"a dry year\",\n",
            "        \"label_1\": \"DATE\",\n",
            "        \"phrase_2\": \"two\",\n",
            "        \"label_2\": \"CARDINAL\",\n",
            "        \"phrase_3\": \"a couple of wet years\",\n",
            "        \"label_3\": \"DATE\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.\\u201d\",\n",
            "        \"phrase_0\": \"the Mountain West\",\n",
            "        \"label_0\": \"LOC\",\n",
            "        \"phrase_1\": \"early July\",\n",
            "        \"label_1\": \"DATE\",\n",
            "        \"phrase_2\": \"the Pacific Northwest\",\n",
            "        \"label_2\": \"LOC\",\n",
            "        \"phrase_3\": \"early August\",\n",
            "        \"label_3\": \"DATE\"\n",
            "    },\n",
            "    {}\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "json_formatted_str = json.dumps(fsi_list_for_ground_truth[:4], indent=4)\n",
        "print(json_formatted_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Post processing the results so that they can be compared with the ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_dictionary_from_results(s):\n",
        "    \n",
        "    ss2=s.split(', ')\n",
        "    \n",
        "    pc=0\n",
        "    lc=0\n",
        "    for w in ss2:\n",
        "        if 'phrase_' in w:\n",
        "            pc+=1\n",
        "        if 'label_' in w:\n",
        "            lc+=1\n",
        "    if ((pc==lc) and ((pc%2)==0) and ((lc%2)==0)):\n",
        "        return (eval(\"{\"+s+\"}\"))\n",
        "    \n",
        "    elif((pc%2)!=0 or ((lc%2)!=0)):\n",
        "       \n",
        "        lim = min(pc,lc)\n",
        "        wlim = 2*lim\n",
        "        return (eval('{'+','.join(ss2[:wlim])+'}'))\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function finds common words in two given phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_common_words(string1, string2):\n",
        "    words1 = set(string1.lower().split())\n",
        "    words2 = set(string2.lower().split())\n",
        "    common_words = words1.intersection(words2)\n",
        "    return list(common_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function removes unnecessary \"the\" and \"a\" from the given phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def drop_words(string):\n",
        "    words_to_drop = ['the', 'a']\n",
        "    pattern = r'\\b(?:{})\\b'.format('|'.join(words_to_drop))\n",
        "    cleaned_string = re.sub(pattern, '', string, flags=re.IGNORECASE)\n",
        "    return cleaned_string.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function handles imbalanced quotation marks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def polish_results(r):\n",
        "    \n",
        "    sp=r.split(',')\n",
        "    \n",
        "    nw=[]\n",
        "    for w in sp:\n",
        "        b=''\n",
        "        b=w.replace('\"', '').replace(\"'\", \"\")\n",
        "        nw.append(b)\n",
        "    \n",
        "    msl=[]\n",
        "    for w in nw:\n",
        "        ns=w.split(\":\")\n",
        "        nss=[]\n",
        "        for i in range(len(ns)):\n",
        "            ns[i]=ns[i].lstrip()\n",
        "        nss.append(\"'\"+ns[0]+\"'\"+':'+\"'\"+ns[1]+\"'\")\n",
        "\n",
        "        ms=''.join(nss)\n",
        "        msl.append(ms)\n",
        "\n",
        "    res=','.join(msl)\n",
        "    \n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The performance of the model can be compared to ground truth labels. The code below handles this task by comparing the identified phrases, which are common in both ground truth and model results. This task is done by ignoring the order which phrases appear in both ground truth and LLMs results and comparing the lenght of common words in both of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true=[]\n",
        "y_pred=[]\n",
        "\n",
        "for i in range(len(fsi_list_for_ground_truth)):\n",
        "    \n",
        "    try:\n",
        "        keys=fsi_list_for_ground_truth[i].keys()\n",
        "        if (len(keys) !=0):\n",
        "            temp_s = copy.deepcopy(fsi_list_for_ground_truth[i])\n",
        "            del temp_s['document']\n",
        "            \n",
        "            \n",
        "            ground_truth_keys = list(temp_s.keys())\n",
        "            ground_truth_values = list(temp_s.values())\n",
        "            \n",
        "            model_results=extract_dictionary_from_results(polish_results(results[i]['generated_text']))\n",
        "            \n",
        "            model_res_keys=list(model_results.keys())\n",
        "            model_res_values=list(model_results.values())\n",
        "            \n",
        "          \n",
        "            \n",
        "            for k in ground_truth_keys:\n",
        "                if ('phrase_' in k):\n",
        "                    \n",
        "                    phrase=temp_s[k]\n",
        "                    \n",
        "                    for v in model_res_values:\n",
        "                        if (len(find_common_words(drop_words(phrase),drop_words(v)))/len(phrase.split())>0.5):\n",
        "                            ground_truth_label = temp_s['label_'+(ground_truth_keys[ground_truth_values.index(phrase)].strip('phrase_'))]\n",
        "                            model_res_label=model_results['label_'+(model_res_keys[model_res_values.index(v)].strip('phrase_'))]\n",
        "                            \n",
        "                            if (model_res_label==ground_truth_label):\n",
        "                                y_true.append(1)\n",
        "                                y_pred.append(1)\n",
        "                            else:\n",
        "                                y_true.append(1)\n",
        "                                y_pred.append(0)\n",
        "                            \n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "        \n",
        "len_y_true = len(y_true)\n",
        "len_y_pred = len(y_pred)\n",
        "\n",
        "fsi_ners=copy.deepcopy(fsi_list_for_ground_truth)\n",
        "\n",
        "try:\n",
        "    del fsi_ners['document']\n",
        "    \n",
        "except:\n",
        "    pass\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "len_y_true = len(y_true)\n",
        "len_y_pred = len(y_pred)\n",
        "\n",
        "for i in range(len(fsi_list_for_ground_truth)):\n",
        "    fsi_ners=copy.deepcopy(fsi_list_for_ground_truth[i])\n",
        "    try:\n",
        "        del fsi_ners['document']\n",
        "       \n",
        "        \n",
        "        model_ners=extract_dictionary_from_results(results[i]['generated_text'])\n",
        "       \n",
        "        \n",
        "        if (len(fsi_ners)>len(model_ners)):\n",
        "            diff = len(fsi_ners)-len(model_ners)\n",
        "            \n",
        "            for j in range(len(diff)):\n",
        "                y_true.append(1)\n",
        "                y_pred.append(0)\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "print(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.47      0.64        15\n",
            "\n",
            "    accuracy                           0.47        15\n",
            "   macro avg       0.50      0.23      0.32        15\n",
            "weighted avg       1.00      0.47      0.64        15\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_pred=y_pred,y_true=y_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's only apply for single entity of Location"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SINGLE ENTITY\n",
        "Single entity case: We tried a single entity extraction as well. It is essential to consider the quality of the extraction process. If the objective is to extract multiple entity types and the accuracy is not good enough,you may want to experiment with a smaller set of entity types at a time to see whether the accuracy can be improved (as there are more examples of that entity type that can fit in the context of the model, compared to the case of many entity types). \n",
        "\n",
        "Here, we are trying to experiment with a single entity type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "specific_label = 'LOC'\n",
        "desc = 'location'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_replacement_dictionary={'GPE':'LOC'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "instruction=f\"\"\"\n",
        "Accurately identify and classify the \n",
        "NERs of type {desc} ({specific_label}).\n",
        "\n",
        "Return your responses in dictionary format. for the each item you found, provide the \"phrase\" and\n",
        "the corresponding \"label\" along with their number as dictionary key separated by numbers. \n",
        "Increment the 'phrase_' and 'label_' for the next NER.Each 'phrase_' should be coupled with a 'label_'.\n",
        "Make sure to encapsulate the found phrases and labels in single quotation mark.\n",
        "For instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\n",
        "Use the following training examples as follows:\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accurately identify and classify the \n",
            "NERs of type location (LOC).\n",
            "\n",
            "Return your responses in dictionary format. for the each item you found, provide the \"phrase\" and\n",
            "the corresponding \"label\" along with their number as dictionary key separated by numbers. \n",
            "Increment the 'phrase_' and 'label_' for the next NER.Each 'phrase_' should be coupled with a 'label_'.\n",
            "Make sure to encapsulate the found phrases and labels in single quotation mark.\n",
            "For instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\n",
            "Use the following training examples as follows:\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(instruction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function replaces the ground truth lables with the desired one as mentioned in the replacement dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def replace_label_values(examples,label_replacement_dictionary):\n",
        "    examples_cp = copy.deepcopy(examples)\n",
        "    for i in range(len(examples_cp)):\n",
        "        keys = list(examples_cp[i].keys())\n",
        "        for k in keys:\n",
        "            if 'label_' in k:\n",
        "                for rl in label_replacement_dictionary.keys():\n",
        "                    if (examples_cp[i][k] == rl):\n",
        "                        examples_cp[i][k]=label_replacement_dictionary[rl]\n",
        "    return examples_cp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "post_processed_examples = replace_label_values(example_dic_list,label_replacement_dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"document\": \"\\\"In 1999\\u00a0New Scientist\\u00a0reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas\\u00a0could disappear by 2035.\",\n",
            "        \"phrase_0\": \"1999\",\n",
            "        \"label_0\": \"DATE\",\n",
            "        \"phrase_1\": \"Indian\",\n",
            "        \"label_1\": \"NORP\",\n",
            "        \"phrase_2\": \"Syed Hasnain\",\n",
            "        \"label_2\": \"PERSON\",\n",
            "        \"phrase_3\": \"Himalayas\",\n",
            "        \"label_3\": \"LOC\",\n",
            "        \"phrase_4\": \"2035\",\n",
            "        \"label_4\": \"DATE\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"\\\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads,\\u00a0on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\",\n",
            "        \"phrase_0\": \"U.S.\",\n",
            "        \"label_0\": \"LOC\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"Skeptics who oppose scientific findings that threaten their world view are far closer to Galileo's belief-based critics in the Catholic Church.\",\n",
            "        \"phrase_0\": \"Galileo\",\n",
            "        \"label_0\": \"PRODUCT\",\n",
            "        \"phrase_1\": \"the Catholic Church\",\n",
            "        \"label_1\": \"ORG\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"Pollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\",\n",
            "        \"phrase_0\": \"DeConto\",\n",
            "        \"label_0\": \"LOC\",\n",
            "        \"phrase_1\": \"first\",\n",
            "        \"label_1\": \"ORDINAL\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "json_formatted_str = json.dumps(post_processed_examples[:4], indent=4)\n",
        "print(json_formatted_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def keep_only_certain_labels(examples, specific_label):\n",
        "    list_of_modified_examples=[]\n",
        "    for e in examples:\n",
        "        e_cp = copy.deepcopy(e)\n",
        "        keys = list(e_cp.keys())\n",
        "        \n",
        "        for k in keys:\n",
        "            if 'label_' in k:\n",
        "                numeric_val = k.split('label_')[1]\n",
        "                #print('NV=',numeric_val)\n",
        "                if (e_cp[k]!=specific_label):\n",
        "                    del e_cp[k]\n",
        "                    del e_cp['phrase_'+numeric_val]\n",
        "        \n",
        "        if(len(e_cp)>1):\n",
        "            list_of_modified_examples.append(e_cp)\n",
        "    \n",
        "    return list_of_modified_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "modified_examples_list = keep_only_certain_labels(post_processed_examples, specific_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"document\": \"\\\"In 1999\\u00a0New Scientist\\u00a0reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas\\u00a0could disappear by 2035.\",\n",
            "        \"phrase_3\": \"Himalayas\",\n",
            "        \"label_3\": \"LOC\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"\\\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads,\\u00a0on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\",\n",
            "        \"phrase_0\": \"U.S.\",\n",
            "        \"label_0\": \"LOC\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"Pollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\",\n",
            "        \"phrase_0\": \"DeConto\",\n",
            "        \"label_0\": \"LOC\"\n",
            "    },\n",
            "    {\n",
            "        \"document\": \"the world is barely half a degree Celsius (0.9 degrees Fahrenheit) warmer than it was about 35 years ago\",\n",
            "        \"phrase_2\": \"Fahrenheit\",\n",
            "        \"label_2\": \"LOC\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "json_formatted_str = json.dumps(modified_examples_list, indent=4)\n",
        "print(json_formatted_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "examples=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(modified_examples_list)):\n",
        "    examples.append('document: \\n'+modified_examples_list[i]['document']+'\\n')\n",
        "    di=copy.deepcopy(modified_examples_list[i])\n",
        "    del di['document']\n",
        "    examples.append('\\n')\n",
        "    examples.append(str(di))\n",
        "    examples.append('\\n\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "examples_input=''.join(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "document: \n",
            "\"In 1999 New Scientist reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas could disappear by 2035.\n",
            "\n",
            "{'phrase_3': 'Himalayas', 'label_3': 'LOC'}\n",
            "\n",
            "\n",
            "document: \n",
            "\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads, on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\n",
            "\n",
            "{'phrase_0': 'U.S.', 'label_0': 'LOC'}\n",
            "\n",
            "\n",
            "document: \n",
            "Pollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\n",
            "\n",
            "{'phrase_0': 'DeConto', 'label_0': 'LOC'}\n",
            "\n",
            "\n",
            "document: \n",
            "the world is barely half a degree Celsius (0.9 degrees Fahrenheit) warmer than it was about 35 years ago\n",
            "\n",
            "{'phrase_2': 'Fahrenheit', 'label_2': 'LOC'}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(examples_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = []\n",
        "for inp in few_shot_inputs_[:40]:\n",
        "    results.append(prompt.generate(\" \".join([instruction+examples_input+ \"document:\" +inp['input']]), model_id, parameters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"generated_text\": \"phrase_0: \\\"the ocean waters and this environment that we live in.\\\", 'label_0': 'LOC'\",\n",
            "        \"generated_token_count\": 31,\n",
            "        \"input_token_count\": 495,\n",
            "        \"stop_reason\": \"eos_token\"\n",
            "    },\n",
            "    {\n",
            "        \"generated_text\": \"phrase_0: \\\"The Rio Grande\\\", 'label_0': 'LOC'\",\n",
            "        \"generated_token_count\": 24,\n",
            "        \"input_token_count\": 510,\n",
            "        \"stop_reason\": \"eos_token\"\n",
            "    },\n",
            "    {\n",
            "        \"generated_text\": \"phrase_0': \\\"the Mountain West\\\", 'label_0': 'LOC', phrase_1': \\\"the Pacific Northwest\\\", 'label_1': 'LOC'\",\n",
            "        \"generated_token_count\": 48,\n",
            "        \"input_token_count\": 510,\n",
            "        \"stop_reason\": \"eos_token\"\n",
            "    },\n",
            "    {\n",
            "        \"generated_text\": \"phrase_0: carbon dioxide emissions label_0: 'LOC'\",\n",
            "        \"generated_token_count\": 21,\n",
            "        \"input_token_count\": 486,\n",
            "        \"stop_reason\": \"eos_token\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "json_formatted_str = json.dumps(results[:4], indent=4)\n",
        "print(json_formatted_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def polish_results(r):\n",
        "    \n",
        "    sp=r.split(',')\n",
        "    \n",
        "    nw=[]\n",
        "    for w in sp:\n",
        "        b=''\n",
        "        b=w.replace('\"', '').replace(\"'\", \"\")\n",
        "        nw.append(b)\n",
        "        \n",
        "    msl=[]\n",
        "    for w in nw:\n",
        "        ns=w.split(\":\")\n",
        "        nss=[]\n",
        "        for i in range(len(ns)):\n",
        "            ns[i]=ns[i].lstrip()\n",
        "        nss.append(\"'\"+ns[0]+\"'\"+':'+\"'\"+ns[1]+\"'\")\n",
        "\n",
        "        ms=''.join(nss)\n",
        "        msl.append(ms)\n",
        "\n",
        "    res=','.join(msl)\n",
        "    \n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'phrase_0':'the Mountain West','label_0':'LOC','phrase_1':'the Pacific Northwest','label_1':'LOC'\n"
          ]
        }
      ],
      "source": [
        "print(polish_results(results[2]['generated_text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'phrase_0': 'the Mountain West', 'label_0': 'LOC', 'phrase_1': 'the Pacific Northwest', 'label_1': 'LOC'}\n"
          ]
        }
      ],
      "source": [
        "print(extract_dictionary_from_results(polish_results(results[2]['generated_text'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'phrase_0': 'the ocean waters and this environment that we live in.', 'label_0': 'LOC'}\n"
          ]
        }
      ],
      "source": [
        "print(extract_dictionary_from_results(polish_results(results[0]['generated_text'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true=[]\n",
        "y_pred=[]\n",
        "\n",
        "for i in range(len(fsi_list_for_ground_truth)):\n",
        "    try:\n",
        "        keys=fsi_list_for_ground_truth[i].keys()\n",
        "        if (len(keys) !=0):\n",
        "            temp_s = copy.deepcopy(fsi_list_for_ground_truth[i])\n",
        "            del temp_s['document']\n",
        "      \n",
        "            \n",
        "            ground_truth_keys = list(temp_s.keys())\n",
        "            ground_truth_values = list(temp_s.values())\n",
        "            \n",
        "            model_results=extract_dictionary_from_results(polish_results(results[i]['generated_text']))\n",
        "            \n",
        "            model_res_keys=list(model_results.keys())\n",
        "            model_res_values=list(model_results.values())\n",
        "            \n",
        "            \n",
        "            \n",
        "            for k in ground_truth_keys:\n",
        "                if ('phrase_' in k):\n",
        "                  \n",
        "                    phrase=temp_s[k]\n",
        "                   \n",
        "                    for v in model_res_values:\n",
        "                        if (len(find_common_words(drop_words(phrase),drop_words(v)))/len(phrase.split())>0.5):\n",
        "\n",
        "                            ground_truth_label = temp_s['label_'+(ground_truth_keys[ground_truth_values.index(phrase)].strip('phrase_'))]\n",
        "                            \n",
        "                            if (ground_truth_label==specific_label):\n",
        "                                model_res_label=model_results['label_'+(model_res_keys[model_res_values.index(v)].strip('phrase_'))]\n",
        "\n",
        "                                if (model_res_label==ground_truth_label):\n",
        "                                    y_true.append(1)\n",
        "                                    y_pred.append(1)\n",
        "                                else:\n",
        "                                    y_true.append(1)\n",
        "                                    y_pred.append(0)\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "        \n",
        "len_y_true = len(y_true)\n",
        "len_y_pred = len(y_pred)\n",
        "\n",
        "fsi_ners=copy.deepcopy(fsi_list_for_ground_truth)\n",
        "\n",
        "try:\n",
        "    del fsi_ners['document']\n",
        "    \n",
        "except:\n",
        "    pass\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "len_y_true = len(y_true)\n",
        "len_y_pred = len(y_pred)\n",
        "\n",
        "for i in range(len(fsi_list_for_ground_truth)):\n",
        "    fsi_ners=copy.deepcopy(fsi_list_for_ground_truth[i])\n",
        "    try:\n",
        "        del fsi_ners['document']\n",
        "        \n",
        "        \n",
        "        model_ners=extract_dictionary_from_results(results[i]['generated_text'])\n",
        "       \n",
        "        \n",
        "        if (len(fsi_ners)>len(model_ners)):\n",
        "            diff = len(fsi_ners)-len(model_ners)\n",
        "            \n",
        "            for j in range(len(diff)):\n",
        "                y_true.append(1)\n",
        "                y_pred.append(0)\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 1, 1, 1]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 1, 1, 1]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_pred=y_pred,y_true=y_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        " You successfully completed this notebook!\n",
        " \n",
        " You learned how to extract named entities with Google's `google/flan-ul2` on watsonx. \n",
        " \n",
        " Check out our <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"Online Documentation\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " **Author: Kahila Mokhtari**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Copyright © 2023-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}