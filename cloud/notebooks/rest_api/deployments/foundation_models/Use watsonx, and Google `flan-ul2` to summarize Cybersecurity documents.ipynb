{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and Google `flan-ul2` to summarize Cybersecurity documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook contains the steps and code to demonstrate support of text summarization in watsonx. It introduces commands for data retrieval and model testing.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The goal of this notebook is to demonstrate how to use `ul2` model to summarize cybersecurity: SPEC5G Cellular Network Protocol.\n",
        "\n",
        "## Use case & dataset\n",
        "\n",
        "5G is the 5th generation cellular network protocol. It is the state-of-the-art global wireless standard that enables an advanced kind of network designed to connect virtually everyone and everything with increased speed and reduced latency. Therefore, its development, analysis, and security are critical. However, all approaches to the 5G protocol development and security analysis, e.g., property extraction, protocol summarization, and semantic analysis of the protocol specifications and implementations are completely manual. To reduce such manual effort,foundation model are used to summarize the paragraphs automitically. The dataset that is used in this notebook has two columns which are paragraph and simplification(summary).\n",
        "\n",
        "\n",
        "\n",
        "## Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Data loading](#data)\n",
        "- [Foundation Models on watsonx](#models)\n",
        "- [Model testing](#predict)\n",
        "- [Score](#score)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "##  Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install and import the `datasets` and dependecies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!pip install datasets | tail -n 1\n",
        "!pip install requests | tail -n 1\n",
        "!pip install wget | tail -n 1\n",
        "!pip install ibm-cloud-sdk-core | tail -n 1\n",
        "!pip install \"scikit-learn==1.3.2\" | tail -n 1\n",
        "!pip install rouge | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os, getpass, wget\n",
        "import requests\n",
        "from ibm_cloud_sdk_core import IAMTokenManager\n",
        "from pandas import read_csv, DataFrame\n",
        "from rouge import Rouge\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inferencing class\n",
        "This cell defines a class that makes a REST API call to the watsonx Foundation Model\n",
        "inferencing API that we will use to generate output from the provided input.\n",
        "The class takes the access token created in the previous step, and uses it to\n",
        "make a REST API call with input, model id and model parameters. The response\n",
        "from the API call is returned as the cell output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Action:** Provide watsonx.ai Runtime url to work with watsonx.ai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint_url = input(\"Please enter your watsonx.ai Runtime endpoint url (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a `Prompt` class for prompts generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Prompt:\n",
        "    def __init__(self, access_token, project_id):\n",
        "        self.access_token = access_token\n",
        "        self.project_id = project_id\n",
        "\n",
        "    def generate(self, input, model_id, parameters):\n",
        "        wml_url = f\"{endpoint_url}/ml/v1/text/generation?version=2024-03-19\"\n",
        "        Headers = {\n",
        "            \"Authorization\": \"Bearer \" + self.access_token,\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Accept\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model_id\": model_id,\n",
        "            \"input\": input,\n",
        "            \"parameters\": parameters,\n",
        "            \"project_id\": self.project_id\n",
        "        }\n",
        "        response = requests.post(wml_url, json=data, headers=Headers)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()[\"results\"][0]\n",
        "        else:\n",
        "            return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### watsonx API connection\n",
        "This cell defines the credentials required to work with watsonx API for Foundation\n",
        "Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"IBM Cloud user API key\">documentation</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "access_token = IAMTokenManager(\n",
        "    apikey = getpass.getpass(\"Please enter your watsonx.ai api key (hit enter): \"),\n",
        "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
        ").get_token()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the project id\n",
        "The API requires project id that provides the context for the call. We will obtain\n",
        "the id from the project in which this notebook runs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"data\"></a>\n",
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the `cybersecurity: SPEC5G Cellular Network Protocol` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = 'Data_Cyber.csv'\n",
        "url = 'https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/data/spec5g/spec5g.csv'\n",
        "if not os.path.isfile(filename): wget.download(url, out=filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Paragraph</th>\n",
              "      <th>Simplification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 5G NR, for the procedures such as handover ...</td>\n",
              "      <td>In 5G NR, signal strength or signal quality ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5G NR has introduced cell signal measurement b...</td>\n",
              "      <td>5G NR measures cell signal with SS/PBCH Block ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Radio (NR) is the wireless standard and fo...</td>\n",
              "      <td>New Radio (NR) is the wireless standard and fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Current regulations in the U.S. allow a device...</td>\n",
              "      <td>Current literature and presentations at variou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In general, it is  very critical for a UE to c...</td>\n",
              "      <td>It is important for UE to consider the certain...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Paragraph  \\\n",
              "0  In 5G NR, for the procedures such as handover ...   \n",
              "1  5G NR has introduced cell signal measurement b...   \n",
              "2  New Radio (NR) is the wireless standard and fo...   \n",
              "3  Current regulations in the U.S. allow a device...   \n",
              "4  In general, it is  very critical for a UE to c...   \n",
              "\n",
              "                                      Simplification  \n",
              "0  In 5G NR, signal strength or signal quality ma...  \n",
              "1  5G NR measures cell signal with SS/PBCH Block ...  \n",
              "2  New Radio (NR) is the wireless standard and fo...  \n",
              "3  Current literature and presentations at variou...  \n",
              "4  It is important for UE to consider the certain...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data= read_csv(\"Data_Cyber.csv\", index_col=0)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect data sample. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Check the sample text and summary length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The original text lenght statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    713.000000\n",
              "mean     101.632539\n",
              "std       34.300754\n",
              "min       35.000000\n",
              "25%       78.000000\n",
              "50%       98.000000\n",
              "75%      121.000000\n",
              "max      266.000000\n",
              "Name: Paragraph, dtype: float64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Paragraph.apply(lambda x: len(x.split())).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reference summary lenght statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    713.000000\n",
              "mean      43.927069\n",
              "std       24.889311\n",
              "min        8.000000\n",
              "25%       28.000000\n",
              "50%       38.000000\n",
              "75%       53.000000\n",
              "max      249.000000\n",
              "Name: Simplification, dtype: float64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Simplification.apply(lambda x: len(x.split())).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split data to train and test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train, data_test, y_train, y_test = train_test_split(data['Paragraph'], \n",
        "                                                    data['Simplification'],\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=33,)\n",
        "data_train = DataFrame(data_train)\n",
        "data_test = DataFrame(data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"models\"></a>\n",
        "## Foundation Models on watsonx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bigcode/starcoder',\n",
              " 'bigscience/mt0-xxl',\n",
              " 'codellama/codellama-34b-instruct-hf',\n",
              " 'eleutherai/gpt-neox-20b',\n",
              " 'google/flan-t5-xl',\n",
              " 'google/flan-t5-xxl',\n",
              " 'google/flan-ul2',\n",
              " 'ibm-mistralai/mixtral-8x7b-instruct-v01-q',\n",
              " 'ibm/granite-13b-chat-v1',\n",
              " 'ibm/granite-13b-chat-v2',\n",
              " 'ibm/granite-13b-instruct-v1',\n",
              " 'ibm/granite-13b-instruct-v2',\n",
              " 'ibm/granite-20b-multilingual',\n",
              " 'ibm/mpt-7b-instruct2',\n",
              " 'meta-llama/llama-2-13b-chat',\n",
              " 'meta-llama/llama-2-70b-chat']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models_json = requests.get(endpoint_url + '/ml/v1/foundation_model_specs?version=2024-03-19&limit=50',\n",
        "                           headers={\n",
        "                                    'Authorization': f'Bearer {access_token}',\n",
        "                                    'Content-Type': 'application/json',\n",
        "                                    'Accept': 'application/json'\n",
        "                            }).json()\n",
        "models_ids = [m['model_id'] for m in models_json['resources']]\n",
        "models_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You need to specify `model_id` that will be used for inferencing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_id = \"google/flan-ul2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"predict\"></a>\n",
        "##  Generate document summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define instructions for the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "instruction =  \"\"\"\n",
        "Extract the key outline of the \"Original text\" similar to the Simplification according to the examples.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare model inputs for zero-shot example, use below zero_shot_inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentence example 1 is:\n",
            " UE A can then prompt the user to initiate a voice call to UE B 6a(Successful case). The RAB Assignment Request message is sent from MSC B to the RNC B, requesting the establishment of a RAB for a Video Call.\n",
            " The radio bearer is established between the RNC B and UE B.\n",
            " RNC B responds to MSC B with a RAB Assignment Response message.\n",
            " Following the allocation of the radio resources, UE B sends an Alerting message to 6b (Failure case). The video call fails because of lack of radio resources on the B side.\n",
            " \n",
            "\n",
            "The sentence example 2 is:\n",
            " As a network option, the operator may refuse to provide the requested information. When gsmSCF processing is complete the call control is returned to the GMSC server .\n",
            " The GMSC server interrogates the HLR in order to determine his current location.\n",
            " The HLR shall create an HLR interrogation record. The GMSC server routes the call to the VPLMN in which subscriber \"B\" is currently located.\n",
            " The GMSC server shall create an outgoing gateway record for accounting purposes.\n",
            " The GMSC server shall also create a roaming record.\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "zero_shot_inputs = [{\"input\": text} for text in data_test['Paragraph']]\n",
        "for i in range(2):\n",
        "    print(f\"The sentence example {i+1} is:\\n {zero_shot_inputs[i]['input']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare model inputs for few-shot examples, use below few_shot_inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train_and_labels=data_train.copy()\n",
        "data_train_and_labels['Simplification']=y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "train_samples=data_train_and_labels.sample(2)\n",
        "few_shot_example=[]\n",
        "examples = []\n",
        "for s in range(len(train_samples)):\n",
        "    examples.append(f\"\\tsentence:\\t{train_samples['Paragraph'].iloc[s]}\\n\\tSimplification: {train_samples['Simplification'].iloc[s]}\\n\")\n",
        "few_shot_examples=[''.join(examples)]\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentence example 1 is:\n",
            " UE A can then prompt the user to initiate a voice call to UE B 6a(Successful case). The RAB Assignment Request message is sent from MSC B to the RNC B, requesting the establishment of a RAB for a Video Call.\n",
            " The radio bearer is established between the RNC B and UE B.\n",
            " RNC B responds to MSC B with a RAB Assignment Response message.\n",
            " Following the allocation of the radio resources, UE B sends an Alerting message to 6b (Failure case). The video call fails because of lack of radio resources on the B side.\n",
            " \n",
            "\n",
            "The sentence example 2 is:\n",
            " As a network option, the operator may refuse to provide the requested information. When gsmSCF processing is complete the call control is returned to the GMSC server .\n",
            " The GMSC server interrogates the HLR in order to determine his current location.\n",
            " The HLR shall create an HLR interrogation record. The GMSC server routes the call to the VPLMN in which subscriber \"B\" is currently located.\n",
            " The GMSC server shall create an outgoing gateway record for accounting purposes.\n",
            " The GMSC server shall also create a roaming record.\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "few_shot_inputs_ = [{\"input\": text} for text in data_test['Paragraph'].values]\n",
        "for i in range(2):\n",
        "    print(f\"The sentence example {i+1} is:\\n {few_shot_inputs_[i]['input']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the model parameters\n",
        "We need to provide a set of model parameters that will influence the\n",
        "result. Based on decoding strategy that ww have for the models, the parameters can change.\n",
        "\n",
        "There are two decoding strategies: `greedy` and `sampling`.\n",
        "\n",
        "We usually use `greedy` for complaint classification, extraction and Q&A.\n",
        "\n",
        "We usually use `sampling` for content generation and summarization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters = {\n",
        "         \"decoding_method\": \"greedy\",\n",
        "         \"random_seed\": 33,\n",
        "         \"repetition_penalty\":1,\n",
        "         \"min_new_tokens\": 50,\n",
        "         \"max_new_tokens\": 300\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate the cybersecurity: SPEC5G Cellular Network Protocol summary using `ul2` model.\n",
        "\n",
        "\n",
        "**Note:** You might need to adjust model `parameters` for different models or tasks, to do so please refer to <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/fm_model.html#metanames.GenTextParamsMetaNames\" target=\"_blank\" rel=\"GenTextParamsMetaNames params\">documentation</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the `Prompt` class.\n",
        "\n",
        "**Hint:** Your authentication token might expire, if so please regenerate the `access_token` reinitialize the `Prompt` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = Prompt(access_token, project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the docs summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = []\n",
        "for inp in few_shot_inputs_[:2]:\n",
        "    results.append(prompt.generate(\" \".join([instruction+few_shot_examples[0], inp['input']]), model_id, parameters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'Simplification: UE A can then prompt the user to initiate a voice call to UE B 6a(Successful case). The RAB Assignment Request message is sent from MSC B to the RNC B, requesting the establishment of a RAB for a Video Call. The radio bearer is established between the RNC B and UE B. RNC B responds to MSC B with a RAB Assignment Response message. Following the allocation of the radio resources, UE B sends an Alerting message to',\n",
              "  'generated_token_count': 118,\n",
              "  'input_token_count': 471,\n",
              "  'stop_reason': 'eos_token'},\n",
              " {'generated_text': 'Simplification: The GMSC server interrogates the HLR in order to determine his current location. The GMSC server routes the call to the VPLMN in which subscriber \"B\" is currently located. The GMSC server shall create an outgoing gateway record for accounting purposes. The GMSC server shall also create a roaming record.',\n",
              "  'generated_token_count': 78,\n",
              "  'input_token_count': 459,\n",
              "  'stop_reason': 'eos_token'}]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"score\"></a>\n",
        "## Score the model\n",
        "\n",
        "#### Cosine Similarity \n",
        "\n",
        "**Note:** To run the Score section for model scoring on the cybersecurity dataset please transform following `markdown` cells to `code` cells.\n",
        "Have in mind that scoring model on the whole test set can take significant amount of time.\n",
        "\n",
        "In this sample notebook `spacy` implementation of cosine similarity for `en_core_web_md`  corpus was used for cosine similarity calculation.\n",
        "\n",
        "**Tip:** You might consider using bigger language corpus, different word embeddings and distance metrics for output summary scoring against the reference summary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the true labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "y_true = y_test.values[:2]\n",
        "print(y_true)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the prediction labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "y_pred = [result['generated_text'] for result in results]\n",
        "y_pred\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use `spacy` and `en_core_web_md` corpus to calculate cosine similarity of generated and reference summaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "!pip install -U spacy | tail -1\n",
        "!python -m spacy download en_core_web_md | tail -1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "import spacy\n",
        "import en_core_web_md\n",
        "nlp = en_core_web_md.load()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "for truth, pred in zip(y_true, y_pred):\n",
        "    t = nlp(truth)\n",
        "    p = nlp(pred)\n",
        "    print(\"Reference summary similarity with the predicted summary\", t.similarity(p))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Rouge Metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: Rouge (Recall-Oriented Understudy for Gisting Evaluation) metric is a set of evaluation measures used in natural language processing (NLP) and specifically in text summarization tasks. Please refer to below link for more information:\n",
        "<a href=\"https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html\" target=\"_blank\" rel=\"noopener no referrer\">torchmetrics</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "rouge = Rouge()\n",
        "scores=[]\n",
        "for i in range(len(y_true)):\n",
        "    \n",
        "    score = rouge.get_scores(y_true[i], y_pred[i])\n",
        "    scores.append(score)\n",
        "scores\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        " You successfully completed this notebook!.\n",
        " \n",
        " You learned how to generate documents summaries with Google's `flan-ul2` on watsonx. \n",
        " \n",
        " Check out our <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"Online Documentation\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts. \n",
        " \n",
        " **Author: Kahila Mokhtari**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Copyright © 2023-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
