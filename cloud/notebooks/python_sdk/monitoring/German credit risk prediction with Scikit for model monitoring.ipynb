{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German credit risk prediciton with Scikit-learn for model monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be run in a Watson Studio project, using **Default Python 3.6** runtime environment. It requires service credentials for the following Cloud services:\n",
    "  * Watson Machine Learning V4\n",
    "\n",
    "The notebook will train, create and deploy a German Credit Risk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning goals\n",
    "\n",
    "In this notebook, you will learn how to:\n",
    "\n",
    "-  Explore data\n",
    "-  Prepare data for training and evaluation\n",
    "-  Create a scikit-learn pipeline\n",
    "-  Train and evaluate a model\n",
    "-  Store a model in the Watson Machine Learning (WML) repository\n",
    "-  Deploy and score the model\n",
    "\n",
    "### Contents\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Explore Data](#explore)\n",
    "- [Create a model](#create_model)\n",
    "- [Publish the model](#publish_model)\n",
    "- [Deploy and score](#deploy_model)\n",
    "- [Clean up](#cleanup)\n",
    "- [Summary](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to WML\n",
    "\n",
    "Authenticate the Watson Machine Learning service on IBM Cloud. You need to provide platform `api_key` and instance `location`.\n",
    "\n",
    "You can use [IBM Cloud CLI](https://cloud.ibm.com/docs/cli/index.html) to retrieve platform API Key and instance location.\n",
    "\n",
    "API Key can be generated in the following way:\n",
    "```\n",
    "ibmcloud login\n",
    "ibmcloud iam api-key-create API_KEY_NAME\n",
    "```\n",
    "\n",
    "In result, get the value of `api_key` from the output.\n",
    "\n",
    "\n",
    "Location of your WML instance can be retrieved in the following way:\n",
    "```\n",
    "ibmcloud login --apikey API_KEY -a https://cloud.ibm.com\n",
    "ibmcloud resource service-instance WML_INSTANCE_NAME\n",
    "```\n",
    "\n",
    "In result, get the value of `location` from the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: Your `Cloud API key` can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.\n",
    "\n",
    "You can also get service specific apikey by going to the [**Service IDs** section of the Cloud Console](https://cloud.ibm.com/iam/serviceids).  From that page, click **Create**, then copy the created key and paste it below.\n",
    "\n",
    "**Action**: Enter your `api_key` and `location` in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = 'PASTE YOUR PLATFORM API KEY HERE'\n",
    "location = 'PASTE YOUR INSTANCE LOCATION HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": apikeyv,\n",
    "    \"url\": 'https://' + location + '.ml.cloud.ibm.com'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import the `ibm-watson-machine-learning` package\n",
    "**Note:** `ibm-watson-machine-learning` documentation can be found <a href=\"http://ibm-wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with spaces\n",
    "\n",
    "First of all, you need to create a space that will be used for your work. If you do not have space already created, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create one.\n",
    "\n",
    "- Click New Deployment Space\n",
    "- Create an empty space\n",
    "- Select Cloud Object Storage\n",
    "- Select Watson Machine Learning instance and press Create\n",
    "- Copy `space_id` and paste it below\n",
    "\n",
    "**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
    "\n",
    "**Action**: Assign space ID below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_id = 'PASTE YOUR SPACE ID HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `list` method to print all existing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.spaces.list(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to interact with all resources available in Watson Machine Learning, you need to set **space** which you will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next cells, you will need to paste some credentials to Cloud Object Storage. If you haven't worked with COS yet please visit [getting started with COS tutorial](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started). \n",
    "You can find `COS_API_KEY_ID` and `COS_RESOURCE_CRN` variables in **_Service Credentials_** in menu of your COS instance. Used COS Service Credentials must be created with _Role_ parameter set as Writer. Later training data file will be loaded to the bucket of your instance and used as training refecence in subsription.  \n",
    "`COS_ENDPOINT` variable can be found in **_Endpoint_** field of the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COS_API_KEY_ID = \"***\"\n",
    "COS_RESOURCE_CRN = \"***\" \n",
    "COS_ENDPOINT = \"***\"\n",
    "IAM_AUTH_ENDPOINT = \"***\"\n",
    "BUCKET_NAME = \"***\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the notebook\n",
    "\n",
    "At this point, the notebook is ready to run. You can either run the cells one at a time, or click the **Kernel** option above and select **Restart and Run All** to run all the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn how to train Scikit-learn model and next deploy it as web-service using Watson Machine Learning service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm german_credit_data_biased_training.csv\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_data_biased_training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "training_data_file_name = \"german_credit_data_biased_training.csv\"\n",
    "data_df = pd.read_csv(training_data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data <a name=\"explore\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Columns: ', list(data_df.columns))\n",
    "print('Number of columns: ', len(data_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data contains twenty one fields. `Risk` field is the one you would like to predict using feedback data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Number of records: ', data_df.Risk.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = data_df.groupby('Risk')['Risk'].count()\n",
    "target_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count.plot.pie(figsize=(8, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save training data to Cloud Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config, ClientError\n",
    "\n",
    "cos_client = ibm_boto3.resource(\"s3\",\n",
    "    ibm_api_key_id=COS_API_KEY_ID,\n",
    "    ibm_service_instance_id=COS_RESOURCE_CRN,\n",
    "    ibm_auth_endpoint=IAM_AUTH_ENDPOINT,\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=COS_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_data_file_name, \"rb\") as file_data:\n",
    "    cos_client.Object(BUCKET_NAME, training_data_file_name).upload_fileobj(\n",
    "        Fileobj=file_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model <a name=\"create_model\"></a>\n",
    "In this section you will learn how to:\n",
    "\n",
    "- Prepare data for training a model\n",
    "- Create machine learning pipeline\n",
    "- Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Scikit German Risk Model WML V4\"\n",
    "\n",
    "DEPLOYMENT_NAME = \"Scikit German Risk Deployment WML V4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will start with importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_idx = np.s_[0:-1]\n",
    "all_records_idx = np.s_[:]\n",
    "first_record_idx = np.s_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step you will encode target column labels into numeric values. You can use `inverse_transform` to decode numeric predictions into labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_fields = [type(fld) is str for fld in train_data.iloc[first_record_idx, features_idx]]\n",
    "ct = ColumnTransformer([(\"ohe\", OneHotEncoder(), list(np.array(train_data.columns)[features_idx][string_fields]))])\n",
    "clf_linear = SGDClassifier(loss='log', penalty='l2', max_iter=1000, tol=1e-5)\n",
    "\n",
    "pipeline_linear = Pipeline([('ct', ct), ('clf_linear', clf_linear)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model = pipeline_linear.fit(train_data.drop('Risk', axis=1), train_data.Risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = risk_model.predict(test_data.drop('Risk', axis=1))\n",
    "indexed_preds = [0 if prediction=='No Risk' else 1 for prediction in predictions]\n",
    "\n",
    "real_observations = test_data.Risk.replace('Risk', 1)\n",
    "real_observations = real_observations.replace('No Risk', 0).values\n",
    "\n",
    "auc = roc_auc_score(real_observations, indexed_preds)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the model <a name=\"publish_model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the notebook uses the supplied Watson Machine Learning credentials to save the model (including the pipeline) to the WML instance. Previous versions of the model are removed so that the notebook can be run again, resetting all data for another demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "software_spec_uid = client.software_specifications.get_id_by_name(\"scikit-learn_0.20-py3.6\")\n",
    "print(\"Software Specification ID: {}\".format(software_spec_uid))\n",
    "model_props = {\n",
    "    client.repository.ModelMetaNames.NAME: \"{}\".format(MODEL_NAME),\n",
    "    client.repository.ModelMetaNames.TYPE: 'scikit-learn_0.20',\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Storing model ...\")\n",
    "\n",
    "published_model_details = client.repository.store_model(model=risk_model, meta_props=model_props, training_data=data_df.drop([\"Risk\"], axis=1), training_target=data_df.Risk)\n",
    "model_uid = client.repository.get_model_uid(published_model_details)\n",
    "print(\"Done\")\n",
    "print(\"Model ID: {}\".format(model_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and score <a name=\"deploy_model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section of the notebook deploys the model as a RESTful web service in Watson Machine Learning. The deployed model will have a scoring URL you can use to send data to the model for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Deploying model...\")\n",
    "metadata = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: DEPLOYMENT_NAME,\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}\n",
    "deployment = client.deployments.create(model_uid, meta_props=metadata)\n",
    "deployment_uid = client.deployments.get_uid(deployment)\n",
    "    \n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\",\n",
    "                  \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\",\n",
    "                  \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n",
    "                  \"Telephone\", \"ForeignWorker\"]\n",
    "values = [\n",
    "            [\"no_checking\", 13, \"credits_paid_to_date\", \"car_new\", 1343, \"100_to_500\", \"1_to_4\", 2, \"female\", \"none\", 3,\n",
    "             \"savings_insurance\", 46, \"none\", \"own\", 2, \"skilled\", 1, \"none\", \"yes\"],\n",
    "            [\"no_checking\", 24, \"prior_payments_delayed\", \"furniture\", 4567, \"500_to_1000\", \"1_to_4\", 4, \"male\", \"none\",\n",
    "             4, \"savings_insurance\", 36, \"none\", \"free\", 2, \"management_self-employed\", 1, \"none\", \"yes\"],\n",
    "        ]\n",
    "\n",
    "scoring_payload = {\"input_data\": [{\"fields\": fields, \"values\": values}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = client.deployments.score(deployment_uid, scoring_payload)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "##  Clean up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to clean up all created assets:\n",
    "- experiments\n",
    "- trainings\n",
    "- pipelines\n",
    "- model definitions\n",
    "- models\n",
    "- functions\n",
    "- deployments\n",
    "\n",
    "please follow up this sample [notebook](https://github.com/IBM/watson-machine-learning-samples/blob/master/notebooks/python_sdk/instance-management/Machine%20Learning%20artifacts%20management.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "##  Summary and next steps     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You successfully completed this notebook! \n",
    " \n",
    "You have finished the hands-on lab for IBM Watson Machine Learning. You created, published and deployed Scikit-Learn german credit risk model. \n",
    "\n",
    "Check out our <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts. \n",
    "\n",
    "You can now run the model monitoring [notebook](Monitor%20credit%20risk%20model%20with%20Watson%20Openscale.ipynb). You need to pass deployed model id in mentioned notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Lukasz Cmielowski, PhD, is an Automation Architect and Data Scientist at IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge.\n",
    "\n",
    "Szymon Kucharczyk, Software Engineer at IBM Watson Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© 2020 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
