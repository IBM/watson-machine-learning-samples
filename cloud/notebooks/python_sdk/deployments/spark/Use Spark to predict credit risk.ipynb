{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Use Spark to predict credit risk with `ibm-watson-machine-learning`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces commands for model persistance to Watson Machine Learning repository, model deployment, and scoring.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.6 and Apache® Spark 2.4.\n",
    "\n",
    "You will use **German Credit Risk** dataset.\n",
    "\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "-  Load a CSV file into an Apache® Spark DataFrame.\n",
    "-  Explore data.\n",
    "-  Prepare data for training and evaluation.\n",
    "-  Persist a pipeline and model in Watson Machine Learning repository from tar.gz files.\n",
    "-  Deploy a model for online scoring using Wastson Machine Learning API.\n",
    "-  Score sample scoring data using the Watson Machine Learning API.\n",
    "-  Explore and visualize prediction result using the plotly package.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.\t[Set up](#setup)\n",
    "2.\t[Load and explore data](#load)\n",
    "3.\t[Persist model](#persistence)\n",
    "4.\t[Predict locally](#visualization)\n",
    "5.\t[Deploy and score in a Cloud](#scoring)\n",
    "6.\t[Clean up](#cleanup)\n",
    "7.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html?context=analytics\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to WML\n",
    "\n",
    "Authenticate the Watson Machine Learning service on IBM Cloud. You need to provide platform `api_key` and instance `location`.\n",
    "\n",
    "You can use [IBM Cloud CLI](https://cloud.ibm.com/docs/cli/index.html) to retrieve platform API Key and instance location.\n",
    "\n",
    "API Key can be generated in the following way:\n",
    "```\n",
    "ibmcloud login\n",
    "ibmcloud iam api-key-create API_KEY_NAME\n",
    "```\n",
    "\n",
    "In result, get the value of `api_key` from the output.\n",
    "\n",
    "\n",
    "Location of your WML instance can be retrieved in the following way:\n",
    "```\n",
    "ibmcloud login --apikey API_KEY -a https://cloud.ibm.com\n",
    "ibmcloud resource service-instance WML_INSTANCE_NAME\n",
    "```\n",
    "\n",
    "In result, get the value of `location` from the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: Your `Cloud API key` can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below. You can also get a service specific url by going to the [**Endpoint URLs** section of the Watson Machine Learning docs](https://cloud.ibm.com/apidocs/machine-learning).  You can check your instance location in your  <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance details.\n",
    "\n",
    "You can also get service specific apikey by going to the [**Service IDs** section of the Cloud Console](https://cloud.ibm.com/iam/serviceids).  From that page, click **Create**, then copy the created key and paste it below.\n",
    "\n",
    "**Action**: Enter your `api_key` and `location` in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'PASTE YOUR PLATFORM API KEY HERE'\n",
    "location = 'PASTE YOUR INSTANCE LOCATION HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": api_key,\n",
    "    \"url\": 'https://' + location + '.ml.cloud.ibm.com'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import the `ibm-watson-machine-learning` package\n",
    "**Note:** `ibm-watson-machine-learning` documentation can be found <a href=\"http://ibm-wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with spaces\n",
    "\n",
    "First of all, you need to create a space that will be used for your work. If you do not have space already created, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create one.\n",
    "\n",
    "- Click New Deployment Space\n",
    "- Create an empty space\n",
    "- Select Cloud Object Storage\n",
    "- Select Watson Machine Learning instance and press Create\n",
    "- Copy `space_id` and paste it below\n",
    "\n",
    "**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
    "\n",
    "**Action**: Assign space ID below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_id = 'PASTE YOUR SPACE ID HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `list` method to print all existing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.spaces.list(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to interact with all resources available in Watson Machine Learning, you need to set **space** which you will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "except:\n",
    "    print('Error: Spark runtime is missing. If you are using Watson Studio change the notebook runtime to Spark.')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 2. Load and explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will load the data as an Apache® Spark DataFrame and perform a basic exploration.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file for German Credit Risk is available on the same repository as this notebook. Load the file to Apache® Spark DataFrame using code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from wget import download\n",
    "\n",
    "sample_dir = 'spark_sample_model'\n",
    "if not os.path.isdir(sample_dir):\n",
    "    os.mkdir(sample_dir)\n",
    "    \n",
    "filename = os.path.join(sample_dir, 'credit_risk_training.csv')\n",
    "if not os.path.isfile(filename):\n",
    "    filename = download('https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/data/credit_risk/credit_risk_training.csv', out=sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df_data = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the loaded data by using the following Apache® Spark DataFrame methods:\n",
    "-  print schema\n",
    "-  print top ten records\n",
    "-  count all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data contains 21 fields. Risk field is the one we would like to predict (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.show(n=5, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of records: \" + str(df_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data set contains 5000 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare data\n",
    "\n",
    "In this subsection you will split your data into: train, test and predict datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_data = df_data.randomSplit([0.8, 0.18, 0.02], 24)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "predict_data = splitted_data[2]\n",
    "\n",
    "print(\"Number of training records: \" + str(train_data.count()))\n",
    "print(\"Number of testing records : \" + str(test_data.count()))\n",
    "print(\"Number of prediction records : \" + str(predict_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see our data has been successfully split into three datasets: \n",
    "\n",
    "-  The train data set, which is the largest group, is used for training.\n",
    "-  The test data set will be used for model evaluation and is used to test the assumptions of the model.\n",
    "-  The predict data set will be used for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"persistence\"></a>\n",
    "## 3. Persist model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn how to store your pipeline and model in Watson Machine Learning repository by using python client libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Apache® Spark 2.4 is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save training data in your Cloud Object Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ibm-cos-sdk library allows Python developers to manage Cloud Object Storage (COS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: Put credentials from Object Storage Service in Bluemix here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_credentials = {\n",
    "                  \"apikey\": \"***\",\n",
    "                  \"cos_hmac_keys\": {\n",
    "                    \"access_key_id\": \"***\",\n",
    "                    \"secret_access_key\": \"***\"\n",
    "                  },\n",
    "                  \"endpoints\": \"***\",\n",
    "                  \"iam_apikey_description\": \"***\",\n",
    "                  \"iam_apikey_name\": \"***\",\n",
    "                  \"iam_role_crn\": \"***\",\n",
    "                  \"iam_serviceid_crn\": \"***\",\n",
    "                  \"resource_instance_id\": \"***\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_apikey = cos_credentials['apikey']\n",
    "connection_resource_instance_id = cos_credentials[\"resource_instance_id\"]\n",
    "connection_access_key_id = cos_credentials['cos_hmac_keys']['access_key_id']\n",
    "connection_secret_access_key = cos_credentials['cos_hmac_keys']['secret_access_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: Define the service endpoint we will use. <br>\n",
    "**Tip**: You can find this information in Endpoints section of your Cloud Object Storage intance's dashbord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_endpoint = 'https://s3.us.cloud-object-storage.appdomain.cloud'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also need IBM Cloud authorization endpoint to be able to create COS resource object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_endpoint = 'https://iam.cloud.ibm.com/identity/token'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create COS resource to be able to write data to Cloud Object Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = ibm_boto3.resource('s3',\n",
    "                         ibm_api_key_id=cos_credentials['apikey'],\n",
    "                         ibm_service_instance_id=cos_credentials['resource_instance_id'],\n",
    "                         ibm_auth_endpoint=auth_endpoint,\n",
    "                         config=Config(signature_version='oauth'),\n",
    "                         endpoint_url=service_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will create bucket in COS and copy `training dataset` for model from **credit_risk_training.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "bucket_uid = str(uuid4())\n",
    "\n",
    "score_filename = \"credit_risk_training.csv\"\n",
    "buckets = [\"credit-risk-\" + bucket_uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bucket in buckets:\n",
    "    if not cos.Bucket(bucket) in cos.buckets.all():\n",
    "        print('Creating bucket \"{}\"...'.format(bucket))\n",
    "        try:\n",
    "            cos.create_bucket(Bucket=bucket)\n",
    "        except ibm_boto3.exceptions.ibm_botocore.client.ClientError as e:\n",
    "            print('Error: {}.'.format(e.response['Error']['Message']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_obj = cos.Bucket(buckets[0])\n",
    "\n",
    "print('Uploading data {}...'.format(score_filename))\n",
    "with open(filename, 'rb') as f:\n",
    "    bucket_obj.upload_fileobj(f, score_filename)\n",
    "print('{} is uploaded.'.format(score_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Save pipeline and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will learn how to save pipeline and model artifacts to your Watson Machine Learning instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download pipeline and model archives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from wget import download\n",
    "\n",
    "sample_dir = 'spark_sample_model'\n",
    "if not os.path.isdir(sample_dir):\n",
    "    os.mkdir(sample_dir)\n",
    "    \n",
    "pipeline_filename = os.path.join(sample_dir, 'credit_risk_spark_pipeline.tar.gz')\n",
    "if not os.path.isfile(pipeline_filename):\n",
    "    pipeline_filename = download('https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/models/spark/credit-risk/model/credit_risk_spark_pipeline.tar.gz', out=sample_dir)\n",
    "model_filename = os.path.join(sample_dir, 'credit_risk_spark_model.gz')\n",
    "if not os.path.isfile(model_filename):\n",
    "    model_filename = download('https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/models/spark/credit-risk/model/credit_risk_spark_model.gz', out=sample_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Store piepline and model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to store your Spark model, you need to provide a training data reference, this will allow to read the model schema automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_data_references = [\n",
    "                {\n",
    "                    \"type\": \"s3\",\n",
    "                    \"connection\": {\n",
    "                        \"access_key_id\": connection_access_key_id,\n",
    "                        \"endpoint_url\": service_endpoint,\n",
    "                        \"secret_access_key\": connection_secret_access_key\n",
    "                    },\n",
    "                    \"location\": {\n",
    "                        \"bucket\": buckets[0],\n",
    "                        \"path\": score_filename,\n",
    "                    },\n",
    "                    \"schema\": {\n",
    "                    \"id\": \"training_schema\",\n",
    "                    \"fields\": [\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"CheckingStatus\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"LoanDuration\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"integer\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"CreditHistory\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"LoanPurpose\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"LoanAmount\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"integer\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"ExistingSavings\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"EmploymentDuration\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"InstallmentPercent\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"integer\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"Sex\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"OthersOnLoan\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"CurrentResidenceDuration\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"integer\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"OwnsProperty\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"Age\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"integer\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"InstallmentPlans\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"Housing\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"ExistingCreditsCount\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"integer\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"Job\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"Dependents\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"integer\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"Telephone\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": \"ForeignWorker\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"metadata\": {\n",
    "                          \"modeling_role\": \"target\"\n",
    "                        },\n",
    "                        \"name\": \"Risk\",\n",
    "                        \"nullable\": True,\n",
    "                        \"type\": \"string\"\n",
    "                      }\n",
    "                    ]\n",
    "                  }\n",
    "                }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "published_model_details = client.repository.store_model(\n",
    "    model=model_filename, \n",
    "    meta_props={\n",
    "        client.repository.ModelMetaNames.NAME:'Credit Risk model',\n",
    "        client.repository.ModelMetaNames.SPACE_UID: space_id,\n",
    "        client.repository.ModelMetaNames.TYPE: \"mllib_2.4\",\n",
    "        client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_id_by_name('spark-mllib_2.4'),\n",
    "        client.repository.ModelMetaNames.TRAINING_DATA_REFERENCES: training_data_references,\n",
    "        client.repository.ModelMetaNames.LABEL_FIELD: \"Risk\",\n",
    "    }, \n",
    "    training_data=train_data, \n",
    "    pipeline=pipeline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uid = client.repository.get_model_uid(published_model_details)\n",
    "print(model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repository.get_model_details(model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get saved model metadata from Watson Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: Use `client.repository.ModelMetaNames.show()` to get the list of available props."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repository.ModelMetaNames.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will learn how to load back saved model from specified instance of Watson Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = client.repository.load(model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print for example model name to make sure that model has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(loaded_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualization\"></a>\n",
    "## 4. Predict locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn how to score test data using loaded model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1: Make local prediction using previously loaded model and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will score *predict_data* data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.transform(predict_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the results by calling the *show()* method on the predictions DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tabulating a count, you can see which product line is the most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"predictedLabel\").groupBy(\"predictedLabel\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scoring\"></a>\n",
    "## 5. Deploy and score in a Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn how to create online scoring and to score a new data record using `ibm-watson-machine-learning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can also use REST API to deploy and score.\n",
    "For more information about REST APIs, see the [Swagger Documentation](https://watson-ml-v4-api.mybluemix.net/wml-restapi-cloud.html#/Deployments/deployments_create)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Create online scoring endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create an online scoring endpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create online deployment for published model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_details = client.deployments.create(\n",
    "    model_uid, \n",
    "    meta_props={\n",
    "        client.deployments.ConfigurationMetaNames.NAME: \"Credit Risk model deployment\",\n",
    "        client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can send new scoring records (new data) for which you would like to get predictions. To do that, execute the following sample code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\",\n",
    "                  \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\",\n",
    "                  \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n",
    "                  \"Telephone\", \"ForeignWorker\"]\n",
    "values = [\n",
    "    [\"no_checking\", 13, \"credits_paid_to_date\", \"car_new\", 1343, \"100_to_500\", \"1_to_4\", 2, \"female\", \"none\", 3,\n",
    "     \"savings_insurance\", 46, \"none\", \"own\", 2, \"skilled\", 1, \"none\", \"yes\"],\n",
    "    [\"no_checking\", 24, \"prior_payments_delayed\", \"furniture\", 4567, \"500_to_1000\", \"1_to_4\", 4, \"male\", \"none\",\n",
    "     4, \"savings_insurance\", 36, \"none\", \"free\", 2, \"management_self-employed\", 1, \"none\", \"yes\"],\n",
    "    [\"0_to_200\", 26, \"all_credits_paid_back\", \"car_new\", 863, \"less_100\", \"less_1\", 2, \"female\", \"co-applicant\",\n",
    "     2, \"real_estate\", 38, \"none\", \"own\", 1, \"skilled\", 1, \"none\", \"yes\"],\n",
    "    [\"0_to_200\", 14, \"no_credits\", \"car_new\", 2368, \"less_100\", \"1_to_4\", 3, \"female\", \"none\", 3, \"real_estate\",\n",
    "     29, \"none\", \"own\", 1, \"skilled\", 1, \"none\", \"yes\"],\n",
    "    [\"0_to_200\", 4, \"no_credits\", \"car_new\", 250, \"less_100\", \"unemployed\", 2, \"female\", \"none\", 3,\n",
    "     \"real_estate\", 23, \"none\", \"rent\", 1, \"management_self-employed\", 1, \"none\", \"yes\"],\n",
    "    [\"no_checking\", 17, \"credits_paid_to_date\", \"car_new\", 832, \"100_to_500\", \"1_to_4\", 2, \"male\", \"none\", 2,\n",
    "     \"real_estate\", 42, \"none\", \"own\", 1, \"skilled\", 1, \"none\", \"yes\"],\n",
    "    [\"no_checking\", 33, \"outstanding_credit\", \"appliances\", 5696, \"unknown\", \"greater_7\", 4, \"male\",\n",
    "     \"co-applicant\", 4, \"unknown\", 54, \"none\", \"free\", 2, \"skilled\", 1, \"yes\", \"yes\"],\n",
    "    [\"0_to_200\", 13, \"prior_payments_delayed\", \"retraining\", 1375, \"100_to_500\", \"4_to_7\", 3, \"male\", \"none\", 3,\n",
    "     \"real_estate\", 37, \"none\", \"own\", 2, \"management_self-employed\", 1, \"none\", \"yes\"]\n",
    "]\n",
    "\n",
    "payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values}]}\n",
    "deployment_id = client.deployments.get_id(deployment_details)\n",
    "\n",
    "client.deployments.score(deployment_id, payload_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "## 6. Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to clean up all created assets:\n",
    "- experiments\n",
    "- trainings\n",
    "- pipelines\n",
    "- model definitions\n",
    "- models\n",
    "- functions\n",
    "- deployments\n",
    "\n",
    "please follow up this sample [notebook](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Machine%20Learning%20artifacts%20management.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 7. Summary and next steps     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You successfully completed this notebook! You learned how to use Apache Spark machine learning as well as Watson Machine Learning for model creation and deployment. Check out our [Online Documentation](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html?context=analytics) for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "**Amadeusz Masny**, Python Software Developer in Watson Machine Learning at IBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2020 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
