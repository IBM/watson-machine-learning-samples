{"metadata": {"kernelspec": {"display_name": "Python 3.11", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "![](https://github.ibm.com/WML/watson-machine-learning-samples/blob/dev/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png?raw=true \"title\")\n", "metadata": {"id": "b9034efb-4104-4176-950e-0de875eb07f5"}}, {"cell_type": "markdown", "source": "# Use lm-evaluation-harness and own benchmarking data with watsonx.ai foundation models", "metadata": {}}, {"cell_type": "markdown", "source": "This notebook contains the steps and code to demonstrate usage of `lm-evaluation-harness` (also called `lm-eval`) package with `ibm_watsonx_ai` and `watsonx_llm` language model.   \n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.", "metadata": {"id": "00639b8e-fe72-4a3e-bea3-d40fdc55fb7d"}}, {"cell_type": "markdown", "source": "## Learning goals\n\nThe learning goals of this notebook are: \n1. Setting up `lm-evaluation-harness` and `ibm_watsonx_ai`\n2. Basic `lm-evaluation-harness` usage with available tasks\n3. Preparing custom tasks and setting up local datasets\n4. Calling `lm-evaluation-harness` with locally prepared tasks", "metadata": {"id": "078d559c-58fc-4899-803c-cc3a58c4038d"}}, {"cell_type": "markdown", "source": "## Table of contents\nThis notebook contains the following parts:\n\n1. [Prerequisites](#prerequisites)\n   - [How to install lm-evaluation-harness - two ways](#install-lm-eval)\n   - [Install lm-evaluation-harness and ibm_watsonx_ai](#install-packages)\n   - [Validate installation](#validate-install)\n3. [Setting up necessary IBM watsonx credentials](#credentials)\n   - [Working with projects](#projects)\n   - [Export watsonx variables to be used by lm-evaluation-harness](#export-variables)\n4. [Basic lm-evaluation-harness usage](#usage)\n5. [Preparing own data for benchmarking](#prepare-own-data)\n   - [Prepare an APIClient instance](#prepare-client)\n   - [Prepare data assets](#prepare-assets)\n   - [Download datasets](#download-files)\n   - [Validate download](#validate-download)\n   - [Sample YAML task syntax](#yaml-task)\n   - [Save custom task to file](#save-task)\n6. [Run lm-evaluation-harness benchmarks with local data](#benchmarks-local)\n7. [Summary and next steps](#summary)", "metadata": {"id": "d6bd4d32-b6d7-4056-9138-a41665c3fd60"}}, {"cell_type": "markdown", "source": "## Prerequisites <a name=\"prerequisites\"></a>\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n- Create a [watsonx.ai Runtime](https://cloud.ibm.com/catalog/services/watson-machine-learning) instance (a free plan is offered and information about how to create the instance can be found [here](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp)).\n- Create a [Cloud Object Storage (COS) instance](https://console.bluemix.net/catalog/infrastructure/cloud-object-storage) (a lite plan is offered and information about how to order storage can be found [here](https://cloud.ibm.com/docs/cloud-object-storage/basics/order-storage.html#order-storage)).\n  \n__Note: When using Watson Studio, you already have a COS instance associated with the project you are running the notebook in.__", "metadata": {"id": "4316b92d-682b-408c-a8b7-8ea8bc3c5179"}}, {"cell_type": "markdown", "source": "#### How to install lm-evaluation-harness - two ways <a name=\"install-lm-eval\"></a>", "metadata": {}}, {"cell_type": "markdown", "source": "`lm-evaluation-harness` is a unified framework to test generative language models on a large number of different evaluation tasks. For more info and the source code, check out its [GitHub repository](https://github.com/EleutherAI/lm-evaluation-harness/tree/main)\n\n1. Package installation - to use as is: \n    ```\n    !pip install lm-eval | tail -n 1\n    ```\n\n2. Local installation - for debugging purposes:\n\n    ```\n    git clone https://github.com/EleutherAI/lm-evaluation-harness\n    cd lm-evaluation-harness\n    pip install -e .\n    ```", "metadata": {"id": "698a888c-e4bb-4f4d-aae8-84dd2cfa5d64"}}, {"cell_type": "markdown", "source": "#### Install ibm_watsonx_ai and lm-evaluation-harness package from pip <a name=\"install-packages\"></a>\n\n__Note__: \n- `ibm-watsonx-ai` documentation can be found [here](https://ibm.github.io/watsonx-ai-python-sdk/index.html).\n- `lm-evaluation-harness` documentation can be found [here](https://github.com/EleutherAI/lm-evaluation-harness/tree/main/docs)", "metadata": {}}, {"cell_type": "code", "source": "!pip install -U ibm_watsonx_ai | tail -n 1 \n!pip install lm-eval | tail -n 1 ", "metadata": {"id": "5025324a-7005-450a-aa9a-9922123d20e1"}, "outputs": [{"name": "stdout", "text": "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from lomond->ibm_watsonx_ai) (1.16.0)\nSuccessfully installed DataProperty-1.1.0 accelerate-1.3.0 chardet-5.2.0 colorama-0.4.6 datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 huggingface-hub-0.27.1 jsonlines-4.0.0 lm-eval-0.4.7 mbstrdecoder-1.1.4 more_itertools-10.6.0 multiprocess-0.70.16 pathvalidate-3.2.3 peft-0.14.0 portalocker-3.1.1 pybind11-2.13.6 pytablewriter-1.2.1 rouge-score-0.1.2 sacrebleu-2.5.1 safetensors-0.5.2 sqlitedict-2.1.0 tabledata-1.3.4 tcolorpy-0.1.7 tokenizers-0.21.0 tqdm-multiprocess-0.0.11 transformers-4.48.0 typepy-1.3.4 word2number-1.1 xxhash-3.5.0 zstandard-0.23.0\n", "output_type": "stream"}], "execution_count": 1}, {"cell_type": "markdown", "source": "- `wget` is used only if you are planning to download datasets directly from HuggingFace. If you already have them stored locally or as data assets on Cloud, skip the line below", "metadata": {"id": "01468868-b35a-40cb-9336-a800e4be2fa2"}}, {"cell_type": "code", "source": "!pip install wget | tail -n 1", "metadata": {"id": "93f49df3-4b35-40e9-914c-c3ba13d21eb0"}, "outputs": [{"name": "stdout", "text": "Successfully installed wget-3.2\n", "output_type": "stream"}], "execution_count": 2}, {"cell_type": "markdown", "source": "#### Validate installation <a name=\"validate-install\"></a>", "metadata": {"id": "411a5800-931b-4d24-8c36-a88269cf70c3"}}, {"cell_type": "code", "source": "!pip list | grep ibm_watsonx_ai\n!pip list | grep lm_eval", "metadata": {"id": "93e3efd1-3e7b-4a59-950e-38383e5b159b"}, "outputs": [{"name": "stdout", "text": "ibm_watsonx_ai                          1.2.1\nlm_eval                                 0.4.7\n", "output_type": "stream"}], "execution_count": 3}, {"cell_type": "markdown", "source": "## Setting up necessary IBM watsonx credentials <a name=\"credentials\"></a>", "metadata": {}}, {"cell_type": "markdown", "source": "Required credentials: \n- IBM Cloud API key,\n- IBM Cloud URL\n- IBM Cloud Project ID\n\nAuthenticate the Watson Machine Learning service on IBM Cloud. You need to provide Cloud API key and location.\n\nTip: Your `Cloud API key` can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the __API Keys__ section, and click __Create an IBM Cloud API key__. Give your key a name and click __Create__, then copy the created key and paste it below. You can also get a service specific url by going to the [Endpoint URLs section of the watsonx.ai Runtime](https://cloud.ibm.com/apidocs/machine-learning) docs. You can check your instance location in your [watsonx.ai Runtime](https://cloud.ibm.com/catalog/services/watson-machine-learning) instance details.\n\nYou can use [IBM Cloud CLI](https://cloud.ibm.com/docs/cli/index.html) to retrieve the instance location.\n\n```\nibmcloud login --apikey API_KEY -a https://cloud.ibm.com\nibmcloud resource service-instance WML_INSTANCE_NAME\n```\n\nNOTE: You can also get a service specific apikey by going to the [Service IDs section of the Cloud Console](https://cloud.ibm.com/iam/serviceids). From that page, click __Create__, and then copy the created key and paste it in the following cell.", "metadata": {}}, {"cell_type": "markdown", "source": "Import widely used modules:", "metadata": {"id": "4278b53a-4e92-4de0-ae16-9950fdb5d0d1"}}, {"cell_type": "code", "source": "import os\nfrom pathlib import Path ", "metadata": {"id": "14568225-0b99-4430-8684-740c3464b1a6"}, "outputs": [], "execution_count": 4}, {"cell_type": "markdown", "source": "__Action__: Enter your `api_key` in the following cell", "metadata": {"id": "74e34cd7-dba7-47dd-bcd7-7e023c8782f8"}}, {"cell_type": "code", "source": "import getpass\napi_key = getpass.getpass(\"Please enter your api key (hit enter): \")", "metadata": {"id": "7fb3062d-ae42-450c-b407-7e60e92091f9"}, "outputs": [{"output_type": "stream", "name": "stdin", "text": "Please enter your api key (hit enter):  \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}], "execution_count": 5}, {"cell_type": "markdown", "source": "__Action__: Enter your `location` in the following cell", "metadata": {"id": "c8bfb084-79b6-471d-b1f0-595ccf5edd69"}}, {"cell_type": "code", "source": "location = \"INSERT YOUR LOCATION HERE\"", "metadata": {"id": "3d799446-9a41-4926-aba4-eade711537d4"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "If you are running this notebook on Cloud, you can access the `location` via:", "metadata": {"id": "28917545-dec7-408e-a27d-cf38f9000e06"}}, {"cell_type": "code", "source": "location = os.environ.get(\"RUNTIME_ENV_REGION\")", "metadata": {"id": "525becc3-f5f9-43d7-a8ba-c85fcdcf3143"}, "outputs": [], "execution_count": 6}, {"cell_type": "code", "source": "url = f\"https://{location}.ml.cloud.ibm.com\"", "metadata": {"id": "8405371b-a233-4544-8a3f-a36060854588"}, "outputs": [], "execution_count": 7}, {"cell_type": "markdown", "source": "## Working with projects <a name=\"projects\"></a>\n\nYou need to create a project that will be used for your work. If you do not have a space, you can use [Projects Dashboard](https://dataplatform.cloud.ibm.com/wx/home?context=wx) to create one.\n\n- Click __Create a new project__\n- Provide a name\n- Select Cloud Object Storage\n- Select Watson Machine Learning instance and press __Create__\n- Copy `project_id` and paste it below\n\n__Action__: Assign project ID below", "metadata": {"id": "a2d06fbb-6cb5-45ee-828f-86ea661963a9"}}, {"cell_type": "code", "source": "project_id = \"INSERT YOUR PROJECT ID HERE\"", "metadata": {"id": "c2ad1b98-4dcb-4585-8bfb-56f558fa70e8"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "If you are running this notebook on Cloud, you can access the `project_id` via: ", "metadata": {"id": "0596b06b-4b82-40ce-92f8-e47316dcaec7"}}, {"cell_type": "code", "source": "project_id = os.environ.get(\"PROJECT_ID\")", "metadata": {"id": "ac7f4a6d-ebbb-409e-baa6-ab721f5183d6"}, "outputs": [], "execution_count": 8}, {"cell_type": "markdown", "source": "## Export watsonx variables to be used by lm-evaluation-harness <a name=\"export-variables\"></a>", "metadata": {"id": "03c6e761-a248-4f9f-bff0-60c921ad2ffa"}}, {"cell_type": "code", "source": "os.environ[\"WATSONX_API_KEY\"] = api_key\nos.environ[\"WATSONX_URL\"] = url\nos.environ[\"WATSONX_PROJECT_ID\"] = project_id", "metadata": {"id": "e3e84905-c10d-4426-b20e-3387463598aa"}, "outputs": [], "execution_count": 9}, {"cell_type": "markdown", "source": "## Basic `lm-evaluation-harness` usage <a name=\"usage\"></a>", "metadata": {"id": "745fac85-275e-4540-8078-4a0b5bdf629a"}}, {"cell_type": "markdown", "source": "Basic `lm-evaluation-harness` syntax requires providing: \n- model\n- specific model_id\n- task name\n\n```\n!lm_eval \\\n--model [model] \\\n--model_args model_id=[model_id] \\\n--limit 10 \\\n--tasks [task_name] \\\n```\n\n--limit 10 is used to evaluate only 10 records. \n\nIn order to get more info about possible arguments, use the command: \n\n```\n!lm-eval -h\n```\n\nSample calling using the `watsonx_llm` and an available `gsm8k` task", "metadata": {"id": "ad906a79-6fe6-4c70-b7ed-38e74dfd3221"}}, {"cell_type": "code", "source": "!lm_eval --model watsonx_llm \\\n--verbosity ERROR \\\n--model_args model_id=ibm/granite-13b-instruct-v2 \\\n--limit 10 \\\n--tasks gsm8k", "metadata": {"id": "b94c9c53-bc5d-42f3-9670-cbe034c4c6b3"}, "outputs": [{"name": "stdout", "text": "2025-01-20:15:26:01,154 INFO     [client.py:443] Client successfully initialized\n2025-01-20:15:26:01,608 INFO     [wml_resource.py:112] Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-01-10&project_id=7e8b59ba-2610-4a29-9d90-dc02483ed5f4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00<00:00, 251.49it/s]\nRunning generate_until function ...:   0%|               | 0/10 [00:00<?, ?it/s]2025-01-20:15:26:05,490 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:05,497 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...:  10%|\u258b      | 1/10 [00:01<00:10,  1.19s/it]2025-01-20:15:26:06,284 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:06,288 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...:  20%|\u2588\u258d     | 2/10 [00:01<00:07,  1.05it/s]2025-01-20:15:26:11,623 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:11,624 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...:  30%|\u2588\u2588     | 3/10 [00:07<00:20,  2.96s/it]2025-01-20:15:26:12,584 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:12,584 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...:  40%|\u2588\u2588\u258a    | 4/10 [00:08<00:13,  2.17s/it]2025-01-20:15:26:15,072 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:15,074 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...:  50%|\u2588\u2588\u2588\u258c   | 5/10 [00:10<00:11,  2.28s/it]2025-01-20:15:26:17,292 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:17,293 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...:  60%|\u2588\u2588\u2588\u2588\u258f  | 6/10 [00:12<00:09,  2.26s/it]2025-01-20:15:26:18,431 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:18,434 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...:  70%|\u2588\u2588\u2588\u2588\u2589  | 7/10 [00:14<00:05,  1.90s/it]2025-01-20:15:26:23,747 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:23,748 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...:  80%|\u2588\u2588\u2588\u2588\u2588\u258c | 8/10 [00:19<00:05,  2.98s/it]2025-01-20:15:26:29,098 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:29,102 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 9/10 [00:24<00:03,  3.73s/it]2025-01-20:15:26:34,372 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:26:34,376 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning generate_until function ...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:30<00:00,  3.01s/it]\nfatal: not a git repository (or any of the parent directories): .git\nwatsonx_llm (model_id=ibm/granite-13b-instruct-v2), gen_kwargs: (None), limit: 10.0, num_fewshot: None, batch_size: 1\n|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value|   |Stderr|\n|-----|------:|----------------|-----:|-----------|---|----:|---|-----:|\n|gsm8k|      3|flexible-extract|     5|exact_match|\u2191  |  0.3|\u00b1  |0.1528|\n|     |       |strict-match    |     5|exact_match|\u2191  |  0.3|\u00b1  |0.1528|\n\n", "output_type": "stream"}], "execution_count": 50}, {"cell_type": "markdown", "source": "If you get a following error: \n`RuntimeError: Model [model_id] is not supported: does not return logprobs for input tokens` try again with a different model that has the `logprobs` enabled. Available models can be found [here](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx)", "metadata": {"id": "5176088f-1f12-4df7-bf92-069667aa8dbc"}}, {"cell_type": "markdown", "source": "## Preparing own data for benchmarking <a name=\"prepare-own-data\"></a>", "metadata": {"id": "5d2f0c0a-29a4-42dd-872d-fd1402ace391"}}, {"cell_type": "markdown", "source": "### Prepare an APIClient instance <a name=\"prepare-client\"></a>", "metadata": {"id": "03764960-193c-42f2-8a82-cb75bfdd974b"}}, {"cell_type": "code", "source": "from ibm_watsonx_ai import Credentials, APIClient\n\napi_client = APIClient(credentials=Credentials(api_key=api_key, url=url), project_id=project_id)", "metadata": {"id": "435f594d-4ba5-48c4-a5a6-1f2bf563b40f"}, "outputs": [], "execution_count": 11}, {"cell_type": "markdown", "source": "### Prepare data assets <a name=\"prepare-assets\"></a>\n\nThis example uses the `validation-00000-of-00001.parquet` datasets from OpenbookQA dataset and it's available [on HuggingFace](https://huggingface.co/datasets/allenai/openbookqa).\n\nLet's save its names for further use. ", "metadata": {"id": "a774c482-5b31-4cf3-bf5a-b68b647ed4cb"}}, {"cell_type": "code", "source": "validation_filename = \"validation-00000-of-00001.parquet\"", "metadata": {"id": "ad789f59-fc3d-4c0f-8640-cce7ddba0e87"}, "outputs": [], "execution_count": 12}, {"cell_type": "markdown", "source": "If you are running this notebook locally, you can download the dataset directly from HuggingFace hub or using `wget`. If you already have the files in your desired location or are using DataConnections, skip the cell below. ", "metadata": {"id": "cf98ba89-70cb-4b78-badf-b23ac7249642"}}, {"cell_type": "code", "source": "import wget\n\nbase_url = 'https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/ARC-Easy/'\n\npath = Path(os.getcwd()) / validation_filename\nif path.exists():\n    path.unlink()\nwget.download(f\"{base_url}{validation_filename}\")", "metadata": {"id": "05b67a23-5eda-4db7-8023-4f2da41aedb4"}, "outputs": [{"execution_count": 14, "output_type": "execute_result", "data": {"text/plain": "'validation-00000-of-00001.parquet'"}, "metadata": {}}], "execution_count": 14}, {"cell_type": "markdown", "source": "If you are running this notebook on Cloud and wish to use a connection to a data asset, execute the cells below.\n\n__Action__: Provide path to a file that you wish to create a data asset with. ", "metadata": {"id": "ca60fc79-a5cb-4d26-ac57-15583809d59e"}}, {"cell_type": "code", "source": "def create_asset(client, file_path): \n    asset_details = client.data_assets.create(file_path=file_path, name=Path(file_path).name)\n    return client.data_assets.get_id(asset_details)", "metadata": {"id": "6bf48b82-58bb-49ae-8ac0-1f1355b4bf80"}, "outputs": [], "execution_count": 16}, {"cell_type": "code", "source": "validation_asset_id = create_asset(api_client, validation_filename)", "metadata": {"id": "8aec0adf-26a1-49e2-a928-31c4d0dd6b53"}, "outputs": [{"name": "stdout", "text": "Creating data asset...\nSUCCESS\n", "output_type": "stream"}], "execution_count": 17}, {"cell_type": "markdown", "source": "If you already have the connection to the following file and wish to download from it, skip the cells above and execute the cell below\n\n__Action__: Provide existing connection ID's. ", "metadata": {"id": "a5c6bfec-7f02-467a-98c0-affbed42983b"}}, {"cell_type": "code", "source": "train_asset_id = \"INSERT TRAIN ASSET ID HERE\"\ntest_asset_id = \"INSERT TEST ASSET ID HERE\"\nvalidation_asset_id = \"INSERT VALIDATION ASSET ID HERE\"", "metadata": {"id": "d0db8e1e-b4e8-4311-9b18-96fc2b2f81db"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### Download data from Data Assets <a name=\"download-files\"></a>\n\nIf your file is already stored locally in your desired location, skip the below cells", "metadata": {"id": "d5eb5c6d-4995-447d-bfa5-86de11212bef"}}, {"cell_type": "code", "source": "download_file = lambda client, asset_id, name: client.data_assets.download(asset_id=asset_id, filename=name)", "metadata": {"id": "5dbdcf74-7860-4a90-bc5b-2ce92ec53277"}, "outputs": [], "execution_count": 18}, {"cell_type": "code", "source": "path = Path(os.getcwd()) / validation_filename\nif path.exists():\n    path.unlink()\ndownload_file(api_client, validation_asset_id, validation_filename)", "metadata": {"id": "7cb72102-b18c-4aae-a6ce-78623a2b4571"}, "outputs": [{"name": "stdout", "text": "Successfully saved data asset content to file: 'validation-00000-of-00001.parquet'\n", "output_type": "stream"}, {"execution_count": 40, "output_type": "execute_result", "data": {"text/plain": "'/home/wsuser/work/validation-00000-of-00001.parquet'"}, "metadata": {}}], "execution_count": 40}, {"cell_type": "markdown", "source": "### Validate files download <a name=\"validate-download\"></a>", "metadata": {"id": "bbfb1bf9-be5f-4faf-896b-0743705ba3b6"}}, {"cell_type": "code", "source": "list(map(str, Path(os.getcwd()).iterdir()))", "metadata": {"id": "ce7d5066-955d-44f3-8870-7dd13ca52990"}, "outputs": [{"execution_count": 57, "output_type": "execute_result", "data": {"text/plain": "['/home/wsuser/work/validation-00000-of-00001.parquet']"}, "metadata": {}}], "execution_count": 57}, {"cell_type": "markdown", "source": "### Sample YAML task syntax <a name=\"yaml-task\">\nFor this section we will be using the [`arc_easy`](https://github.com/EleutherAI/lm-evaluation-harness/tree/main/lm_eval/tasks/arc) task as an example on how to build a task and execute it from outside of the `lm-evaluation-harness` repository. \nTasks for benchmarking are stored as `yaml` files. Let's look at the [Arc-Easy](https://huggingface.co/datasets/allenai/ai2_arc/tree/main/ARC-Easy) dataset and its corresponding task. The `yaml` file containing task info looks like this: \n\n```\ntag:\n  - ai2_arc\ntask: arc_easy\ndataset_path: allenai/ai2_arc\ndataset_name: ARC-Easy\noutput_type: multiple_choice\ntraining_split: train\nvalidation_split: validation\ntest_split: test\ndoc_to_text: \"Question: {{question}}\\nAnswer:\"\ndoc_to_target: \"{{choices.label.index(answerKey)}}\"\ndoc_to_choice: \"{{choices.text}}\"\nshould_decontaminate: true\ndoc_to_decontamination_query: \"Question: {{question}}\\nAnswer:\"\nmetric_list:\n  - metric: acc\n    aggregation: mean\n    higher_is_better: true\n  - metric: acc_norm\n    aggregation: mean\n    higher_is_better: true\nmetadata:\n  version: 1.0\n```\n\nNormally, the `dataset_path` and `dataset_name` point to datasets that are stored in `HuggingFace` hub and the `task` points to the list of tasks registered inside the `lm-evaluation-harness` repo. However, it's possible to point to a local dataset with a custom made task. In order to do so, the user need to specify the local paths in the `dataset_kwargs` field and the files type in the `dataset_path` field:\n\n```\ndataset_path: file_type (arrow, parquet, jsonl...)\ndataset_kwargs:\n  data_files:\n    train: /path/to/train/train_file\n    validation: /path/to/validation/validation_file\n    test: /path/to/test/test_file\n```\nIt is also necessary to have the local `yaml` file saved to a specific path and this path needs to be included when calling the `lm-eval` command\n\nKnowing what should be included in the task structure we can recreate a dictionary with this info. ", "metadata": {"id": "13b31aa4-e0e2-4d5b-8f52-c7241cc9849b"}}, {"cell_type": "code", "source": "task = dict(\n    tag=\"test_task_openbook_qa_local\",\n    task=\"test_task_local\",\n    dataset_path=\"parquet\",\n    dataset_kwargs={\n        \"data_files\": {\n            \"validation\": validation_filename\n        }\n    },\n    output_type=\"multiple_choice\",\n    validation_split=\"validation\",\n    doc_to_text=\"Question: {{question}}\\\\nAnswer:\",\n    doc_to_target=\"{{choices.label.index(answerKey)}}\",\n    doc_to_choice=\"{{choices.text}}\",\n    should_decontaminate=True,\n    doc_to_decontamination_query=\"Question: {{question}}\\\\nAnswer:\",\n    metric_list=[\n        {\n            \"metric\": \"acc\",\n            \"aggregation\": \"mean\",\n            \"higher_is_better\": True\n        },\n        {\n            \"metric\": \"acc_norm\",\n            \"aggregation\": \"mean\",\n            \"higher_is_better\": True\n        },\n    ],\n    metadata={\"version\": \"1.0\"},\n)", "metadata": {"id": "6ed1dc27-814e-4ccf-9f74-d003780aaa7e"}, "outputs": [], "execution_count": 49}, {"cell_type": "markdown", "source": "### Save task to file <a name=\"save-task\"></a>", "metadata": {"id": "0b563096-84f2-447c-ae95-8922817abc6c"}}, {"cell_type": "code", "source": "import codecs\nimport yaml\n\nwith codecs.open(\"test_task.yaml\", \"w\") as yaml_file: \n    yaml.dump(task, yaml_file, default_flow_style=False)", "metadata": {"id": "0b8463a4-a928-4a79-8ade-e0370c1d0718"}, "outputs": [], "execution_count": 44}, {"cell_type": "markdown", "source": "## Run `lm_evaluation-harness` benchmarks with local data <a name=\"benchmarks-local\"></a>\n\nHaving the datasets and the yaml task stored, we can run the lm-eval command with the `--include_path .` argument that will point to the local path and the local `arc_easy` task name (`test_task_local`). Evaluation results will be saved to the specified (`results`) directory. ", "metadata": {"id": "4881f160-8200-4c18-bf7b-823f85a1c297"}}, {"cell_type": "code", "source": "!lm_eval --model watsonx_llm \\\n--model_args model_id=ibm/granite-13b-instruct-v2 \\\n--include_path . \\\n--limit 10 \\\n--tasks test_task_local \\\n--output_path results", "metadata": {"id": "6fb394eb-2ba2-4a94-a692-d30266a46702"}, "outputs": [{"name": "stdout", "text": "2025-01-20:15:27:58,139 INFO     [__main__.py:279] Verbosity set to INFO\n2025-01-20:15:27:58,139 INFO     [__main__.py:303] Including path: .\n2025-01-20:15:28:05,491 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n2025-01-20:15:28:05,492 INFO     [__main__.py:376] Selected Tasks: ['test_task_local']\n2025-01-20:15:28:05,493 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n2025-01-20:15:28:05,493 INFO     [evaluator.py:201] Initializing watsonx_llm model, with arguments: {'model_id': 'ibm/granite-13b-instruct-v2'}\n2025-01-20:15:28:06,528 INFO     [client.py:443] Client successfully initialized\n2025-01-20:15:28:07,166 INFO     [wml_resource.py:112] Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-01-10&project_id=7e8b59ba-2610-4a29-9d90-dc02483ed5f4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n2025-01-20:15:28:07,450 INFO     [task.py:415] Building contexts for test_task_local on rank 0...\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00<00:00, 1192.55it/s]\n2025-01-20:15:28:07,459 INFO     [evaluator.py:496] Running loglikelihood requests\n2025-01-20:15:28:07,764 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:07,764 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:   0%|                | 0/40 [00:00<?, ?it/s]2025-01-20:15:28:07,830 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:07,831 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:08,108 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:08,108 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:   2%|\u258f       | 1/40 [00:00<00:13,  2.91it/s]2025-01-20:15:28:08,380 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:08,380 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:08,471 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:08,471 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:   5%|\u258d       | 2/40 [00:00<00:13,  2.82it/s]2025-01-20:15:28:08,557 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:08,557 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:08,645 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:08,645 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:   8%|\u258c       | 3/40 [00:00<00:10,  3.67it/s]2025-01-20:15:28:08,716 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:08,716 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:08,799 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:08,799 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  10%|\u258a       | 4/40 [00:01<00:08,  4.43it/s]2025-01-20:15:28:09,089 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:09,090 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:09,174 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:09,174 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  12%|\u2588       | 5/40 [00:01<00:09,  3.58it/s]2025-01-20:15:28:09,239 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:09,239 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:09,330 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:09,330 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  15%|\u2588\u258f      | 6/40 [00:01<00:08,  4.21it/s]2025-01-20:15:28:09,388 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:09,389 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:09,469 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:09,469 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  18%|\u2588\u258d      | 7/40 [00:01<00:06,  4.87it/s]2025-01-20:15:28:09,533 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:09,534 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:09,849 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:09,850 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  20%|\u2588\u258c      | 8/40 [00:02<00:08,  3.83it/s]2025-01-20:15:28:09,913 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:09,914 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:10,008 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,008 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  22%|\u2588\u258a      | 9/40 [00:02<00:07,  4.37it/s]2025-01-20:15:28:10,077 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,078 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:10,158 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,159 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  25%|\u2588\u258a     | 10/40 [00:02<00:06,  4.88it/s]2025-01-20:15:28:10,224 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,224 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:10,313 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,313 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  28%|\u2588\u2589     | 11/40 [00:02<00:05,  5.28it/s]2025-01-20:15:28:10,376 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,377 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:10,644 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,644 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  30%|\u2588\u2588     | 12/40 [00:02<00:06,  4.30it/s]2025-01-20:15:28:10,709 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,710 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:10,797 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,797 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  32%|\u2588\u2588\u258e    | 13/40 [00:03<00:05,  4.80it/s]2025-01-20:15:28:10,860 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,861 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:10,942 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:10,943 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  35%|\u2588\u2588\u258d    | 14/40 [00:03<00:04,  5.28it/s]2025-01-20:15:28:11,006 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:11,006 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:11,097 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:11,097 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  38%|\u2588\u2588\u258b    | 15/40 [00:03<00:04,  5.59it/s]2025-01-20:15:28:11,166 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:11,166 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:11,248 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:11,248 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  40%|\u2588\u2588\u258a    | 16/40 [00:03<00:04,  5.87it/s]2025-01-20:15:28:11,313 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:11,313 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:12,447 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:12,447 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  42%|\u2588\u2588\u2589    | 17/40 [00:04<00:11,  2.08it/s]2025-01-20:15:28:12,508 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:12,509 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:12,820 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:12,820 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  45%|\u2588\u2588\u2588\u258f   | 18/40 [00:05<00:09,  2.23it/s]2025-01-20:15:28:12,885 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:12,885 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:13,210 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,210 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  48%|\u2588\u2588\u2588\u258e   | 19/40 [00:05<00:09,  2.32it/s]2025-01-20:15:28:13,269 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,269 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:13,353 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,353 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  50%|\u2588\u2588\u2588\u258c   | 20/40 [00:05<00:06,  2.91it/s]2025-01-20:15:28:13,413 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,414 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:13,500 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,500 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  52%|\u2588\u2588\u2588\u258b   | 21/40 [00:05<00:05,  3.51it/s]2025-01-20:15:28:13,560 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,560 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:13,651 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,652 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  55%|\u2588\u2588\u2588\u258a   | 22/40 [00:05<00:04,  4.08it/s]2025-01-20:15:28:13,719 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,719 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:13,803 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,804 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  57%|\u2588\u2588\u2588\u2588   | 23/40 [00:06<00:03,  4.61it/s]2025-01-20:15:28:13,874 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,875 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:13,969 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:13,969 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  60%|\u2588\u2588\u2588\u2588\u258f  | 24/40 [00:06<00:03,  4.96it/s]2025-01-20:15:28:14,032 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:14,032 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:14,124 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:14,125 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  62%|\u2588\u2588\u2588\u2588\u258d  | 25/40 [00:06<00:02,  5.33it/s]2025-01-20:15:28:14,190 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:14,190 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:14,281 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:14,281 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  65%|\u2588\u2588\u2588\u2588\u258c  | 26/40 [00:06<00:02,  5.60it/s]2025-01-20:15:28:14,347 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:14,348 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:14,437 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:14,437 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  68%|\u2588\u2588\u2588\u2588\u258b  | 27/40 [00:06<00:02,  5.82it/s]2025-01-20:15:28:14,502 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:14,503 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:14,593 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:14,593 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  70%|\u2588\u2588\u2588\u2588\u2589  | 28/40 [00:06<00:02,  5.99it/s]2025-01-20:15:28:15,718 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:15,718 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:15,821 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:15,821 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  72%|\u2588\u2588\u2588\u2588\u2588  | 29/40 [00:08<00:05,  2.06it/s]2025-01-20:15:28:15,890 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:15,891 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:15,981 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:15,982 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  75%|\u2588\u2588\u2588\u2588\u2588\u258e | 30/40 [00:08<00:03,  2.58it/s]2025-01-20:15:28:16,053 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,053 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:16,144 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,144 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  78%|\u2588\u2588\u2588\u2588\u2588\u258d | 31/40 [00:08<00:02,  3.12it/s]2025-01-20:15:28:16,221 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,221 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:16,313 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,313 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  80%|\u2588\u2588\u2588\u2588\u2588\u258c | 32/40 [00:08<00:02,  3.64it/s]2025-01-20:15:28:16,380 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,380 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:16,476 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,477 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  82%|\u2588\u2588\u2588\u2588\u2588\u258a | 33/40 [00:08<00:01,  4.14it/s]2025-01-20:15:28:16,544 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,544 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:16,637 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,637 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  85%|\u2588\u2588\u2588\u2588\u2588\u2589 | 34/40 [00:08<00:01,  4.61it/s]2025-01-20:15:28:16,704 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,704 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:16,796 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,796 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 35/40 [00:09<00:00,  5.01it/s]2025-01-20:15:28:16,887 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:16,887 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:17,007 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:17,008 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 36/40 [00:09<00:00,  4.92it/s]2025-01-20:15:28:17,079 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:17,079 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:17,172 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:17,172 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 37/40 [00:09<00:00,  5.22it/s]2025-01-20:15:28:17,243 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:17,243 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:17,340 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:17,340 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 38/40 [00:09<00:00,  5.42it/s]2025-01-20:15:28:17,420 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:17,420 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:17,520 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:17,521 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 39/40 [00:09<00:00,  5.45it/s]2025-01-20:15:28:17,828 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:17,828 INFO     [wml_resource.py:112] Successfully finished tokenize for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/tokenization?version=2025-01-10'\n2025-01-20:15:28:17,926 INFO     [_client.py:1027] HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10 \"HTTP/1.1 200 OK\"\n2025-01-20:15:28:17,926 INFO     [wml_resource.py:112] Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-01-10'\nRunning loglikelihood function ...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:10<00:00,  3.94it/s]\nfatal: not a git repository (or any of the parent directories): .git\n2025-01-20:15:28:23,709 INFO     [evaluation_tracker.py:206] Saving results aggregated\nwatsonx_llm (model_id=ibm/granite-13b-instruct-v2), gen_kwargs: (None), limit: 10.0, num_fewshot: None, batch_size: 1\n|     Tasks     |Version|Filter|n-shot| Metric |   |Value|   |Stderr|\n|---------------|------:|------|-----:|--------|---|----:|---|-----:|\n|test_task_local|      1|none  |     0|acc     |\u2191  |  0.6|\u00b1  |0.1633|\n|               |       |none  |     0|acc_norm|\u2191  |  0.8|\u00b1  |0.1333|\n\n", "output_type": "stream"}], "execution_count": 51}, {"cell_type": "markdown", "source": "Now let's see the evaluation results. The file name consists of the `results` prefix and a unique timestamp. ", "metadata": {"id": "3183ef7f-cbfc-4b38-a780-3e92406e3296"}}, {"cell_type": "code", "source": "import json\n\ndef read_json_results(file_name): \n    with open(file_name) as results_file: \n        return json.loads(results_file.read())", "metadata": {"id": "d0795a4a-bb89-4440-81c1-66b8b8ae6263"}, "outputs": [], "execution_count": 52}, {"cell_type": "code", "source": "results_files = list(map(str, (Path(os.getcwd()) / \"results\").iterdir()))\nresults_files", "metadata": {"id": "ffbb996f-9236-463b-ac16-7062d6c6ca7b"}, "outputs": [{"execution_count": 53, "output_type": "execute_result", "data": {"text/plain": "['/home/wsuser/work/results/results_2025-01-20T15-28-23.709514.json',\n '/home/wsuser/work/results/results_2025-01-20T15-23-15.196310.json']"}, "metadata": {}}], "execution_count": 53}, {"cell_type": "markdown", "source": "For pretty printing reasons, the `pretty_env_info` is excluded from output. However, if you want to see this data, comment the `try... except...` block", "metadata": {"id": "2dab7e5c-9fd1-4942-ac4a-2ca08567d463"}}, {"cell_type": "code", "source": "for file in results_files:\n    data = read_json_results(file)\n    try:\n        data.pop(\"pretty_env_info\")\n    except KeyError:\n        pass\n    print(json.dumps(data, indent=2), end=\"\\n------------------\\n\")", "metadata": {"id": "1ef3dc31-7165-4f59-86b0-8ba2f5e6c54d"}, "outputs": [{"name": "stdout", "text": "{\n  \"results\": {\n    \"test_task_local\": {\n      \"alias\": \"test_task_local\",\n      \"acc,none\": 0.6,\n      \"acc_stderr,none\": 0.16329931618554522,\n      \"acc_norm,none\": 0.8,\n      \"acc_norm_stderr,none\": 0.13333333333333333\n    }\n  },\n  \"group_subtasks\": {\n    \"test_task_local\": []\n  },\n  \"configs\": {\n    \"test_task_local\": {\n      \"task\": \"test_task_local\",\n      \"tag\": \"test_task_ai2_arc_local\",\n      \"dataset_path\": \"parquet\",\n      \"dataset_kwargs\": {\n        \"data_files\": {\n          \"validation\": \"validation-00000-of-00001.parquet\"\n        }\n      },\n      \"validation_split\": \"validation\",\n      \"doc_to_text\": \"Question: {{question}}\\\\nAnswer:\",\n      \"doc_to_target\": \"{{choices.label.index(answerKey)}}\",\n      \"doc_to_choice\": \"{{choices.text}}\",\n      \"description\": \"\",\n      \"target_delimiter\": \" \",\n      \"fewshot_delimiter\": \"\\n\\n\",\n      \"num_fewshot\": 0,\n      \"metric_list\": [\n        {\n          \"aggregation\": \"mean\",\n          \"higher_is_better\": true,\n          \"metric\": \"acc\"\n        },\n        {\n          \"aggregation\": \"mean\",\n          \"higher_is_better\": true,\n          \"metric\": \"acc_norm\"\n        }\n      ],\n      \"output_type\": \"multiple_choice\",\n      \"repeats\": 1,\n      \"should_decontaminate\": true,\n      \"doc_to_decontamination_query\": \"Question: {{question}}\\\\nAnswer:\",\n      \"metadata\": {\n        \"version\": \"1.0\"\n      }\n    }\n  },\n  \"versions\": {\n    \"test_task_local\": \"1.0\"\n  },\n  \"n-shot\": {\n    \"test_task_local\": 0\n  },\n  \"higher_is_better\": {\n    \"test_task_local\": {\n      \"acc\": true,\n      \"acc_norm\": true\n    }\n  },\n  \"n-samples\": {\n    \"test_task_local\": {\n      \"original\": 570,\n      \"effective\": 10\n    }\n  },\n  \"config\": {\n    \"model\": \"watsonx_llm\",\n    \"model_args\": \"model_id=ibm/granite-13b-instruct-v2\",\n    \"batch_size\": 1,\n    \"batch_sizes\": [],\n    \"device\": null,\n    \"use_cache\": null,\n    \"limit\": 10.0,\n    \"bootstrap_iters\": 100000,\n    \"gen_kwargs\": null,\n    \"random_seed\": 0,\n    \"numpy_seed\": 1234,\n    \"torch_seed\": 1234,\n    \"fewshot_seed\": 1234\n  },\n  \"git_hash\": null,\n  \"date\": 1737386885.4925854,\n  \"transformers_version\": \"4.48.0\",\n  \"upper_git_hash\": null,\n  \"task_hashes\": {},\n  \"model_source\": \"watsonx_llm\",\n  \"model_name\": \"\",\n  \"model_name_sanitized\": \"\",\n  \"system_instruction\": null,\n  \"system_instruction_sha\": null,\n  \"fewshot_as_multiturn\": false,\n  \"chat_template\": null,\n  \"chat_template_sha\": null,\n  \"start_time\": 169250.776165057,\n  \"end_time\": 169276.345702382,\n  \"total_evaluation_time_seconds\": \"25.569537325005513\"\n}\n------------------\n{\n  \"results\": {\n    \"test_task_local\": {\n      \"alias\": \"test_task_local\",\n      \"acc,none\": 0.6,\n      \"acc_stderr,none\": 0.16329931618554522,\n      \"acc_norm,none\": 0.8,\n      \"acc_norm_stderr,none\": 0.13333333333333333\n    }\n  },\n  \"group_subtasks\": {\n    \"test_task_local\": []\n  },\n  \"configs\": {\n    \"test_task_local\": {\n      \"task\": \"test_task_local\",\n      \"tag\": \"test_task_ai2_arc_local\",\n      \"dataset_path\": \"parquet\",\n      \"dataset_kwargs\": {\n        \"data_files\": {\n          \"validation\": \"validation-00000-of-00001.parquet\"\n        }\n      },\n      \"validation_split\": \"validation\",\n      \"doc_to_text\": \"Question: {{question}}\\\\nAnswer:\",\n      \"doc_to_target\": \"{{choices.label.index(answerKey)}}\",\n      \"doc_to_choice\": \"{{choices.text}}\",\n      \"description\": \"\",\n      \"target_delimiter\": \" \",\n      \"fewshot_delimiter\": \"\\n\\n\",\n      \"num_fewshot\": 0,\n      \"metric_list\": [\n        {\n          \"aggregation\": \"mean\",\n          \"higher_is_better\": true,\n          \"metric\": \"acc\"\n        },\n        {\n          \"aggregation\": \"mean\",\n          \"higher_is_better\": true,\n          \"metric\": \"acc_norm\"\n        }\n      ],\n      \"output_type\": \"multiple_choice\",\n      \"repeats\": 1,\n      \"should_decontaminate\": true,\n      \"doc_to_decontamination_query\": \"Question: {{question}}\\\\nAnswer:\",\n      \"metadata\": {\n        \"version\": \"1.0\"\n      }\n    }\n  },\n  \"versions\": {\n    \"test_task_local\": \"1.0\"\n  },\n  \"n-shot\": {\n    \"test_task_local\": 0\n  },\n  \"higher_is_better\": {\n    \"test_task_local\": {\n      \"acc\": true,\n      \"acc_norm\": true\n    }\n  },\n  \"n-samples\": {\n    \"test_task_local\": {\n      \"original\": 570,\n      \"effective\": 10\n    }\n  },\n  \"config\": {\n    \"model\": \"watsonx_llm\",\n    \"model_args\": \"model_id=ibm/granite-13b-instruct-v2\",\n    \"batch_size\": 1,\n    \"batch_sizes\": [],\n    \"device\": null,\n    \"use_cache\": null,\n    \"limit\": 10.0,\n    \"bootstrap_iters\": 100000,\n    \"gen_kwargs\": null,\n    \"random_seed\": 0,\n    \"numpy_seed\": 1234,\n    \"torch_seed\": 1234,\n    \"fewshot_seed\": 1234\n  },\n  \"git_hash\": null,\n  \"date\": 1737386576.2748373,\n  \"transformers_version\": \"4.48.0\",\n  \"upper_git_hash\": null,\n  \"task_hashes\": {},\n  \"model_source\": \"watsonx_llm\",\n  \"model_name\": \"\",\n  \"model_name_sanitized\": \"\",\n  \"system_instruction\": null,\n  \"system_instruction_sha\": null,\n  \"fewshot_as_multiturn\": false,\n  \"chat_template\": null,\n  \"chat_template_sha\": null,\n  \"start_time\": 168941.342660851,\n  \"end_time\": 168967.8324532,\n  \"total_evaluation_time_seconds\": \"26.489792349020718\"\n}\n------------------\n", "output_type": "stream"}], "execution_count": 54}, {"cell_type": "markdown", "source": "## Summary and next steps <a name=\"summary\"></a>\nYou successfully completed this notebook!\n\nYou learned how to use `ibm-watsonx-ai` and `lm-evaluation-harness` to run custom local and registered benchmarks.\n\nCheck out our [Online Documentation](https://www.ibm.com/cloud/watson-studio/autoai) for more samples, tutorials, documentation, how-tos, and blog posts.\n\n### Authors \n<b>Marta Tomzik</b>, Software Engineer at Watson Machine Learning.\n\nCopyright \u00a9 2025 IBM. This notebook and its source code are released under the terms of the MIT License.", "metadata": {"id": "7927ccdc-2326-4ee3-afb5-645423485930"}}]}