{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Use watsonx, and `mistralai/mistral-large` to make simple chat conversation and tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Disclaimers\n",
    "\n",
    "- Use only Projects and Spaces that are available in watsonx context.\n",
    "\n",
    "\n",
    "## Notebook content\n",
    "\n",
    "This notebook provides a detailed demonstration of the steps and code required to showcase support for Chat models, including the integration of tools and watsonx.ai models.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "\n",
    "## Learning goal\n",
    "\n",
    "The purpose of this notebook is to demonstrate how to use Chat models, e.g. `mistralai/mistral-large` by using tools.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Foundation Models on watsonx](#models)\n",
    "- [Work with chat messages](#chat)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watson-machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install and import the `datasets` and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U \"langchain_ibm>=0.3,<0.4\" | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define the WML credentials\n",
    "Use the code cell below to define the WML credentials that are required to work with watsonx Foundation Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">Managing user API keys</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Enter your WML API key and hit enter: \"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define the project ID\n",
    "You need to provide the project ID to give the Foundation Model the context for the call. If you have a default project ID set in Watson Studio, the notebook obtains that project ID. Otherwise, you need to provide the project ID in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Enter your project_id and hit enter: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "## Set up the Foundation Model on `watsonx.ai`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `model_id` of the model you will use for the chat with tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/mistral-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model parameters\n",
    "\n",
    "You might need to adjust model `parameters` depending on the model you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| PARAMETER         | TYPE                                   | EXAMPLE VALUE           |\n",
      "+===================+========================================+=========================+\n",
      "| frequency_penalty | float, NoneType                        | 0.5                     |\n",
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| logprobs          | bool, NoneType                         | True                    |\n",
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| top_logprobs      | int, NoneType                          | 3                       |\n",
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| presence_penalty  | float, NoneType                        | 0.3                     |\n",
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| response_format   | dict, TextChatResponseFormat, NoneType | {'type': 'json_object'} |\n",
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| temperature       | float, NoneType                        | 0.7                     |\n",
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| max_tokens        | int, NoneType                          | 100                     |\n",
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| time_limit        | int, NoneType                          | 600000                  |\n",
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| top_p             | float, NoneType                        | 0.9                     |\n",
      "+-------------------+----------------------------------------+-------------------------+\n",
      "| n                 | int, NoneType                          | 1                       |\n",
      "+-------------------+----------------------------------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
    "\n",
    "TextChatParameters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = TextChatParameters(\n",
    "    temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model\n",
    "\n",
    "Initialize the `ModelInference` class with the previously set parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "\n",
    "model = ModelInference(\n",
    "    model_id=model_id,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id,\n",
    "    params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chat\"></a>\n",
    "## Work with chat messages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with a simple chat message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is 1 + 1\"\n",
    "    }\n",
    "]\n",
    "\n",
    "simple_chat_response = model.chat(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The sum of 1 + 1 is 2. Here it is:\n",
      "\n",
      " 1\n",
      "+1\n",
      "____\n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "print(simple_chat_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with a simple chat message using chat_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What IBM mainly does?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "simple_chat_stream_response = model.chat_stream(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IBM (International Business Machines Corporation) is a multinational technology and consulting company that operates in more than 170 countries. Here are some of the main areas that IBM is involved in:\n",
      "\n",
      "1. **Technology and Consulting Services**: IBM Global Services is the world's largest business and technology services provider. It offers consulting, software development, and IT services.\n",
      "\n",
      "2. **Cloud Computing**: IBM Cloud offers a wide range of services for public, private, and hybrid cloud environments. It includes Infrastructure as a Service (IaaS), Software as a Service (SaaS), and Platform as a Service (PaaS) offerings.\n",
      "\n",
      "3. **Artificial Intelligence (AI) / Cognitive Computing**: IBM Watson is a flagship product in this area, offering a range of AI services, including natural language processing, machine learning, and predictive analytics.\n",
      "\n",
      "4. **Software**: IBM develops, manufactures, and licenses software for various domains. This includes operating systems (like z/OS), middleware (like WebSphere), and analytics software (like SPSS).\n",
      "\n",
      "5. **Hardware**: IBM manufactures and sells computer hardware, from mainframe computers (like IBM Z) to servers (like IBM Power Systems) and storage devices.\n",
      "\n",
      "6. **Research and Development**: IBM Research is one of the world's largest research organizations, with numerous significant inventions and innovations to its credit, like the ATM, hard disk drive, and more.\n",
      "\n",
      "7. **Blockchain**: IBM offers blockchain services and solutions for various industries, with IBM Blockchain Platform being one of the key offerings.\n",
      "\n",
      "8. **Quantum Computing**: IBM is also involved in the development of quantum computing systems and services, with IBM Q being its quantum computing program.\n",
      "\n",
      "9. **Cybersecurity**: IBM Security offers a range of services and solutions to help businesses stay secure and manage risk.\n",
      "\n",
      "These are the primary areas that IBM operates in, but the company's reach and impact extend far beyond these categories."
     ]
    }
   ],
   "source": [
    "for chunk in simple_chat_stream_response:\n",
    "    print(chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\"), end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with an advanced chat message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Who won the world series in 2020?\"\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Where was it played?\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "advanced_chat_response = model.chat(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The 2020 World Series was played at Globe Life Field in Arlington, Texas. Due to the COVID-19 pandemic, the entire series was played at a neutral site, which was the new home of the Texas Rangers. It was the first time since 1944 that the World Series was played at a single location. The Dodgers defeated the Tampa Bay Rays in six games to win their seventh World Series title.\n"
     ]
    }
   ],
   "source": [
    "print(advanced_chat_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with chat messages using `tools` and `tool_choice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str, unit: str = \"celsius\") -> dict:\n",
    "    \"\"\"\n",
    "    Get the current weather in a given location.\n",
    "\n",
    "    Parameters:\n",
    "    - location (str): The city and state, e.g., \"San Francisco, CA\".\n",
    "    - unit (str): The unit for temperature, either \"celsius\" or \"fahrenheit\". Defaults to \"celsius\".\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the current weather details.\n",
    "    \"\"\"\n",
    "    weather_data = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": 20,\n",
    "        \"unit\": unit,\n",
    "        \"description\": \"Partly cloudy\"\n",
    "    }\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting raw python function to correct tool schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"type\": \"function\",\n",
      "        \"function\": {\n",
      "            \"name\": \"get_current_weather\",\n",
      "            \"description\": \"Get the current weather in a given location. Parameters:\\n- location (str): The city and state, e.g., \\\"San Francisco, CA\\\".\\n- unit (str): The unit for temperature, either \\\"celsius\\\" or \\\"fahrenheit\\\". Defaults to \\\"celsius\\\".\",\n",
      "            \"parameters\": {\n",
      "                \"properties\": {\n",
      "                    \"location\": {\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    \"unit\": {\n",
      "                        \"default\": \"celsius\",\n",
      "                        \"type\": \"string\"\n",
      "                    }\n",
      "                },\n",
      "                \"required\": [\n",
      "                    \"location\"\n",
      "                ],\n",
      "                \"type\": \"object\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_ibm.chat_models import convert_to_openai_tool\n",
    "\n",
    "formatted_tools = [convert_to_openai_tool(get_current_weather)]\n",
    "print(json.dumps(formatted_tools, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"},\n",
    "]\n",
    "\n",
    "tool_choice = {\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\"}}\n",
    "\n",
    "tool_response = model.chat(messages=messages, tools=formatted_tools, tool_choice=tool_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"\",\n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"id\": \"chatcmpl-tool-87eea10be7fd48f386c6f4602247cbc4\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "                \"name\": \"get_current_weather\",\n",
      "                \"arguments\": \"{\\\"location\\\":\\\"Boston,MA\\\"}\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(tool_response[\"choices\"][0][\"message\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with chat messages using `tools` and `tool_choice_option`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Adds two numbers.\n",
    "\n",
    "    Parameters:\n",
    "    - a (float): The first number.\n",
    "    - b (float): The second number.\n",
    "\n",
    "    Returns:\n",
    "    - float: The result of a + b.\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def multiply_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Multiplies two numbers.\n",
    "\n",
    "    Parameters:\n",
    "    - a (float): The first number.\n",
    "    - b (float): The second number.\n",
    "\n",
    "    Returns:\n",
    "    - float: The result of a * b.\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting raw python function to correct tool schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"type\": \"function\",\n",
      "        \"function\": {\n",
      "            \"name\": \"add_numbers\",\n",
      "            \"description\": \"Adds two numbers. Parameters:\\n- a (float): The first number.\\n- b (float): The second number.\",\n",
      "            \"parameters\": {\n",
      "                \"properties\": {\n",
      "                    \"a\": {\n",
      "                        \"type\": \"number\"\n",
      "                    },\n",
      "                    \"b\": {\n",
      "                        \"type\": \"number\"\n",
      "                    }\n",
      "                },\n",
      "                \"required\": [\n",
      "                    \"a\",\n",
      "                    \"b\"\n",
      "                ],\n",
      "                \"type\": \"object\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"type\": \"function\",\n",
      "        \"function\": {\n",
      "            \"name\": \"multiply_numbers\",\n",
      "            \"description\": \"Multiplies two numbers. Parameters:\\n- a (float): The first number.\\n- b (float): The second number.\",\n",
      "            \"parameters\": {\n",
      "                \"properties\": {\n",
      "                    \"a\": {\n",
      "                        \"type\": \"number\"\n",
      "                    },\n",
      "                    \"b\": {\n",
      "                        \"type\": \"number\"\n",
      "                    }\n",
      "                },\n",
      "                \"required\": [\n",
      "                    \"a\",\n",
      "                    \"b\"\n",
      "                ],\n",
      "                \"type\": \"object\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "tool_choice_option = \"auto\"\n",
    "\n",
    "formatted_tools = [convert_to_openai_tool(tool) for tool in [add_numbers, multiply_numbers]]\n",
    "\n",
    "print(json.dumps(formatted_tools, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"id\": \"vfrqLLJ8m\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "                \"name\": \"add_numbers\",\n",
      "                \"arguments\": \"{\\\"a\\\": 5, \\\"b\\\": 6}\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 5 + 6?\"},\n",
    "]\n",
    "\n",
    "tools_response = model.chat(messages=messages, tools=formatted_tools, tool_choice_option=tool_choice_option)\n",
    "\n",
    "print(json.dumps(tools_response[\"choices\"][0][\"message\"], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"id\": \"nPLAOHLZs\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "                \"name\": \"multiply_numbers\",\n",
      "                \"arguments\": \"{\\\"a\\\": 5, \\\"b\\\": 6}\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 5 * 6?\"},\n",
    "]\n",
    "\n",
    "tools_response_2 = model.chat(messages=messages, tools=formatted_tools, tool_choice_option=tool_choice_option)\n",
    "\n",
    "print(json.dumps(tools_response_2[\"choices\"][0][\"message\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute tool calls\n",
    "\n",
    "We organize the two functions into a dictionary where keys represent the function name, and values are the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_functions = {\n",
    "    \"add_numbers\": add_numbers,\n",
    "    \"multiply_numbers\": multiply_numbers,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing function: `add_numbers`, with parameters: {'a': 5, 'b': 6}\n",
      "Function result: 11\n"
     ]
    }
   ],
   "source": [
    "tool_call = tools_response[\"choices\"][0][\"message\"][\"tool_calls\"]\n",
    "function_name = tool_call[0][\"function\"][\"name\"]\n",
    "function_params = json.loads(tool_call[0][\"function\"][\"arguments\"])\n",
    "print(f\"Executing function: `{function_name}`, with parameters: {function_params}\")\n",
    "\n",
    "function_result = names_to_functions[function_name](**function_params)\n",
    "print(f\"Function result: {function_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing function: `multiply_numbers`, with parameters: {'a': 5, 'b': 6}\n",
      "Function result: 30\n"
     ]
    }
   ],
   "source": [
    "tool_call = tools_response_2[\"choices\"][0][\"message\"][\"tool_calls\"]\n",
    "function_name = tool_call[0][\"function\"][\"name\"]\n",
    "function_params = json.loads(tool_call[0][\"function\"][\"arguments\"])\n",
    "print(f\"Executing function: `{function_name}`, with parameters: {function_params}\")\n",
    "\n",
    "\n",
    "function_result = names_to_functions[function_name](**function_params)\n",
    "print(f\"Function result: {function_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary and next steps\n",
    "\n",
    "You successfully completed this notebook!\n",
    "\n",
    "You learned how to work with chat models using tools and watsonx.ai.\n",
    "\n",
    "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Author\n",
    "\n",
    "**Mateusz Szewczyk**, Software Engineer at Watson Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2024 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
