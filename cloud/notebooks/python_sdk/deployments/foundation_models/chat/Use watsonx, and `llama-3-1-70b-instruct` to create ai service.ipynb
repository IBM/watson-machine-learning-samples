{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and `meta-llama/llama-3-1-70b-instruct` to create AI service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook provides a detailed demonstration of the steps and code required to showcase support for watsonx.ai AI service.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "This notebook aims to demonstrate the application of Chat models, such as `meta-llama/llama-3-1-70b-instruct`, using the tools provided by LangGraph. LangGraph serves as an Agent Orchestrator, enabling the development of graph-based applications that autonomously execute sequences of actions. In these applications, the Large Language Model (LLM) functions as the primary decision-maker, determining the subsequent steps. \n",
        "\n",
        "Following this, an AI service is created based on the previously constructed application.\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Create AI service](#ai_service)\n",
        "- [Testing AI service's function locally](#testing)\n",
        "- [Deploy AI service](#deploy)\n",
        "- [Example of Executing an AI service](#example)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install and import the `datasets` and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!pip install -U \"langgraph>0.2,<0.3\" | tail -n 1\n",
        "!pip install -U \"ibm_watsonx_ai>=1.1.22\" | tail -n 1\n",
        "!pip install -U \"langchain_ibm>=0.3,<0.4\" | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Define the watsonx.ai credentials\n",
        "Use the code cell below to define the watsonx.ai credentials that are required to work with watsonx Foundation Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">Managing user API keys</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    api_key=getpass.getpass(\"Enter your watsonx.ai api key and hit enter: \"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Working with spaces\n",
        "\n",
        "You need to create a space that will be used for your work. If you do not have a space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=wx) to create one.\n",
        "\n",
        "- Click **New Deployment Space**\n",
        "- Create an empty space\n",
        "- Select Cloud Object Storage\n",
        "- Select watsonx.ai Runtime instance and press **Create**\n",
        "- Go to **Manage** tab\n",
        "- Copy `Space GUID` and paste it below\n",
        "\n",
        "**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
        "\n",
        "**Action**: assign space ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    space_id = os.environ[\"SPACE_ID\"]\n",
        "except KeyError:\n",
        "    space_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an instance of APIClient with authentication details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "api_client = APIClient(credentials=credentials, space_id=space_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify the `model_id` of the model you will use for the chat with tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_id = \"meta-llama/llama-3-1-70b-instruct\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"ai_service\"></a>\n",
        "## Create AI service\n",
        "\n",
        "The content of this notebook is derived from and based on the material presented in the [Use watsonx, and `mistralai/mistral-large` with support for tools to perform simple calculations](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/deployments/foundation_models/chat/Use%20watsonx%2C%20and%20%60mistral-large%60%20with%20support%20for%20tools%20to%20perform%20simple%20calculations.ipynb) notebook. \n",
        "\n",
        "Prepare function which will be deployed using AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deployable_ai_service(context, space_id=space_id, url=credentials[\"url\"], model_id=model_id, **kwargs):\n",
        "    \n",
        "    from ibm_watsonx_ai import APIClient, Credentials\n",
        "    from langchain_ibm import ChatWatsonx\n",
        "    from langchain_core.tools import tool\n",
        "    from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "    api_client = APIClient(\n",
        "        credentials=Credentials(url=url, token=context.generate_token()),\n",
        "        space_id=space_id\n",
        "    )\n",
        "\n",
        "    chat = ChatWatsonx(\n",
        "        watsonx_client=api_client,\n",
        "        model_id=model_id,\n",
        "        params={\"temperature\": 0.1}\n",
        "    )\n",
        "    \n",
        "    @tool\n",
        "    def add(a: float, b: float) -> float:\n",
        "        \"\"\"Add a and b.\"\"\"\n",
        "        return a + b\n",
        "\n",
        "    @tool\n",
        "    def subtract(a: float, b: float) -> float:\n",
        "        \"\"\"Subtract a and b.\"\"\"\n",
        "        return a - b\n",
        "\n",
        "    @tool\n",
        "    def multiply(a: float, b: float) -> float:\n",
        "        \"\"\"Multiply a and b.\"\"\"\n",
        "        return a * b\n",
        "\n",
        "    @tool\n",
        "    def divide(a: float, b: float) -> float:\n",
        "        \"\"\"Divide a and b.\"\"\"\n",
        "        return a / b\n",
        "\n",
        "    tools = [add, subtract, multiply, divide]\n",
        "    \n",
        "    graph = create_react_agent(chat, tools=tools)\n",
        "\n",
        "    def generate(context) -> dict:\n",
        "        \n",
        "        api_client.set_token(context.get_token())\n",
        "   \n",
        "        payload = context.get_json()\n",
        "        question = payload[\"question\"]\n",
        "        \n",
        "        response = graph.invoke({\"messages\": [(\"user\", f\"{question}\")]})\n",
        "        \n",
        "        json_messages = [msg.to_json() for msg in response['messages']]\n",
        "        \n",
        "        response['messages'] = json_messages\n",
        "        \n",
        "        return {\"body\": response}\n",
        "    \n",
        "    def generate_stream(context):\n",
        "        \n",
        "        api_client.set_token(context.get_token())\n",
        "   \n",
        "        payload = context.get_json()\n",
        "        question = payload[\"question\"]\n",
        "        \n",
        "        for el in graph.stream({\"messages\": [(\"user\", f\"{question}\")]}, stream_mode=\"values\"):\n",
        "            \n",
        "            json_messages = [msg.to_json() for msg in el['messages']]\n",
        "            el['messages'] = json_messages\n",
        "            yield el\n",
        "        \n",
        "    return generate, generate_stream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add a helpful function to print messages from the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def print_message(message):\n",
        "    print(f\" ===== {message['id'][-1]} =====\")\n",
        "    if message[\"id\"][-1] == \"AIMessage\":\n",
        "        content = message[\"kwargs\"].get(\"additional_kwargs\", message[\"kwargs\"].get(\"content\"))\n",
        "        if isinstance(content, dict):\n",
        "            print(json.dumps(content, indent=2) + \"\\n\")\n",
        "        else:\n",
        "            print(content + \"\\n\")\n",
        "    elif message[\"id\"][-1] == \"ToolMessage\":\n",
        "        print(message[\"kwargs\"][\"name\"])\n",
        "        print(message[\"kwargs\"][\"content\"] + \"\\n\")\n",
        "    else:\n",
        "        print(message[\"kwargs\"][\"content\"] + \"\\n\")\n",
        "\n",
        "def ai_services_pretty_print(iter):\n",
        "    if \"body\" in iter:\n",
        "        iter = iter[\"body\"]\n",
        "    for message in iter[\"messages\"]:\n",
        "        print_message(message)\n",
        "        \n",
        "def ai_services_pretty_print_stream(iter):\n",
        "    for el in iter:\n",
        "        try:\n",
        "            el = json.loads(el)\n",
        "        except TypeError:\n",
        "            pass\n",
        "        print_message(el[\"messages\"][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"testing\"></a>\n",
        "## Testing AI service's function locally\n",
        "\n",
        "You can test AI service's function locally. Initialise `RuntimeContext` firstly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=api_client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "local_function = deployable_ai_service(context=context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare request json payload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "context.request_payload_json = {\"question\": \"What is the total sum of the numbers 11, 13, and 20? Remember to always return the final result using the last tool message.\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the `generate` function locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "resp = local_function[0](context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ===== HumanMessage =====\n",
            "What is the total sum of the numbers 11, 13, and 20? Remember to always return the final result using the last tool message.\n",
            "\n",
            " ===== AIMessage =====\n",
            "{\n",
            "  \"tool_calls\": [\n",
            "    {\n",
            "      \"id\": \"chatcmpl-tool-a6a9cd6a24154004b8d3aba6c7cc2018\",\n",
            "      \"type\": \"function\",\n",
            "      \"function\": {\n",
            "        \"name\": \"add\",\n",
            "        \"arguments\": \"{\\\"a\\\": \\\"11\\\", \\\"b\\\": \\\"13\\\"}\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            " ===== ToolMessage =====\n",
            "add\n",
            "24.0\n",
            "\n",
            " ===== AIMessage =====\n",
            "{\n",
            "  \"tool_calls\": [\n",
            "    {\n",
            "      \"id\": \"chatcmpl-tool-0adb0b39ec8d4e1897d9b5c7b876afd8\",\n",
            "      \"type\": \"function\",\n",
            "      \"function\": {\n",
            "        \"name\": \"add\",\n",
            "        \"arguments\": \"{\\\"a\\\": \\\"24\\\", \\\"b\\\": \\\"20\\\"}\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            " ===== ToolMessage =====\n",
            "add\n",
            "44.0\n",
            "\n",
            " ===== AIMessage =====\n",
            "The total sum of the numbers 11, 13, and 20 is 44.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ai_services_pretty_print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the `generate_stream` function locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = local_function[1](context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ===== HumanMessage =====\n",
            "What is the total sum of the numbers 11, 13, and 20? Remember to always return the final result using the last tool message.\n",
            "\n",
            " ===== AIMessage =====\n",
            "{\n",
            "  \"tool_calls\": [\n",
            "    {\n",
            "      \"id\": \"chatcmpl-tool-2d29c56e9c05434495713070582eb79d\",\n",
            "      \"type\": \"function\",\n",
            "      \"function\": {\n",
            "        \"name\": \"add\",\n",
            "        \"arguments\": \"{\\\"a\\\": \\\"11\\\", \\\"b\\\": \\\"13\\\"}\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            " ===== ToolMessage =====\n",
            "add\n",
            "24.0\n",
            "\n",
            " ===== AIMessage =====\n",
            "{\n",
            "  \"tool_calls\": [\n",
            "    {\n",
            "      \"id\": \"chatcmpl-tool-a69bd190f74941dca5ff9974579c97ab\",\n",
            "      \"type\": \"function\",\n",
            "      \"function\": {\n",
            "        \"name\": \"add\",\n",
            "        \"arguments\": \"{\\\"a\\\": \\\"24\\\", \\\"b\\\": \\\"20\\\"}\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            " ===== ToolMessage =====\n",
            "add\n",
            "44.0\n",
            "\n",
            " ===== AIMessage =====\n",
            "The total sum of the numbers 11, 13, and 20 is 44.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ai_services_pretty_print_stream(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"deploy\"></a>\n",
        "## Deploy AI service\n",
        "\n",
        "Prepare a configuration file for defining a custom software specification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_yml =\\\n",
        "\"\"\"\n",
        "name: python311\n",
        "channels:\n",
        "  - empty\n",
        "dependencies:\n",
        "  - pip:\n",
        "    - langgraph==0.2.44\n",
        "prefix: /opt/anaconda3/envs/python311\n",
        "\"\"\"\n",
        "\n",
        "with open(\"config.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(config_yml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating package extensions\n",
            "SUCCESS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'2e990d5b-dbe5-4b0a-81e1-cede89509e82'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_sw_spec_id = api_client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\n",
        "meta_prop_pkg_extn = {\n",
        "    api_client.package_extensions.ConfigurationMetaNames.NAME: \"watsonx.ai env with langgraph\",\n",
        "    api_client.package_extensions.ConfigurationMetaNames.DESCRIPTION: \"Environment with langgraph\",\n",
        "    api_client.package_extensions.ConfigurationMetaNames.TYPE: \"conda_yml\"\n",
        "}\n",
        "\n",
        "pkg_extn_details = api_client.package_extensions.store(meta_props=meta_prop_pkg_extn, file_path=\"config.yaml\")\n",
        "pkg_extn_id = api_client.package_extensions.get_id(pkg_extn_details)\n",
        "pkg_extn_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUCCESS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'5ecbae0e-5c58-494d-b2bd-fe9f5eaf7de2'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_prop_sw_spec = {\n",
        "    api_client.software_specifications.ConfigurationMetaNames.NAME: \"AI service watsonx.ai custom software specification with langgraph\",\n",
        "    api_client.software_specifications.ConfigurationMetaNames.DESCRIPTION: \"Software specification for AI service deployment\",\n",
        "    api_client.software_specifications.ConfigurationMetaNames.BASE_SOFTWARE_SPECIFICATION: {\"guid\": base_sw_spec_id}\n",
        "}\n",
        "\n",
        "sw_spec_details = api_client.software_specifications.store(meta_props=meta_prop_sw_spec)\n",
        "sw_spec_id = api_client.software_specifications.get_id(sw_spec_details)\n",
        "api_client.software_specifications.add_package_extension(sw_spec_id, pkg_extn_id)\n",
        "sw_spec_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store AI service with previous created custom software specifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_props = {\n",
        "    api_client.repository.AIServiceMetaNames.NAME: \"AI service SDK with langgraph\",    \n",
        "    api_client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: sw_spec_id\n",
        "}\n",
        "stored_ai_service_details = api_client.repository.store_ai_service(deployable_ai_service, meta_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cdf24a20-6c66-461a-ad56-4cad43302a64'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_service_id = api_client.repository.get_ai_service_id(stored_ai_service_details)\n",
        "ai_service_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create online deployment of AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "Synchronous deployment creation for id: 'cdf24a20-6c66-461a-ad56-4cad43302a64' started\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "\n",
            "initializing\n",
            "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
            "............\n",
            "ready\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Successfully finished deployment creation, deployment_id='6270e0b3-ed52-4f91-9a43-a3ba8131f0ec'\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    api_client.deployments.ConfigurationMetaNames.NAME: \"AI service with tools\",\n",
        "    api_client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
        "}\n",
        "\n",
        "deployment_details = api_client.deployments.create(ai_service_id, meta_props)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtain the `deployment_id` of the previously created deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_id = api_client.deployments.get_id(deployment_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"example\"></a>\n",
        "## Example of Executing an AI service.\n",
        "\n",
        "Execute `generate` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"What is the total sum of the numbers 11, 13, and 20? Remember to always return the final result using the last tool message.\"\n",
        "\n",
        "deployments_results = api_client.deployments.run_ai_service(\n",
        "    deployment_id, {\"question\": question}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ===== HumanMessage =====\n",
            "What is the total sum of the numbers 11, 13, and 20? Remember to always return the final result using the last tool message.\n",
            "\n",
            " ===== AIMessage =====\n",
            "{\n",
            "  \"tool_calls\": [\n",
            "    {\n",
            "      \"function\": {\n",
            "        \"arguments\": \"{\\\"a\\\": \\\"11\\\", \\\"b\\\": \\\"13\\\"}\",\n",
            "        \"name\": \"add\"\n",
            "      },\n",
            "      \"id\": \"chatcmpl-tool-aa6b07d025f846679702a76bb4e323d5\",\n",
            "      \"type\": \"function\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            " ===== ToolMessage =====\n",
            "add\n",
            "24.0\n",
            "\n",
            " ===== AIMessage =====\n",
            "{\n",
            "  \"tool_calls\": [\n",
            "    {\n",
            "      \"function\": {\n",
            "        \"arguments\": \"{\\\"a\\\": \\\"24\\\", \\\"b\\\": \\\"20\\\"}\",\n",
            "        \"name\": \"add\"\n",
            "      },\n",
            "      \"id\": \"chatcmpl-tool-286054ef43224dd28f2695e2a0eb88c7\",\n",
            "      \"type\": \"function\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            " ===== ToolMessage =====\n",
            "add\n",
            "44.0\n",
            "\n",
            " ===== AIMessage =====\n",
            "The total sum of the numbers 11, 13, and 20 is 44.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ai_services_pretty_print(deployments_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute `generate_stream` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"Add 2 to 5. Result multiply by 3? Result devided by 10. Always return the value from the last message to the user.\"\n",
        "\n",
        "deployments_results = api_client.deployments.run_ai_service_stream(\n",
        "    deployment_id, {\"question\": question}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ===== HumanMessage =====\n",
            "Add 2 to 5. Result multiply by 3? Result devided by 10. Always return the value from the last message to the user.\n",
            "\n",
            " ===== AIMessage =====\n",
            "{\n",
            "  \"tool_calls\": [\n",
            "    {\n",
            "      \"id\": \"chatcmpl-tool-a4fd3d8941124487b5c6c93af39a943d\",\n",
            "      \"type\": \"function\",\n",
            "      \"function\": {\n",
            "        \"name\": \"divide\",\n",
            "        \"arguments\": \"{\\\"a\\\": \\\"3\\\", \\\"b\\\": \\\"10\\\"}\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            " ===== ToolMessage =====\n",
            "divide\n",
            "0.3\n",
            "\n",
            " ===== AIMessage =====\n",
            "First, we need to add 2 to 5. Then, we need to multiply the result by 3. Finally, we need to divide the result by 10. The result of the last operation is 0.3.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ai_services_pretty_print_stream(deployments_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to create and deploy AI service using `ibm_watsonx_ai` SDK.\n",
        "\n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Author\n",
        "\n",
        "**Mateusz Szewczyk**, Software Engineer at watsonx.ai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright © 2024-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "watsonx-ai-rt23.1-py310-osx64",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
