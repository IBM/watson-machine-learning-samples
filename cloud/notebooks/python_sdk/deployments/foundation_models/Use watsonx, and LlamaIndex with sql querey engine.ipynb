{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Use watsonx, and LlamaIndex for Text-to-SQL task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Disclaimers\n",
    "\n",
    "- Use only Projects and Spaces that are available in watsonx context.\n",
    "\n",
    "\n",
    "## Notebook content\n",
    "\n",
    "This notebook contains the steps and code to demonstrate construction of natural language queries that are synthesized into SQL queries using watsonx.ai LlamaIndex integration and LlamaIndex query engine.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "\n",
    "## Learning goal\n",
    "\n",
    "The goal of this notebook is to demonstrate how to use `WatsonxLLM` and `WatsonxEmbeddings` together with LlamaIndex SQL query engine to retrieve required information from SQL database and answer given question based on send data.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Create dabase and data insertion](#create_database)\n",
    "- [Initialization of  LlamaIndex `WatsonX` LLM and `WatsonxEmbeddings`](#model)\n",
    "- [SQL Query Engine](#SQL_Query_Engine)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watson-machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U ibm-watsonx-ai | tail -n 1\n",
    "!pip install llama_index | tail -n 1\n",
    "!pip install sqlalchemy | tail -n 1\n",
    "\n",
    "# integration packages\n",
    "!pip install llama-index-embeddings-ibm | tail -n 1\n",
    "!pip install llama-index-llms-ibm | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the WML credentials\n",
    "This cell defines the WML credentials required to work with watsonx Foundation Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Please enter your WML api key (hit enter): \"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the project id\n",
    "The Foundation Model requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_database\"></a>\n",
    "## Create database and insert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the begining we generate dummy data.  We create two tables, `city_stats` that is taken from LlamaIndex <a href=\"https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo/\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a> and `sales_stats`, and using sqlite we store created tables in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "all_table_names = [\"city_stats\"]\n",
    "\n",
    "# create sales SQL table\n",
    "table_name = \"sales_stats\"\n",
    "sales_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"gender\", String(1)),\n",
    "    Column(\"age\", Integer),\n",
    "    Column(\"marital_status\", String(16)),\n",
    "    Column(\"profession\", String(16)),\n",
    "    Column(\"product_line\", String(16)),\n",
    "\n",
    ")\n",
    "all_table_names.append(table_name)\n",
    "\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "rows_city = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
    "    {\"city_name\": \"Chicago\", \"population\": 2679000, \"country\": \"United States\"},\n",
    "    {\"city_name\": \"Seoul\", \"population\": 9776000, \"country\": \"South Korea\"},\n",
    "]\n",
    "\n",
    "for row in rows_city:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)\n",
    "\n",
    "rows_sales = [\n",
    "    {\"gender\": \"M\", \"age\": 27, \"marital_status\": \"Single\", \"profession\": \"Professional\", \"product_line\": \"Personal Accessories\"},\n",
    "    {\"gender\": \"F\", \"age\": 39, \"marital_status\": \"Single\",\"profession\": \"Executive\", \"product_line\": \"Personal Accessories\"},\n",
    "    {\"gender\": \"M\", \"age\": 39, \"marital_status\": \"Married\", \"profession\": \"Student\", \"product_line\": \"Mountaineering Equipment\"},\n",
    "    {\"gender\": \"F\", \"age\": 56, \"marital_status\": \"Single\", \"profession\": \"Hospitality\", \"product_line\": \"Personal Accessories\"},\n",
    "    {\"gender\": \"M\", \"age\": 45, \"marital_status\": \"Married\", \"profession\": \"Retired\", \"product_line\": \"Golf Equipment\"}\n",
    "    ]\n",
    "\n",
    "for row in rows_sales:\n",
    "    stmt = insert(sales_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"models\"></a>\n",
    "## Initialization of  `WatsonxLLM` and`WatsonxEmbeddings`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to initlize the core components of SQL query engine, i.e. LlamaIndex `WatsonxLLM` client for model inferences and `WatsonxEmbeddings` that we will use to embed tables schema and then when fetching data from index.\n",
    "\n",
    "**Action:** For more details check the <a href=\"https://docs.llamaindex.ai/en/stable/\" target=\"_blank\" rel=\"noopener no referrer\">LlamaIndex documentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"watsonxllm\"></a>\n",
    "### LlamaIndex integration\n",
    "\n",
    "`WatsonxLLM` is a wrapper around watsonx.ai models that provide chain integration around the models.\n",
    "\n",
    "\n",
    "### Initialize the `WatsonxLLM` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames\n",
    "parameters = {\n",
    "    GenTextParamsMetaNames.DECODING_METHOD: \"sample\",\n",
    "    GenTextParamsMetaNames.STOP_SEQUENCES: ['\\n\\n']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.ibm import WatsonxLLM\n",
    "\n",
    "granite_llm = WatsonxLLM(\n",
    "    model_id='ibm/granite-13b-chat-v2',\n",
    "    url=credentials.get('url'),\n",
    "    apikey=credentials.get('apikey'),\n",
    "    project_id=project_id,\n",
    "    temperature=0.2,\n",
    "    max_new_tokens=100,\n",
    "    additional_params=parameters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMMetadata(context_window=8192, num_output=100, is_chat_model=False, is_function_calling_model=False, model_name='ibm/granite-13b-chat-v2', system_role=<MessageRole.SYSTEM: 'system'>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "granite_llm.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialize the `WatsonxEmbeddings` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ibm import WatsonxEmbeddings\n",
    "\n",
    "embed_model = WatsonxEmbeddings(apikey=credentials.get('apikey'),\n",
    "                               url=credentials.get('url'), \n",
    "                               model_id=\"ibm/slate-125m-english-rtrvr\", \n",
    "                               project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"SQL_Query_Engine\"></a>\n",
    "## SQL Query Engine\n",
    "Once we have all necessery components we can move to LlamaIndex SQL engine. For more details see LlamaIndex <a href=\"https://docs.llamaindex.ai/en/stable/\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SQL Database and Settings\n",
    "We use `SQLDatabase` wrapper for SQLAlchemy engine to interact with our local SQL database. Furthermore, we use `Settings` to set the global configuration. The Settings is an object that lives throughout session and contains a set of commonly used resources that are utilized during the indexing and querying stage in a LlamaIndex pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\", \"sales_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = granite_llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a Natural language SQL Table query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(sql_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL query example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can provide textual question and based on llm response query engine will execute proper SQL query and send back to the llm to get final answer to our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe largest city in Japan by population is Tokyo, with a population of approximately 13960000.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"What city in Japan has the largest population? How much it is?\")\n",
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now ask what is the average age of male customers in table `sales_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe average age of customers that are Male is 37.0.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the average age of customers that are Male?\")\n",
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In response we can also check what SQL query looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT avg(age) FROM sales_stats WHERE gender = 'M';\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = response.metadata['sql_query']\n",
    "sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(37.0,)]\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as connection:\n",
    "    cursor = connection.exec_driver_sql(sql_query)\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary and next steps\n",
    "\n",
    " You successfully completed this notebook!\n",
    " \n",
    " You learned how to use LlamaIndex SQL Query Engine with `WatsonxLLM` and `WatsonxEmbeddings`.\n",
    " \n",
    "Check out our _<a href=\"https://ibm.github.io/watson-machine-learning-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    " **Mateusz Świtała**, Software Engineer at Watson Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright © 2024 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
