{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Use watsonx.ai Text Extraction service to extract text from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Disclaimers\n",
    "\n",
    "- Use only Projects and Spaces that are available in watsonx context.\n",
    "\n",
    "\n",
    "## Notebook content\n",
    "\n",
    "This notebook contains the steps and code demonstrating how to run a Text Extraction job using python SDK and then retrieve the results in the form of JSON file.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "\n",
    "## Learning goal\n",
    "\n",
    "The purpose of this notebook is to demonstrate the usage a Text Extraction service and `ibm-watsonx-ai` Python SDK to retrieve a text from file that is located at IBM Cloud Object Storage.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [COS connection](#cos_connection)\n",
    "- [Text Extraction request](#text_extraction)\n",
    "- [Results examination](#results)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watson-machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install \"ibm-watsonx-ai>=1.1.5\" | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the WML credentials\n",
    "This cell defines the WML credentials required to work with watsonx Foundation Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "credentials = Credentials(url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "                          api_key=getpass.getpass(\"Please enter your WML api key (hit enter): \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the project id\n",
    "The Text Extraction service requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Client initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "client = APIClient(credentials=credentials, project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"cos_connection\"></a>\n",
    "## Create data connections with source document and results reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The document, from which we are going to extract text, is located at IBM Cloud Object Storage (COS). In the following example we are going to use [Granite Code Models paper](https://arxiv.org/pdf/2405.04324) as a source text document. Also, the final results file, which will contain extracted text and necessary metadata, will be placed in COS. Therefore, we use `ibm_watsonx_ai.helpers.DataConnection` and `ibm_watsonx_ai.helpers.S3Location` class to create a Python objects that will represent the references to the processed files. Please note that you have to create connection asset with your COS details (for detailed explanation how to do this see [IBM Cloud Object Storage connection](https://dataplatform.cloud.ibm.com/docs/content/wsj/manage-data/conn-cos.html?context=wx) or check below cells)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create connection to COS\n",
    "You can skip this section if you already have connection asset with **IBM Cloud Object Storage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_name = 'bluemixcloudobjectstorage'\n",
    "bucketname = \"textextractionms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_credentials = {\n",
    "                  \"endpoint_url\": \"<endpoint url>\",\n",
    "                  \"apikey\": \"<apikey>\",\n",
    "                  \"access_key_id\": \"<access_key_id>\",\n",
    "                  \"secret_access_key\": \"<secret_access_key>\"\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating connections...\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "conn_meta_props= {\n",
    "    client.connections.ConfigurationMetaNames.NAME: f\"Connection to Database - {datasource_name} \",\n",
    "    client.connections.ConfigurationMetaNames.DATASOURCE_TYPE: client.connections.get_datasource_type_id_by_name(datasource_name),\n",
    "    client.connections.ConfigurationMetaNames.DESCRIPTION: \"Connection to external Database\",\n",
    "    client.connections.ConfigurationMetaNames.PROPERTIES: {\n",
    "        'bucket': bucketname,\n",
    "        'access_key': cos_credentials['access_key_id'],\n",
    "        'secret_key': cos_credentials['secret_access_key'],\n",
    "        'iam_url': 'https://iam.cloud.ibm.com/identity/token',\n",
    "        'url': cos_credentials['endpoint_url']\n",
    "    }\n",
    "}\n",
    "\n",
    "conn_details = client.connections.create(meta_props=conn_meta_props)\n",
    "connection_asset_id = client.connections.get_id(conn_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload file and create document and results reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.helpers import DataConnection, S3Location\n",
    "\n",
    "local_source_file_name = \"granite_code_models_paper.pdf\"\n",
    "source_file_name = \"./files/granite_code_models_paper.pdf\"\n",
    "results_file_name = \"./files/text_extraction_granite_code_models_paper.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_document_reference = DataConnection(connection_asset_id=connection_asset_id,\n",
    "                                           location=S3Location(bucket = bucketname, path = \".\"))\n",
    "remote_document_reference.set_client(client)\n",
    "\n",
    "remote_document_reference.write(local_source_file_name, remote_name=source_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create Data Connection that represents document and results reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_reference = DataConnection(connection_asset_id=connection_asset_id,\n",
    "                                    location=S3Location(bucket=bucketname,\n",
    "                                                        path=source_file_name))\n",
    "\n",
    "results_reference = DataConnection(connection_asset_id=connection_asset_id,\n",
    "                                   location=S3Location(bucket=bucketname,\n",
    "                                                       path=results_file_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"text_extraction\"></a>\n",
    "## Text Extraction request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data connection for source and results files are ready, we can proceed to the text extraction run job step. To initialize Text Extraction manager we use `TextExtractions` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models.extractions import TextExtractions\n",
    "from ibm_watsonx_ai.metanames import TextExtractionsMetaNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = TextExtractions(api_client=client,\n",
    "                             project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running job the steps for the text extraction pipeline can be specified. For more details about available steps see [documentation](https://cloud.ibm.com/apidocs/watsonx-ai#text-extraction). The list of steps available in sdk can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------  ----  --------\n",
      "META_PROP NAME    TYPE  REQUIRED\n",
      "OCR               dict  N\n",
      "TABLE_PROCESSING  dict  N\n",
      "----------------  ----  --------\n"
     ]
    }
   ],
   "source": [
    "TextExtractionsMetaNames().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view sample parameter values for the text extraction steps run `get_example_values()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ocr': {'languages_list': ['en']}, 'tables_processing': {'enabled': True}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextExtractionsMetaNames().get_example_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example we are going to use the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = {TextExtractionsMetaNames.OCR: {'languages_list': ['en']},\n",
    "        TextExtractionsMetaNames.TABLE_PROCESSING: {'enabled': True}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run Text Extraction job. Please note that to get results in a more readable format we set `results_format` to `\"markdown\"`. However, if you want to get a file with more detailed results please use `\"json\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'id': 'ac2fac08-575c-4661-bd1f-1738be6f506a',\n",
       "  'created_at': '2024-11-28T14:50:22.990Z',\n",
       "  'project_id': '7e8b59ba-2610-4a29-9d90-dc02483ed5f4'},\n",
       " 'entity': {'document_reference': {'type': 'connection_asset',\n",
       "   'connection': {'id': '99d36548-ecb8-462a-ac5b-9d6604c1fc37'},\n",
       "   'location': {'file_name': './files/granite_code_models_paper.pdf',\n",
       "    'bucket': 'textextractionms'}},\n",
       "  'document': None,\n",
       "  'results_reference': {'type': 'connection_asset',\n",
       "   'connection': {'id': '99d36548-ecb8-462a-ac5b-9d6604c1fc37'},\n",
       "   'location': {'bucket': 'textextractionms',\n",
       "    'file_name': './files/text_extraction_granite_code_models_paper.json'}},\n",
       "  'steps': {'ocr': {'languages_list': ['en']},\n",
       "   'tables_processing': {'enabled': True}},\n",
       "  'assembly_md': {},\n",
       "  'results': {'status': 'submitted', 'number_pages_processed': 0}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = extraction.run_job(document_reference=document_reference, \n",
    "                             results_reference=results_reference, \n",
    "                             steps=steps,\n",
    "                             results_format=\"markdown\")\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_job_id = extraction.get_id(extraction_details=details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list text extraction jobs using a proper list method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXTRACTION_ID</th>\n",
       "      <th>CREATED</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ac2fac08-575c-4661-bd1f-1738be6f506a</td>\n",
       "      <td>2024-11-28T14:50:22.990Z</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          EXTRACTION_ID                   CREATED   STATUS\n",
       "0  ac2fac08-575c-4661-bd1f-1738be6f506a  2024-11-28T14:50:22.990Z  running"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction.list_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, to get details of a particular text extraction request run following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': {'document_reference': {'connection': {'id': '99d36548-ecb8-462a-ac5b-9d6604c1fc37'},\n",
       "   'location': {'bucket': 'textextractionms',\n",
       "    'file_name': './files/granite_code_models_paper.pdf'},\n",
       "   'type': 'connection_asset'},\n",
       "  'results': {'completed_at': '2024-11-28T14:50:52.104Z',\n",
       "   'number_pages_processed': 28,\n",
       "   'running_at': '2024-11-28T14:50:25.294Z',\n",
       "   'status': 'completed'},\n",
       "  'results_reference': {'connection': {'id': '99d36548-ecb8-462a-ac5b-9d6604c1fc37'},\n",
       "   'location': {'bucket': 'textextractionms',\n",
       "    'file_name': './files/text_extraction_granite_code_models_paper.json'},\n",
       "   'type': 'connection_asset'},\n",
       "  'steps': {'ocr': {'languages_list': ['en']},\n",
       "   'tables_processing': {'enabled': True}}},\n",
       " 'metadata': {'created_at': '2024-11-28T14:50:22.990Z',\n",
       "  'id': 'ac2fac08-575c-4661-bd1f-1738be6f506a',\n",
       "  'modified_at': '2024-11-28T14:50:52.146Z',\n",
       "  'project_id': '7e8b59ba-2610-4a29-9d90-dc02483ed5f4'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction.get_job_details(extraction_id=extraction_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, to delete text extraction jub run use `delete_job()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"results\"></a>\n",
    "## Results examination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job extraction is completed we can download the results file and process it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_reference = extraction.get_results_reference(extraction_id=extraction_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"text_extraction_results_granite_code_models_paper.md\"\n",
    "\n",
    "results_reference.download(filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "†Corresponding Authors \n",
      "\n",
      "Large Language Models (LLMs) trained on code are revolutionizing the software development process. Increasingly, code LLMs are being inte- grated into software development environments to improve the produc- tivity of human programmers, and LLM-based agents are beginning to show promise for handling complex tasks autonomously. Realizing the full potential of code LLMs requires a wide range of capabilities, including code generation, fixing bugs, explaining and documenting code, maintaining repositories, and more. In this work, we introduce the Granite series of decoder-only code models for code generative tasks, trained with code written in 116 programming languages. The Granite Code models family consists of models ranging in size from 3 to 34 billion parameters, suitable for applications ranging from complex application modernization tasks to on-device memory-constrained use cases. Evaluation on a comprehensive set of tasks demonstrates that Granite Code mode\n"
     ]
    }
   ],
   "source": [
    "with open(filename, 'r') as file:\n",
    "    extracted_text = file.read()\n",
    "\n",
    "print(extracted_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary and next steps\n",
    "\n",
    " You successfully completed this notebook!\n",
    " \n",
    " You learned how to use `TextExtractions` manager to run text extraction requests, check status of the submitted job and download a results file.\n",
    " \n",
    "Check out our _<a href=\"https://ibm.github.io/watson-machine-learning-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Authors:\n",
    " **Mateusz Świtała**, Software Engineer at Watson Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright © 2024 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
