{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Use AutoAI RAG and Chroma to create a pattern and get information from `ibm-watsonx-ai` SDK documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disclaimers\n",
    "\n",
    "- Use only Projects and Spaces that are available in watsonx context.\n",
    "\n",
    "\n",
    "## Notebook content\n",
    "\n",
    "This notebook contains the steps and code to demonstrate the usage of IBM AutoAI RAG. The AutoAI RAG experiment conducted in this notebook uses data scraped from the `ibm-watsonx-ai` SDK documentation.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "\n",
    "## Learning goal\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "- Create an AutoAI RAG job that will find the best RAG pattern based on provided data\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [RAG Optimizer definition](#definition)\n",
    "- [RAG Experiment run](#run)\n",
    "- [RAG Patterns comparison and testing](#comparison)\n",
    "- [Historical runs](#runs)\n",
    "- [Clean up](#cleanup)\n",
    "- [Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import the required modules and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U 'ibm-watsonx-ai[rag]>=1.2.4' | tail -n 1\n",
    "!pip install -U \"langchain_community>=0.3,<0.4\" | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the watsonx.ai credentials\n",
    "This cell defines the credentials required to work with the watsonx.ai Runtime service.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Please enter your watsonx.ai api key (hit enter): \"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the project id\n",
    "The foundation model requires a project id that provides the context for the call. We will try to obtain the id directly from the project in which this notebook runs. If this fails, you'll have to provide the project id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of APIClient with authentication details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "client = APIClient(credentials=credentials, project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"definition\"></a>\n",
    "\n",
    "## RAG Optimizer definition\n",
    "\n",
    "### Defining a connection to training data\n",
    "\n",
    "Upload training data to a COS bucket and then define a connection to this file. This example uses the `Base` description from the [`ibm_watsonx_ai`](https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html) documentation.\n",
    "\n",
    "The code in the next cell uploads training data to the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data asset...\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4f76e9c4-724e-45a2-8099-2d93f2746db3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "url = \"https://ibm.github.io/watsonx-ai-python-sdk/base.html\"\n",
    "\n",
    "document_filename = \"base.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "response.raise_for_status()\n",
    "\n",
    "if not os.path.isfile(document_filename):\n",
    "    with open(document_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(response.text)\n",
    "\n",
    "document_asset_details = client.data_assets.create(name=document_filename, file_path=document_filename)\n",
    "\n",
    "document_asset_id = client.data_assets.get_id(document_asset_details)\n",
    "document_asset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a connection to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.helpers import DataConnection\n",
    "\n",
    "input_data_references = [DataConnection(data_asset_id=document_asset_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a connection to test data\n",
    "\n",
    "Upload a `json` file that will be used for benchmarking to COS and then define a connection to this file. This example uses content from the [`ibm_watsonx_ai`](https://ibm.github.io/watsonx-ai-python-sdk/index.html) SDK documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_data_IBM_page_content = [\n",
    "    {\n",
    "        \"question\": \"How can you set or refresh user request headers using the APIClient class?\",\n",
    "        \"correct_answer\": \"client.set_headers({'Authorization': 'Bearer <token>'})\",\n",
    "        \"correct_answer_document_ids\": [\n",
    "            \"base.html\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How to initialise Credentials object with api_key\",\n",
    "        \"correct_answer\": \"credentials = Credentials(url = 'https://us-south.ml.cloud.ibm.com', api_key = '***********')\",\n",
    "        \"correct_answer_document_ids\": [\n",
    "            \"base.html\"\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell uploads testing data to the bucket as a `json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data asset...\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'84b59630-65a4-466d-b174-400928fb9634'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_filename = \"benchmarking_data_Base.json\"\n",
    "\n",
    "if not os.path.isfile(test_filename):\n",
    "    with open(test_filename, \"w\") as json_file:\n",
    "        json.dump(benchmarking_data_IBM_page_content, json_file, indent=4)\n",
    "\n",
    "test_asset_details = client.data_assets.create(name=test_filename, file_path=test_filename)\n",
    "\n",
    "test_asset_id = client.data_assets.get_id(test_asset_details)\n",
    "test_asset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define connection information to testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_references = [DataConnection(data_asset_id=test_asset_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Optimizer configuration\n",
    "\n",
    "Provide the input information for AutoAI RAG optimizer:\n",
    "- `name` - experiment name\n",
    "- `description` - experiment description\n",
    "- `max_number_of_rag_patterns` - maximum number of RAG patterns to create\n",
    "- `optimization_metrics` - target optimization metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.experiment import AutoAI\n",
    "\n",
    "experiment = AutoAI(credentials, project_id=project_id)\n",
    "\n",
    "rag_optimizer = experiment.rag_optimizer(\n",
    "    name='AutoAI RAG run - Base documentation',\n",
    "    description=\"AutoAI RAG Optimizer on ibm_watsonx_ai Base documentation\",\n",
    "    foundation_models=[\"ibm/granite-13b-chat-v2\"],\n",
    "    embedding_models=[\"ibm/slate-125m-english-rtrvr\"],\n",
    "    retrieval_methods=[\"simple\"],\n",
    "    chunking=[\n",
    "        {\n",
    "            \"chunk_size\": 512,\n",
    "            \"chunk_overlap\": 64,\n",
    "            \"method\": \"recursive\"\n",
    "        }\n",
    "    ],\n",
    "    max_number_of_rag_patterns=4,\n",
    "    optimization_metrics=[AutoAI.RAGMetrics.ANSWER_CORRECTNESS]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration parameters can be retrieved via `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'AutoAI RAG run - ModelInference documentation',\n",
       " 'description': 'AutoAI RAG Optimizer on ibm_watsonx_ai ModelInference documentation',\n",
       " 'chunking': [{'chunk_size': 512, 'chunk_overlap': 64, 'method': 'recursive'}],\n",
       " 'embedding_models': ['ibm/slate-125m-english-rtrvr'],\n",
       " 'retrieval_methods': ['simple'],\n",
       " 'foundation_models': ['ibm/granite-13b-chat-v2'],\n",
       " 'max_number_of_rag_patterns': 4,\n",
       " 'optimization_metrics': ['answer_correctness']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_optimizer.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"run\"></a>\n",
    "## RAG Experiment run\n",
    "\n",
    "Call the `run()` method to trigger the AutoAI RAG experiment. You can either use interactive mode (synchronous job) or background mode (asynchronous job) by specifying `background_mode=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##############################################\n",
      "\n",
      "Running 'efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69'\n",
      "\n",
      "##############################################\n",
      "\n",
      "\n",
      "pending.................\n",
      "running....\n",
      "completed\n",
      "Training of 'efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69' finished successfully.\n"
     ]
    }
   ],
   "source": [
    "run_details = rag_optimizer.run(\n",
    "    input_data_references=input_data_references,\n",
    "    test_data_references=test_data_references,\n",
    "    background_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `get_run_status()` method to monitor AutoAI RAG jobs in background mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_optimizer.get_run_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparison\"></a>\n",
    "## Comparison and testing of RAG Patterns\n",
    "\n",
    "You can list the trained patterns and information on evaluation metrics in the form of a Pandas DataFrame by calling the `summary()` method. You can use the DataFrame to compare all discovered patterns and select the one you like for further testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_answer_correctness</th>\n",
       "      <th>mean_faithfulness</th>\n",
       "      <th>mean_context_correctness</th>\n",
       "      <th>chunking.method</th>\n",
       "      <th>chunking.chunk_size</th>\n",
       "      <th>chunking.chunk_overlap</th>\n",
       "      <th>embeddings.model_id</th>\n",
       "      <th>vector_store.distance_metric</th>\n",
       "      <th>retrieval.method</th>\n",
       "      <th>retrieval.number_of_chunks</th>\n",
       "      <th>generation.model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pattern4</th>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>cosine</td>\n",
       "      <td>simple</td>\n",
       "      <td>3</td>\n",
       "      <td>ibm/granite-13b-chat-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern1</th>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>cosine</td>\n",
       "      <td>simple</td>\n",
       "      <td>5</td>\n",
       "      <td>ibm/granite-13b-chat-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern2</th>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>simple</td>\n",
       "      <td>5</td>\n",
       "      <td>ibm/granite-13b-chat-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern3</th>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>simple</td>\n",
       "      <td>3</td>\n",
       "      <td>ibm/granite-13b-chat-v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean_answer_correctness  mean_faithfulness  \\\n",
       "Pattern_Name                                               \n",
       "Pattern4                       0.7083             0.2317   \n",
       "Pattern1                       0.5833             0.2045   \n",
       "Pattern2                       0.5833             0.2372   \n",
       "Pattern3                       0.5833             0.2117   \n",
       "\n",
       "              mean_context_correctness chunking.method  chunking.chunk_size  \\\n",
       "Pattern_Name                                                                  \n",
       "Pattern4                           1.0       recursive                  512   \n",
       "Pattern1                           1.0       recursive                  512   \n",
       "Pattern2                           1.0       recursive                  512   \n",
       "Pattern3                           1.0       recursive                  512   \n",
       "\n",
       "              chunking.chunk_overlap           embeddings.model_id  \\\n",
       "Pattern_Name                                                         \n",
       "Pattern4                          64  ibm/slate-125m-english-rtrvr   \n",
       "Pattern1                          64  ibm/slate-125m-english-rtrvr   \n",
       "Pattern2                          64  ibm/slate-125m-english-rtrvr   \n",
       "Pattern3                          64  ibm/slate-125m-english-rtrvr   \n",
       "\n",
       "             vector_store.distance_metric retrieval.method  \\\n",
       "Pattern_Name                                                 \n",
       "Pattern4                           cosine           simple   \n",
       "Pattern1                           cosine           simple   \n",
       "Pattern2                        euclidean           simple   \n",
       "Pattern3                        euclidean           simple   \n",
       "\n",
       "              retrieval.number_of_chunks      generation.model_id  \n",
       "Pattern_Name                                                       \n",
       "Pattern4                               3  ibm/granite-13b-chat-v2  \n",
       "Pattern1                               5  ibm/granite-13b-chat-v2  \n",
       "Pattern2                               5  ibm/granite-13b-chat-v2  \n",
       "Pattern3                               3  ibm/granite-13b-chat-v2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = rag_optimizer.summary()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can pass the `scoring` parameter to the summary method, to filter RAG patterns starting with the best.\n",
    "\n",
    "```python\n",
    "summary = rag_optimizer.summary(scoring=\"faithfulness\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': {'completed_at': '2025-01-10T10:15:30.808Z',\n",
       "  'hardware_spec': {'id': 'a6c4923b-b8e4-444c-9f43-8a7ec3020110', 'name': 'L'},\n",
       "  'input_data_references': [{'location': {'href': '/v2/assets/4f76e9c4-724e-45a2-8099-2d93f2746db3?project_id=b9156b62-8f2a-4a40-8570-990fdd5d67cb',\n",
       "     'id': '4f76e9c4-724e-45a2-8099-2d93f2746db3'},\n",
       "    'type': 'data_asset'}],\n",
       "  'message': {'level': 'info', 'text': 'AAR019I: AutoAI execution completed.'},\n",
       "  'parameters': {'constraints': {'chunking': [{'chunk_overlap': 64,\n",
       "      'chunk_size': 512,\n",
       "      'method': 'recursive'}],\n",
       "    'embedding_models': ['ibm/slate-125m-english-rtrvr'],\n",
       "    'foundation_models': ['ibm/granite-13b-chat-v2'],\n",
       "    'max_number_of_rag_patterns': 4,\n",
       "    'retrieval_methods': ['simple']},\n",
       "   'optimization': {'metrics': ['answer_correctness']},\n",
       "   'output_logs': True},\n",
       "  'results': [{'context': {'iteration': 1,\n",
       "     'max_combinations': 4,\n",
       "     'rag_pattern': {'composition_steps': ['chunking',\n",
       "       'embeddings',\n",
       "       'vector_store',\n",
       "       'retrieval',\n",
       "       'generation'],\n",
       "      'duration_seconds': 16,\n",
       "      'location': {'evaluation_results': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern1/evaluation_results.json',\n",
       "       'indexing_notebook': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern1/indexing_inference_notebook.ipynb',\n",
       "       'inference_notebook': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern1/indexing_inference_notebook.ipynb'},\n",
       "      'name': 'Pattern1',\n",
       "      'settings': {'chunking': {'chunk_overlap': 64,\n",
       "        'chunk_size': 512,\n",
       "        'method': 'recursive'},\n",
       "       'embeddings': {'model_id': 'ibm/slate-125m-english-rtrvr',\n",
       "        'truncate_input_tokens': 512,\n",
       "        'truncate_strategy': 'left'},\n",
       "       'generation': {'context_template_text': '[Document]\\n{document}\\n[End]',\n",
       "        'model_id': 'ibm/granite-13b-chat-v2',\n",
       "        'parameters': {'decoding_method': 'greedy',\n",
       "         'max_new_tokens': 1000,\n",
       "         'min_new_tokens': 1},\n",
       "        'prompt_template_text': '<|system|>\\nYou are Granite Chat, an AI language model developed by IBM. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.\\n<|user|>\\nYou are a AI language model designed to function as a specialized Retrieval Augmented Generation (RAG) assistant. When generating responses, prioritize correctness, i.e., ensure that your response is grounded in context and user query. Always make sure that your response is relevant to the question.\\nAnswer Length: detailed\\n{reference_documents}\\n{question} \\n<|assistant|>'},\n",
       "       'retrieval': {'method': 'simple', 'number_of_chunks': 5},\n",
       "       'vector_store': {'datasource_type': 'chroma',\n",
       "        'distance_metric': 'cosine',\n",
       "        'index_name': 'autoai_rag_efb6f9ce_20250110101318',\n",
       "        'operation': 'upsert',\n",
       "        'schema': {'fields': [{'description': 'text field',\n",
       "           'name': 'text',\n",
       "           'role': 'text',\n",
       "           'type': 'string'},\n",
       "          {'description': 'document name field',\n",
       "           'name': 'document_id',\n",
       "           'role': 'document_name',\n",
       "           'type': 'string'},\n",
       "          {'description': 'chunk starting token position in the source document',\n",
       "           'name': 'start_index',\n",
       "           'role': 'start_index',\n",
       "           'type': 'number'},\n",
       "          {'description': 'chunk number per document',\n",
       "           'name': 'sequence_number',\n",
       "           'role': 'sequence_number',\n",
       "           'type': 'number'},\n",
       "          {'description': 'vector embeddings',\n",
       "           'name': 'vector',\n",
       "           'role': 'vector_embeddings',\n",
       "           'type': 'array'}],\n",
       "         'id': 'autoai_rag_1.0',\n",
       "         'name': 'Document schema using open-source loaders',\n",
       "         'type': 'struct'}}}},\n",
       "     'software_spec': {'name': 'autoai-rag_rt24.1-py3.11'}},\n",
       "    'metrics': {'test_data': [{'ci_high': 0.6667,\n",
       "       'ci_low': 0.5,\n",
       "       'mean': 0.5833,\n",
       "       'metric_name': 'answer_correctness'},\n",
       "      {'ci_high': 0.2541,\n",
       "       'ci_low': 0.155,\n",
       "       'mean': 0.2045,\n",
       "       'metric_name': 'faithfulness'},\n",
       "      {'mean': 1.0, 'metric_name': 'context_correctness'}]}},\n",
       "   {'context': {'iteration': 2,\n",
       "     'max_combinations': 4,\n",
       "     'rag_pattern': {'composition_steps': ['chunking',\n",
       "       'embeddings',\n",
       "       'vector_store',\n",
       "       'retrieval',\n",
       "       'generation'],\n",
       "      'duration_seconds': 13,\n",
       "      'location': {'evaluation_results': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern2/evaluation_results.json',\n",
       "       'indexing_notebook': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern2/indexing_inference_notebook.ipynb',\n",
       "       'inference_notebook': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern2/indexing_inference_notebook.ipynb'},\n",
       "      'name': 'Pattern2',\n",
       "      'settings': {'chunking': {'chunk_overlap': 64,\n",
       "        'chunk_size': 512,\n",
       "        'method': 'recursive'},\n",
       "       'embeddings': {'model_id': 'ibm/slate-125m-english-rtrvr',\n",
       "        'truncate_input_tokens': 512,\n",
       "        'truncate_strategy': 'left'},\n",
       "       'generation': {'context_template_text': '[Document]\\n{document}\\n[End]',\n",
       "        'model_id': 'ibm/granite-13b-chat-v2',\n",
       "        'parameters': {'decoding_method': 'greedy',\n",
       "         'max_new_tokens': 1000,\n",
       "         'min_new_tokens': 1},\n",
       "        'prompt_template_text': '<|system|>\\nYou are Granite Chat, an AI language model developed by IBM. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.\\n<|user|>\\nYou are a AI language model designed to function as a specialized Retrieval Augmented Generation (RAG) assistant. When generating responses, prioritize correctness, i.e., ensure that your response is grounded in context and user query. Always make sure that your response is relevant to the question.\\nAnswer Length: detailed\\n{reference_documents}\\n{question} \\n<|assistant|>'},\n",
       "       'retrieval': {'method': 'simple', 'number_of_chunks': 5},\n",
       "       'vector_store': {'datasource_type': 'chroma',\n",
       "        'distance_metric': 'euclidean',\n",
       "        'index_name': 'autoai_rag_efb6f9ce_20250110101349',\n",
       "        'operation': 'upsert',\n",
       "        'schema': {'fields': [{'description': 'text field',\n",
       "           'name': 'text',\n",
       "           'role': 'text',\n",
       "           'type': 'string'},\n",
       "          {'description': 'document name field',\n",
       "           'name': 'document_id',\n",
       "           'role': 'document_name',\n",
       "           'type': 'string'},\n",
       "          {'description': 'chunk starting token position in the source document',\n",
       "           'name': 'start_index',\n",
       "           'role': 'start_index',\n",
       "           'type': 'number'},\n",
       "          {'description': 'chunk number per document',\n",
       "           'name': 'sequence_number',\n",
       "           'role': 'sequence_number',\n",
       "           'type': 'number'},\n",
       "          {'description': 'vector embeddings',\n",
       "           'name': 'vector',\n",
       "           'role': 'vector_embeddings',\n",
       "           'type': 'array'}],\n",
       "         'id': 'autoai_rag_1.0',\n",
       "         'name': 'Document schema using open-source loaders',\n",
       "         'type': 'struct'}}}},\n",
       "     'software_spec': {'name': 'autoai-rag_rt24.1-py3.11'}},\n",
       "    'metrics': {'test_data': [{'ci_high': 0.6667,\n",
       "       'ci_low': 0.5,\n",
       "       'mean': 0.5833,\n",
       "       'metric_name': 'answer_correctness'},\n",
       "      {'ci_high': 0.3194,\n",
       "       'ci_low': 0.155,\n",
       "       'mean': 0.2372,\n",
       "       'metric_name': 'faithfulness'},\n",
       "      {'mean': 1.0, 'metric_name': 'context_correctness'}]}},\n",
       "   {'context': {'iteration': 3,\n",
       "     'max_combinations': 4,\n",
       "     'rag_pattern': {'composition_steps': ['chunking',\n",
       "       'embeddings',\n",
       "       'vector_store',\n",
       "       'retrieval',\n",
       "       'generation'],\n",
       "      'duration_seconds': 25,\n",
       "      'location': {'evaluation_results': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern3/evaluation_results.json',\n",
       "       'indexing_notebook': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern3/indexing_inference_notebook.ipynb',\n",
       "       'inference_notebook': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern3/indexing_inference_notebook.ipynb'},\n",
       "      'name': 'Pattern3',\n",
       "      'settings': {'chunking': {'chunk_overlap': 64,\n",
       "        'chunk_size': 512,\n",
       "        'method': 'recursive'},\n",
       "       'embeddings': {'model_id': 'ibm/slate-125m-english-rtrvr',\n",
       "        'truncate_input_tokens': 512,\n",
       "        'truncate_strategy': 'left'},\n",
       "       'generation': {'context_template_text': '[Document]\\n{document}\\n[End]',\n",
       "        'model_id': 'ibm/granite-13b-chat-v2',\n",
       "        'parameters': {'decoding_method': 'greedy',\n",
       "         'max_new_tokens': 1000,\n",
       "         'min_new_tokens': 1},\n",
       "        'prompt_template_text': '<|system|>\\nYou are Granite Chat, an AI language model developed by IBM. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.\\n<|user|>\\nYou are a AI language model designed to function as a specialized Retrieval Augmented Generation (RAG) assistant. When generating responses, prioritize correctness, i.e., ensure that your response is grounded in context and user query. Always make sure that your response is relevant to the question.\\nAnswer Length: detailed\\n{reference_documents}\\n{question} \\n<|assistant|>'},\n",
       "       'retrieval': {'method': 'simple', 'number_of_chunks': 3},\n",
       "       'vector_store': {'datasource_type': 'chroma',\n",
       "        'distance_metric': 'euclidean',\n",
       "        'index_name': 'autoai_rag_efb6f9ce_20250110101349',\n",
       "        'operation': 'upsert',\n",
       "        'schema': {'fields': [{'description': 'text field',\n",
       "           'name': 'text',\n",
       "           'role': 'text',\n",
       "           'type': 'string'},\n",
       "          {'description': 'document name field',\n",
       "           'name': 'document_id',\n",
       "           'role': 'document_name',\n",
       "           'type': 'string'},\n",
       "          {'description': 'chunk starting token position in the source document',\n",
       "           'name': 'start_index',\n",
       "           'role': 'start_index',\n",
       "           'type': 'number'},\n",
       "          {'description': 'chunk number per document',\n",
       "           'name': 'sequence_number',\n",
       "           'role': 'sequence_number',\n",
       "           'type': 'number'},\n",
       "          {'description': 'vector embeddings',\n",
       "           'name': 'vector',\n",
       "           'role': 'vector_embeddings',\n",
       "           'type': 'array'}],\n",
       "         'id': 'autoai_rag_1.0',\n",
       "         'name': 'Document schema using open-source loaders',\n",
       "         'type': 'struct'}}}},\n",
       "     'software_spec': {'name': 'autoai-rag_rt24.1-py3.11'}},\n",
       "    'metrics': {'test_data': [{'ci_high': 0.6667,\n",
       "       'ci_low': 0.5,\n",
       "       'mean': 0.5833,\n",
       "       'metric_name': 'answer_correctness'},\n",
       "      {'ci_high': 0.219,\n",
       "       'ci_low': 0.2044,\n",
       "       'mean': 0.2117,\n",
       "       'metric_name': 'faithfulness'},\n",
       "      {'mean': 1.0, 'metric_name': 'context_correctness'}]}},\n",
       "   {'context': {'iteration': 4,\n",
       "     'max_combinations': 4,\n",
       "     'rag_pattern': {'composition_steps': ['chunking',\n",
       "       'embeddings',\n",
       "       'vector_store',\n",
       "       'retrieval',\n",
       "       'generation'],\n",
       "      'duration_seconds': 24,\n",
       "      'location': {'evaluation_results': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern4/evaluation_results.json',\n",
       "       'indexing_notebook': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern4/indexing_inference_notebook.ipynb',\n",
       "       'inference_notebook': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/Pattern4/indexing_inference_notebook.ipynb'},\n",
       "      'name': 'Pattern4',\n",
       "      'settings': {'chunking': {'chunk_overlap': 64,\n",
       "        'chunk_size': 512,\n",
       "        'method': 'recursive'},\n",
       "       'embeddings': {'model_id': 'ibm/slate-125m-english-rtrvr',\n",
       "        'truncate_input_tokens': 512,\n",
       "        'truncate_strategy': 'left'},\n",
       "       'generation': {'context_template_text': '[Document]\\n{document}\\n[End]',\n",
       "        'model_id': 'ibm/granite-13b-chat-v2',\n",
       "        'parameters': {'decoding_method': 'greedy',\n",
       "         'max_new_tokens': 1000,\n",
       "         'min_new_tokens': 1},\n",
       "        'prompt_template_text': '<|system|>\\nYou are Granite Chat, an AI language model developed by IBM. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.\\n<|user|>\\nYou are a AI language model designed to function as a specialized Retrieval Augmented Generation (RAG) assistant. When generating responses, prioritize correctness, i.e., ensure that your response is grounded in context and user query. Always make sure that your response is relevant to the question.\\nAnswer Length: detailed\\n{reference_documents}\\n{question} \\n<|assistant|>'},\n",
       "       'retrieval': {'method': 'simple', 'number_of_chunks': 3},\n",
       "       'vector_store': {'datasource_type': 'chroma',\n",
       "        'distance_metric': 'cosine',\n",
       "        'index_name': 'autoai_rag_efb6f9ce_20250110101318',\n",
       "        'operation': 'upsert',\n",
       "        'schema': {'fields': [{'description': 'text field',\n",
       "           'name': 'text',\n",
       "           'role': 'text',\n",
       "           'type': 'string'},\n",
       "          {'description': 'document name field',\n",
       "           'name': 'document_id',\n",
       "           'role': 'document_name',\n",
       "           'type': 'string'},\n",
       "          {'description': 'chunk starting token position in the source document',\n",
       "           'name': 'start_index',\n",
       "           'role': 'start_index',\n",
       "           'type': 'number'},\n",
       "          {'description': 'chunk number per document',\n",
       "           'name': 'sequence_number',\n",
       "           'role': 'sequence_number',\n",
       "           'type': 'number'},\n",
       "          {'description': 'vector embeddings',\n",
       "           'name': 'vector',\n",
       "           'role': 'vector_embeddings',\n",
       "           'type': 'array'}],\n",
       "         'id': 'autoai_rag_1.0',\n",
       "         'name': 'Document schema using open-source loaders',\n",
       "         'type': 'struct'}}}},\n",
       "     'software_spec': {'name': 'autoai-rag_rt24.1-py3.11'}},\n",
       "    'metrics': {'test_data': [{'ci_high': 0.75,\n",
       "       'ci_low': 0.6667,\n",
       "       'mean': 0.7083,\n",
       "       'metric_name': 'answer_correctness'},\n",
       "      {'ci_high': 0.2589,\n",
       "       'ci_low': 0.2044,\n",
       "       'mean': 0.2317,\n",
       "       'metric_name': 'faithfulness'},\n",
       "      {'mean': 1.0, 'metric_name': 'context_correctness'}]}}],\n",
       "  'results_reference': {'location': {'path': 'default_autoai_rag_out',\n",
       "    'training': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69',\n",
       "    'training_status': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/training-status.json',\n",
       "    'training_log': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/output.log',\n",
       "    'assets_path': 'default_autoai_rag_out/efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69/assets'},\n",
       "   'type': 'container'},\n",
       "  'running_at': '2025-01-10T10:12:50.000Z',\n",
       "  'state': 'completed',\n",
       "  'step': 'generation',\n",
       "  'test_data_references': [{'location': {'href': '/v2/assets/84b59630-65a4-466d-b174-400928fb9634?project_id=b9156b62-8f2a-4a40-8570-990fdd5d67cb',\n",
       "     'id': '84b59630-65a4-466d-b174-400928fb9634'},\n",
       "    'type': 'data_asset'}],\n",
       "  'timestamp': '2025-01-10T10:19:50.024Z'},\n",
       " 'metadata': {'created_at': '2025-01-10T10:10:59.861Z',\n",
       "  'description': 'AutoAI RAG Optimizer on ibm_watsonx_ai ModelInference documentation',\n",
       "  'id': 'efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69',\n",
       "  'modified_at': '2025-01-10T10:15:30.971Z',\n",
       "  'name': 'AutoAI RAG run - ModelInference documentation',\n",
       "  'project_id': 'b9156b62-8f2a-4a40-8570-990fdd5d67cb'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_optimizer.get_run_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get selected pattern\n",
    "\n",
    "Get the RAGPattern object from the RAG Optimizer experiment. By default, the RAGPattern of the best pattern is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pattern_name = summary.index.values[0]\n",
    "print('Best pattern is:', best_pattern_name)\n",
    "\n",
    "best_pattern = rag_optimizer.get_pattern(pattern_name=\"Pattern1\")\n",
    "best_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern details can be retrieved by calling the `get_pattern_details` method:\n",
    "\n",
    "```python\n",
    "rag_optimizer.get_pattern_details(pattern_name='Pattern2')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the index/collection\n",
    "\n",
    "Build solution on the best pattern, with additional document indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check which `index_name` you are working on:\n",
    "\n",
    "```python\n",
    "best_pattern.vector_store._index_name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://ibm.github.io/watsonx-ai-python-sdk/fm_embeddings.html\",\n",
    "    \"https://ibm.github.io/watsonx-ai-python-sdk/fm_custom_models.html\",\n",
    "    \"https://ibm.github.io/watsonx-ai-python-sdk/fm_text_extraction.html\"\n",
    "]\n",
    "docs_list = WebBaseLoader(urls).load()\n",
    "doc_splits = best_pattern.chunker.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['26e3b6934e2d26b5016e48a72f8066e6e6c46f842921dc3850a9d7e90db422b7',\n",
       " '2a41a4ffaa8030ef315178951f17656100e491e07cbc27e3fd5c246e47297470',\n",
       " 'df6e5765dcfdfa245e80b5f526c4b6ae9bf661b94f46263f6d10fc235670a649',\n",
       " '3cafdf9aa72070f81f85138d6548290f69ce1daf06c2ff77833acb109c54daf1',\n",
       " '800812f60df6a099a6540f30db77eada51455f15d781f1ecc59a830206e9ee4a',\n",
       " '5c177d22821e150afc95ea18a34a94bd4e4cc18fc906fa9f48067a73e4fd9a14',\n",
       " 'd83f23a1d666979ab04abca6229d981af044ce09fbef23a0d180eb5756c50bc8',\n",
       " '987e2db87207c400067195d32d74c46002c6dbea3d63cbcf2bf7739375075424',\n",
       " '75ad5d3f99270fe00cfea3f68f9825fabd66206746ab7b62fe7d7533cb249c78',\n",
       " '03222e428bf11a47ab5b4622437bb34aca042c6e889fbca7817b1d80500e954a',\n",
       " '9d83427cd6341b0d3be46ae5ecef1dafb4ddcafb63540ec12a005c9d1deb92bf',\n",
       " 'da6f13c46cf0bd9e4fc79ef9f80cb89a42fcd260bc9c9397bfa349333fc312eb',\n",
       " '710988569ce081d6edc51cc23903d248a2017451afc6b75c36e69a34ee02c468',\n",
       " '531720786df6b24f44b66afb5e99e5d16f51d78f3a399df9f24e929e0c6e37ae',\n",
       " '9673f7cc44e2c6b59af016a5f97efe77682acab9a46bdf3f57863c0353db5f3d',\n",
       " '73a56b3bf7e6ccd5105013c1ebc8d73a45ed64e48daaea25ad95a9ea0e530f66',\n",
       " 'fd6e62fbdf29810ab9312b9ca0bba262b62a0991e6f36474a22818575d688ef0',\n",
       " 'c1f9e2d2b63d7a68bd8405caacd3ee7d4271a935503e9fc4ad132d863f0f9152',\n",
       " 'c1ddf6459ad12eb0aad568ec5da83f03097f6442eb144133f0f2b788afd2c088',\n",
       " '6956b13358764b6c097b6ab421e8e74a30088bad09ef937f2ffb50c9ddf5898e',\n",
       " '860961359a43043a8fd90d8b7376473edd0fd39ce1b6b724c1ff8323a01758dd',\n",
       " '68799f2438b62ad530437694832105a3fc974eb7f8fb9e55ef83395793911577',\n",
       " '2352e4a519641e8a66a5b87b0015c3a02ecbdc5aa1de62f7a904038d2acda69d',\n",
       " 'b686b759549d9781b9f66325db9f6034e6afaeac60de759afeb4b874b34b3cd6',\n",
       " 'e4a6a6b3c45d63bbc81b143815e6ac7b0a3998e38ce6cc590fa427fd0a1e7bed',\n",
       " 'cf632d17fdaabb5000d5bc1d07af8a8356277ec3cd5ec5a367d5915bf44ad634',\n",
       " 'f61cc206172c9f07ad86f8c5320e44e662fd88b8cc49252b2722fdad6bf884e5',\n",
       " 'ee8cc57587a324ac3c43b44e0669b169d4c3139a31adce852d688ca6b19f0fc6',\n",
       " '531b89f8fb66af799ec63adaf4e8163aa86a415f59f71ba403c71a7a1586b8e0',\n",
       " 'c16e03a96347002fc7365194f0f63ed22d76f8b1b4699fcd391be5dedc1c005f',\n",
       " '2029010a59ab1a1b1b8f360ed3d6532e77176ff31c6bf9d9dffa9b37b23f7dee',\n",
       " 'e4f459e29d7080ed5a85c0942dfaf355d231cee59d53648170867507e7df6d5d',\n",
       " '18446c0fa3966431f1c74dd3db41217e76b9c969e7e1de96b4669d26bdbd4f68',\n",
       " '1973580c0f13fb48f067d79f597590b4db4d75c164bd09ceab943de09c161df1',\n",
       " '54619f9b8ce803679610afc8a4c4e316c16fff73d67031bf8c1f83b8fd9a7b31',\n",
       " 'bd84c8df19f0ac48edda33555ce69c21507d0e666bb1433805647f99df0959bb',\n",
       " '3095fd98675edfec0e467b7b4e1ce38dbd5eba89e7ee9cfa03ba944852313724',\n",
       " 'a8bd89d8e09e3a95060956b88a3d9b85dff06a6f3bdff60f6efe3bd5b2b7d8f2',\n",
       " 'c277e67493de9ee9e92b82030b57c9e021b384c126a46ecea6445e6c63b912c6',\n",
       " '87f5a49d9549eb4260a2a66bce63f367fa39e9e915cb6790c99e290257988e6a',\n",
       " '2fddccc515c8d4d23d2d1e75ac4dc391f413fd2c6baf378d2bb76110bbb60a19',\n",
       " '001b26fe1f1a0a6b642b34eba602bf838947cfff794415787960e855fa68c91c',\n",
       " 'a2cb2616f62ab0831970ae4889e45685168d869dd11ee8f792ae389c3efb913c',\n",
       " 'b2b99fd59119815de9bc3dfd29d46aeaf4929e7eb4875c4e53b527d2fd982eab',\n",
       " '481b335b0d8f1fc74be755601b13981af0fdbe4befa99c7c9ec59eb0e2ed001c',\n",
       " '6e8c8f4479328c60de924d7636089ad176041648938dc6156000577e52caffcb',\n",
       " 'c7484d65bb4e88c10a710b68a0b444b002e73ebef345ff15627f9f8b2ce4c1ad',\n",
       " '17858cb4104c0c36a9f1287888351599dc3103d2b57ca182f85089ab087fdf3c',\n",
       " '2e1e623e9a5e5d25c96e3e63c40dff4839c63787bdfa423ea6b115ee1cc6e67c',\n",
       " '303835f544bbcec40d2063472f10bb7189ed514bf93bcdfae201e6e5d163787f',\n",
       " 'd25fa313eeceafd6b3f16ad27794e7d816b3d26cab0fec035eee862e6b7e3e6a',\n",
       " '68e3e02337f85ecd81da415de431d4be81b7230cfbf35976398f7a569f782273',\n",
       " '547676950eb909affba820fda6e0e3a4e741197e597214ef86c6c8da3d135e61',\n",
       " '04b0c30d3de9df3176bca372e27fb30d71a7d1aad77d60ca8e0f3571298f174c',\n",
       " '236c80504dd62f867ba64780339310ff6da2c1207d3bdad2601175d92ad490d6',\n",
       " '61c6b52998e65348bb296a7a8befcdc96f0af6506690a275e1892a08f5bf6496',\n",
       " '3dbba258aab554d28bb2d6e55d05c730dfa2d21a4e2d5abe50d81dba8cc5055f',\n",
       " 'a7d024c9244d327a30df25e0b7dc63659e72bb959407f51947959b84de30b3f7',\n",
       " '2568930293951272143b719c7b613ffef404cc11fcb0c48913e070b80ce362a9',\n",
       " '6152bbd7066755eb867681c0e39170d6c9c7494fe915285b575d94e407057728',\n",
       " '864c04bab6375d7cae2a99d0deaf5af954259842144674c67ffc088baa04130e',\n",
       " '1739949dd889dc912a77c1045b0e2a6bfe4cfd7f051fb6749f5a6d46227c36e8',\n",
       " '96c1df2eb0305d0faf8c18399e818cfc6be287c66ca416e9161f25d5b06243f2',\n",
       " '0c6b4cf5c33d84c97271da2fbddfd910914b80c63ca22cd4e9f9f0ee54eda8ef',\n",
       " 'bdbd0974ded5efd7349bf9f493a0628df9b65245446fcb177e1c2186b1fe9c8c',\n",
       " '0ec434ccae697cd03bf14f41247e5bc22da92c1c99dd96d538715161f6d52c03',\n",
       " '321f0fc064aa3a50ef0a6df155b33ce054fe5046003c1c4a19870fa1bda21831',\n",
       " 'e7e0b918538d1831863485c25ea55c7a05505e77332c3f96600fd2bd706f93a1',\n",
       " 'ee2d58e72cdf6f056861a2523fd183ae2f26e7678430520f05f823a0127478df',\n",
       " 'fdebb9d726075059af7622033d727f5c36f411c71f291e1d3eea449cf5e568ed']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pattern.indexing_function(doc_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the RAGPattern locally, to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'fields': ['answer', 'reference_documents'],\n",
       "   'values': [[\"\\nTo add Task Credentials, you can use the `client.task_credentials.store()` method. This method requires no parameters and will create new task credentials if they do not already exist. If the list of task credentials is empty, this method will automatically add them.\\n\\nHere's an example of how to add Task Credentials:\\n\\n```python\\nfrom ibm_watsonx_ai import APIClient\\n\\n# Initialize the APIClient object if needed\\nfrom ibm_watsonx_ai import APIClient\\nclient = APIClient(credentials)\\n\\n# Add Task Credentials\\nclient.task_credentials.store()\\n```\\n\\nNote: If you are using a custom foundation model, you will need to add Task Credentials before deploying the model. Failure to do so will result in token expiration issues.\",\n",
       "     [{'page_content': 'With task credentials, you can deploy a custom foundation model and avoid token expiration issues.\\nFor more details, see Adding task credentials.\\nTo list available task credentials, use the list method:\\nclient.task_credentials.list()\\n\\n\\nIf the list is empty, you can create new task credentials with the store method:\\nclient.task_credentials.store()\\n\\n\\nTo get the status of available task credentials, use the get_details method:\\nclient.task_credentials.get_details()',\n",
       "       'metadata': {'document_id': '8500262700953266120',\n",
       "        'language': 'en',\n",
       "        'sequence_number': 7,\n",
       "        'source': 'https://ibm.github.io/watsonx-ai-python-sdk/fm_custom_models.html',\n",
       "        'start_index': 0,\n",
       "        'title': 'Custom models - IBM watsonx.ai'}},\n",
       "      {'page_content': 'Initialize an APIClient object¶\\nInitialize an APIClient object if needed. For more details about supported APIClient initialization, see Setup.\\nfrom ibm_watsonx_ai import APIClient\\n\\nclient = APIClient(credentials)\\nclient.set.default_project(project_id=project_id)\\n# or client.set.default_space(space_id=space_id)\\n\\n\\n\\n\\nAdd Task Credentials¶\\n\\nWarning\\nIf not already added, Task Credentials are required on IBM watsonx.ai for IBM Cloud to make a deployment.',\n",
       "       'metadata': {'document_id': '8500262700953266120',\n",
       "        'language': 'en',\n",
       "        'sequence_number': 6,\n",
       "        'source': 'https://ibm.github.io/watsonx-ai-python-sdk/fm_custom_models.html',\n",
       "        'start_index': 0,\n",
       "        'title': 'Custom models - IBM watsonx.ai'}},\n",
       "      {'page_content': 'Note\\nWhen the credentials parameter is passed, one of these parameters is required: [project_id, space_id].\\n\\n\\nHint\\nYou can copy the project_id from the Project’s Manage tab (Project -> Manage -> General -> Details).\\n\\nExample:\\n from ibm_watsonx_ai import Credentials\\n from ibm_watsonx_ai.foundation_models import Embeddings\\n from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames as EmbedParams\\n from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes',\n",
       "       'metadata': {'document_id': '-541837184247348180',\n",
       "        'language': 'en',\n",
       "        'sequence_number': 10,\n",
       "        'source': 'https://ibm.github.io/watsonx-ai-python-sdk/fm_embeddings.html',\n",
       "        'start_index': 0,\n",
       "        'title': 'Embeddings - IBM watsonx.ai'}},\n",
       "      {'page_content': 'Parameters:\\n\\ncredentials (Credentials, optional) – credentials to the Watson Machine Learning instance\\nproject_id (str, optional) – ID of the Watson Studio project, defaults to None\\nspace_id (str, optional) – ID of the Watson Studio space, defaults to None\\napi_client (APIClient, optional) – initialized APIClient object with a set project ID or space ID. If passed, credentials and project_id/space_id are not required, defaults to None\\n\\n\\nRaises:',\n",
       "       'metadata': {'document_id': '87506292822977493',\n",
       "        'language': 'en',\n",
       "        'sequence_number': 6,\n",
       "        'source': 'https://ibm.github.io/watsonx-ai-python-sdk/fm_text_extraction.html',\n",
       "        'start_index': 0,\n",
       "        'title': 'Text Extractions - IBM watsonx.ai'}},\n",
       "      {'page_content': 'Initialize the APIClient object¶\\nInitialize the APIClient object if needed. For information about supported APIClient initialization, see Setup.\\nfrom ibm_watsonx_ai import APIClient\\n\\nclient = APIClient(credentials)\\nclient.set.default_project(project_id=project_id)\\n# or client.set.default_space(space_id=space_id)\\n\\n\\n\\n\\nList model specifications¶\\n\\nWarning\\nOnly applicable for IBM watsonx.ai for IBM Cloud Pak® for Data 4.8.4 and later.',\n",
       "       'metadata': {'document_id': '8500262700953266120',\n",
       "        'language': 'en',\n",
       "        'sequence_number': 17,\n",
       "        'source': 'https://ibm.github.io/watsonx-ai-python-sdk/fm_custom_models.html',\n",
       "        'start_index': 0,\n",
       "        'title': 'Custom models - IBM watsonx.ai'}}]]]}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [\"How to add Task Credentials?\"]\n",
    "\n",
    "payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"values\": questions,\n",
    "            \"access_token\": client.token\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "best_pattern.inference_function()(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"runs\"></a>\n",
    "## Historical runs\n",
    "\n",
    "In this section you learn to work with historical RAG Optimizer jobs (runs).\n",
    "\n",
    "To list historical runs use the `list()` method and provide the `'rag_optimizer'` filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>run_id</th>\n",
       "      <th>state</th>\n",
       "      <th>auto_pipeline_optimizer name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-10T10:15:30.971Z</td>\n",
       "      <td>efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69</td>\n",
       "      <td>completed</td>\n",
       "      <td>AutoAI RAG run - ModelInference documentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-09T15:13:26.515Z</td>\n",
       "      <td>555cb99c-925b-4f71-9e09-83533ed22fd3</td>\n",
       "      <td>completed</td>\n",
       "      <td>AutoAI RAG run - ModelInference documentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-09T12:58:25.539Z</td>\n",
       "      <td>e0b4281c-8908-433b-a762-b68c9a7e3b09</td>\n",
       "      <td>completed</td>\n",
       "      <td>AutoAI RAG run - ModelInference documentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-09T09:49:10.264Z</td>\n",
       "      <td>71d650bb-c357-468a-87cb-e461242c68b3</td>\n",
       "      <td>completed</td>\n",
       "      <td>AutoAI RAG run - ModelInference documentation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp                                run_id      state  \\\n",
       "0  2025-01-10T10:15:30.971Z  efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69  completed   \n",
       "1  2025-01-09T15:13:26.515Z  555cb99c-925b-4f71-9e09-83533ed22fd3  completed   \n",
       "2  2025-01-09T12:58:25.539Z  e0b4281c-8908-433b-a762-b68c9a7e3b09  completed   \n",
       "3  2025-01-09T09:49:10.264Z  71d650bb-c357-468a-87cb-e461242c68b3  completed   \n",
       "\n",
       "                    auto_pipeline_optimizer name  \n",
       "0  AutoAI RAG run - ModelInference documentation  \n",
       "1  AutoAI RAG run - ModelInference documentation  \n",
       "2  AutoAI RAG run - ModelInference documentation  \n",
       "3  AutoAI RAG run - ModelInference documentation  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.runs(filter='rag_optimizer').list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'efb6f9ce-8057-4fc1-9d84-5d2d78ffcf69'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = run_details['metadata']['id']\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get executed optimizer's configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'AutoAI RAG run - ModelInference documentation',\n",
       " 'description': 'AutoAI RAG Optimizer on ibm_watsonx_ai ModelInference documentation',\n",
       " 'chunking': [{'chunk_overlap': 64, 'chunk_size': 512, 'method': 'recursive'}],\n",
       " 'embedding_models': ['ibm/slate-125m-english-rtrvr'],\n",
       " 'retrieval_methods': ['simple'],\n",
       " 'foundation_models': ['ibm/granite-13b-chat-v2'],\n",
       " 'max_number_of_rag_patterns': 4,\n",
       " 'optimization_metrics': ['answer_correctness']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.runs.get_rag_params(run_id=run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get historical rag_optimizer instance and training details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_opt = experiment.runs.get_rag_optimizer(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List trained patterns for selected optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_answer_correctness</th>\n",
       "      <th>mean_faithfulness</th>\n",
       "      <th>mean_context_correctness</th>\n",
       "      <th>chunking.method</th>\n",
       "      <th>chunking.chunk_size</th>\n",
       "      <th>chunking.chunk_overlap</th>\n",
       "      <th>embeddings.model_id</th>\n",
       "      <th>vector_store.distance_metric</th>\n",
       "      <th>retrieval.method</th>\n",
       "      <th>retrieval.number_of_chunks</th>\n",
       "      <th>generation.model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pattern4</th>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>cosine</td>\n",
       "      <td>simple</td>\n",
       "      <td>3</td>\n",
       "      <td>ibm/granite-13b-chat-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern1</th>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>cosine</td>\n",
       "      <td>simple</td>\n",
       "      <td>5</td>\n",
       "      <td>ibm/granite-13b-chat-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern2</th>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>simple</td>\n",
       "      <td>5</td>\n",
       "      <td>ibm/granite-13b-chat-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern3</th>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>simple</td>\n",
       "      <td>3</td>\n",
       "      <td>ibm/granite-13b-chat-v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean_answer_correctness  mean_faithfulness  \\\n",
       "Pattern_Name                                               \n",
       "Pattern4                       0.7083             0.2317   \n",
       "Pattern1                       0.5833             0.2045   \n",
       "Pattern2                       0.5833             0.2372   \n",
       "Pattern3                       0.5833             0.2117   \n",
       "\n",
       "              mean_context_correctness chunking.method  chunking.chunk_size  \\\n",
       "Pattern_Name                                                                  \n",
       "Pattern4                           1.0       recursive                  512   \n",
       "Pattern1                           1.0       recursive                  512   \n",
       "Pattern2                           1.0       recursive                  512   \n",
       "Pattern3                           1.0       recursive                  512   \n",
       "\n",
       "              chunking.chunk_overlap           embeddings.model_id  \\\n",
       "Pattern_Name                                                         \n",
       "Pattern4                          64  ibm/slate-125m-english-rtrvr   \n",
       "Pattern1                          64  ibm/slate-125m-english-rtrvr   \n",
       "Pattern2                          64  ibm/slate-125m-english-rtrvr   \n",
       "Pattern3                          64  ibm/slate-125m-english-rtrvr   \n",
       "\n",
       "             vector_store.distance_metric retrieval.method  \\\n",
       "Pattern_Name                                                 \n",
       "Pattern4                           cosine           simple   \n",
       "Pattern1                           cosine           simple   \n",
       "Pattern2                        euclidean           simple   \n",
       "Pattern3                        euclidean           simple   \n",
       "\n",
       "              retrieval.number_of_chunks      generation.model_id  \n",
       "Pattern_Name                                                       \n",
       "Pattern4                               3  ibm/granite-13b-chat-v2  \n",
       "Pattern1                               5  ibm/granite-13b-chat-v2  \n",
       "Pattern2                               5  ibm/granite-13b-chat-v2  \n",
       "Pattern3                               3  ibm/granite-13b-chat-v2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_opt.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "## Clean up\n",
    "\n",
    "To delete the current experiment, use the `cancel_run` method.\n",
    "\n",
    "**Warning:** Be careful: once you delete an experiment, you will no longer be able to refer to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_optimizer.cancel_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to clean up all created assets:\n",
    "- experiments\n",
    "- trainings\n",
    "- pipelines\n",
    "- model definitions\n",
    "- models\n",
    "- functions\n",
    "- deployments\n",
    "\n",
    "please follow up this sample [notebook](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Machine%20Learning%20artifacts%20management.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary and next steps\n",
    "\n",
    "You successfully completed this notebook!.\n",
    "\n",
    "You learned how to use `ibm-watsonx-ai` to run AutoAI RAG experiments. \n",
    "\n",
    " Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "**Mateusz Szewczyk**, Software Engineer watsonx.ai\n",
    "\n",
    "Copyright © 2024-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watson-machine-learning-samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
